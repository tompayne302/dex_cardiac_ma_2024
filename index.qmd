---
title: "Dexmedetomidine in cardiac surgery meta-analysis"
author: 
  - name: Tom Payne
    affiliation: University of Sydney
date: today
---

```{r setup, include=FALSE}

library(tidyverse)
library(ggplot2)
library(ggpubr)
library(gridExtra)
library(ggrepel)
library(knitr)
library(kableExtra)
library(metafor)
library(lme4)
library(numDeriv)
library(BiasedUrn)
library(glue)
library(gt)
library(meta)
library(gridBase)
library(grid)
library(bayesmeta)
library(dplyr)
library(brms)
library(tidybayes)
library(rjags)
library(ggridges)
library(ggdist)
library(patchwork)
library(janitor)
library(rjags)
library(dmetar)
library(ggtext)
library(RoBMA)


knitr::opts_chunk$set(echo = F, message = F, warning = F, error = T, 
                      fig.height = 3, out.width = "90%", 
                      dev = "png", dpi = 300, cache = T)

### Set filepaths 
import_path_mac <- '/Users/thomaspayne/Documents/MPhil/cardiac_dex_ma/'
export_path_mac <- '/Users/thomaspayne/Documents/MPhil/cardiac_dex_ma/'

data <- read.csv(paste0(export_path_mac, "Data Extraction_R.o.B_13Sep2023v1.csv"))

## Create a column for total in dex and control group, and order by year
dat1 <- data %>%
  clean_names() %>%
  filter(!is.na(year)) %>%
  mutate_all(~ str_replace_all(., "\n", "")) %>%
  mutate_all(~ifelse(. == "N/A", "NA", .)) %>%
  mutate(across(contains(c("mortality", "brady", "hypo", "arrhythmia", "age_mean")), as.numeric)) %>%
  rename(dex_n = dex_number_participants,
         dex_del = dex_delirium,
        dex_no_del = dex_delirium_without,
        control_n = control_number_participants,
        control_del = control_delirium_incidence_1,
        control_no_del = control_delirium_incidence_without,
        age_60 = total_age_incl_lower_60,
        dex_dose = dex_maintenance_dose_quantity) %>%
  mutate(control_del_rate = as.numeric(control_del)/as.numeric(control_n),
         control_del_rate_frac = paste0(control_del, "/", control_n),
         dex_del_rate_frac = paste0(dex_del, "/", dex_n),
         dex_mortality = ifelse(is.na(dex_mortality_extended_1), dex_mortality_hospital_1,
                                ifelse(is.na(dex_mortality_hospital_1), dex_mortality_extended_1,
                                       dex_mortality_extended_1 + dex_mortality_hospital_1)),
         dex_no_mortality = ifelse(is.na(dex_mortality_extended_without), dex_mortality_hospital_without,
                                ifelse(is.na(dex_mortality_hospital_without), dex_mortality_extended_without,
                                       dex_mortality_extended_without + dex_mortality_hospital_without)),
         control_mortality = ifelse(is.na(control_mortality_extended_1), control_mortality_hospital_1,
                                ifelse(is.na(control_mortality_hospital_1), control_mortality_extended_1,
                                       control_mortality_extended_1 + control_mortality_hospital_1)),
         control_no_mortality = ifelse(is.na(control_mortality_extended_without), control_mortality_hospital_without,
                                ifelse(is.na(control_mortality_hospital_without), control_mortality_extended_without,
                                       control_mortality_extended_without + control_mortality_hospital_without)),
         control_mortality_rate = control_mortality/control_no_mortality,
         dex_bradycardia = ifelse(is.na(dex_brady_postop_1), dex_brady_intraop_1,
                                ifelse(is.na(dex_brady_intraop_1), dex_brady_postop_1,
                                       dex_brady_postop_1 + dex_brady_intraop_1)),
         dex_no_bradycardia = ifelse(is.na(dex_brady_postop_without), dex_brady_intraop_without,
                                ifelse(is.na(dex_brady_intraop_without), dex_brady_postop_without,
                                       dex_brady_postop_without + dex_brady_intraop_without)),
         control_bradycardia = ifelse(is.na(control_brady_postop_1), control_brady_intraop_1,
                                ifelse(is.na(control_brady_intraop_1), control_brady_postop_1,
                                       control_brady_postop_1 + control_brady_intraop_1)),
         control_no_bradycardia = ifelse(is.na(control_brady_postop_without), control_brady_intraop_without,
                                ifelse(is.na(control_brady_intraop_without), control_brady_postop_without,
                                       control_brady_postop_without + control_brady_intraop_without)),
         control_bradycardia_rate = control_bradycardia/control_no_bradycardia,
         dex_hypotension = ifelse(is.na(dex_hypo_postop_1), dex_hypo_intraop_1,
                                ifelse(is.na(dex_hypo_intraop_1), dex_hypo_postop_1,
                                       dex_hypo_postop_1 + dex_hypo_intraop_1)),
         dex_no_hypotension = ifelse(is.na(dex_hypo_postop_without), dex_hypo_intraop_without,
                                ifelse(is.na(dex_hypo_intraop_without), dex_hypo_postop_without,
                                       dex_hypo_postop_without + dex_hypo_intraop_without)),
         control_hypotension = ifelse(is.na(control_hypo_postop_1), control_hypo_intraop_1,
                                ifelse(is.na(control_hypo_intraop_1), control_hypo_postop_1,
                                       control_hypo_postop_1 + control_hypo_intraop_1)),
         control_no_hypotension = ifelse(is.na(control_hypo_postop_without), control_hypo_intraop_without,
                                ifelse(is.na(control_hypo_intraop_without), control_hypo_postop_without,
                                       control_hypo_postop_without + control_hypo_intraop_without)),
         control_hypotension_rate = control_hypotension/control_no_hypotension,
         dex_arrhythmia = ifelse(is.na(dex_arrhythmia_af_1), dex_arrhythmia_other_1,
                                ifelse(is.na(dex_arrhythmia_other_1), dex_arrhythmia_af_1,
                                       dex_arrhythmia_af_1 + dex_arrhythmia_other_1)),
         dex_no_arrhythmia = ifelse(is.na(dex_arrhythmia_af_without), dex_arrhythmia_other_without,
                                ifelse(is.na(dex_arrhythmia_other_without), dex_arrhythmia_af_without,
                                       dex_arrhythmia_af_without + dex_arrhythmia_other_without)),
         control_arrhythmia = ifelse(is.na(control_arrhythmia_af_1), control_arrhythmia_other_1,
                                ifelse(is.na(control_arrhythmia_other_1), control_arrhythmia_af_1,
                                       control_arrhythmia_af_1 + control_arrhythmia_other_1)),
         control_no_arrhythmia = ifelse(is.na(control_arrhythmia_af_without), control_arrhythmia_other_without,
                                ifelse(is.na(control_arrhythmia_other_without), control_arrhythmia_af_without,
                                       control_arrhythmia_af_without + control_arrhythmia_other_without)),
          control_arrhythmia_rate = control_arrhythmia/control_no_arrhythmia,
         mean_age = (dex_age_mean + control_age_mean)/2) %>%
  mutate(dex_dose = case_when(
    dex_dose == "high" ~ "High",
    dex_dose == "low" ~ "Low",
    TRUE ~ dex_dose
  ),
  control_agent_clean = case_when(
    grepl("ns", control_agent, ignore.case = TRUE) ~ "Normal saline",
    grepl("propofol", control_agent, ignore.case = TRUE) ~ "Propofol",
    grepl("morphine", control_agent, ignore.case = TRUE) ~ "Morphine",
    TRUE ~ control_agent
  )) %>%
  mutate_at(vars(dex_del, dex_n, dex_no_del, control_del, control_n, control_no_del,
                 dex_delirium_duration_days_mean, dex_delirium_duration_days_sd,
                 control_delirium_duration_days_mean, control_delirium_duration_days_sd,
                 dex_timetoextubation_mean, dex_timetoextubation_sd,
                 control_timetoextubation_mean, control_timetoextubation_sd,
                 dex_icu_days_mean, dex_icu_days_sd, control_icu_days_mean, control_icu_days_sd,
                 dex_hospitial_days_mean, dex_hospitial_days_sd, control_hospitial_days_mean, control_hospitial_days_sd), as.numeric) %>%
  rename_with(~ gsub("hospitial", "hospital", .), contains("hospitial"))

# Now we need to join the risk of bias data
rob <- read.csv(paste0(export_path_mac, "R.o.B v1_10Sep23.csv"))

rob <- rob %>%
  clean_names() %>%
  filter(!author == "") %>%
  mutate(across(everything(), ~str_replace_all(.x, "\n", ""))) %>%
  rename(d1 = domain_1_randomisation_process,
         d2 = domain_2_deviations_from_intended_interventions,
         d3 = domain_3_missing_outcome_data,
         d4 = domain_4_measurement_of_outcome,
         d5 = domain_5_selection_of_reported_result,
         overall = overall_r_o_b)

dat <- merge(dat1, rob, by = "author", all.x = TRUE) %>%
  mutate_at(vars(d1:overall), ~as.factor(trimws(.))) %>%
  mutate_at(vars(d1:overall), ~case_when(
    . == "Low" ~ "+",
    . == "High" ~ "x",
    . == "Some concerns" ~ "–",
    TRUE ~ as.character(.)
  )) %>%
  mutate_at(vars(d1:overall), as.factor)

## Delirium incidence outcome
## First, calculate logORs and variance for delirium
dat_del_na_removed <- dat[!is.na(dat$dex_del)&!is.na(dat$control_del),]
IVdat_del_bayesmeta <- escalc(measure="OR", ai=dex_del, bi=dex_no_del, 
                ci=control_del, di=control_no_del, data=dat_del_na_removed, slab=paste(author,year, sep=", "))

IVdat_del_bayesmeta$yi[IVdat_del_bayesmeta$author == "Chitnis"] <- -0.6478209
IVdat_del_bayesmeta$vi[IVdat_del_bayesmeta$author == "Chitnis"] <- 0.4599308^2

IVdat_del_bayesmeta$yi[IVdat_del_bayesmeta$author == "Soh"] <- -1.049854
IVdat_del_bayesmeta$vi[IVdat_del_bayesmeta$author == "Soh"] <- 0.7047859^2
  
## First we need to make sure that any duplicate author names are changed
# Create a new column to store the updated author names
IVdat_del_bayesmeta$author_updated <- IVdat_del_bayesmeta$author

# Identify the rows where the author name is duplicated
duplicated_rows <- duplicated(IVdat_del_bayesmeta$author) | duplicated(IVdat_del_bayesmeta$author, fromLast = TRUE)

# Create a suffix vector for duplicated author names
suffix_vec <- rep("", length(IVdat_del_bayesmeta$author))
suffix_vec[duplicated(IVdat_del_bayesmeta$author)] <- ave(IVdat_del_bayesmeta$author, IVdat_del_bayesmeta$author, FUN = function(x) {
  letters[seq_along(x)]
})

# Add suffixes to the duplicated author names
IVdat_del_bayesmeta$author[duplicated_rows] <- paste0(IVdat_del_bayesmeta$author[duplicated_rows], "_", suffix_vec[duplicated_rows])

IVdat_del <- IVdat_del_bayesmeta %>%
  mutate(sei = sqrt(vi),
         author1 = paste(author, year, sep = " ")) %>%
  mutate(author1 = ifelse(author1 == "Turan 2020", "Turan 2020 (DECADE)", author1)) %>%
  arrange(year)

IVdat_del_low_rob <- IVdat_del %>%
  filter(!overall == "x") 

## Conduct the primary analysis (binary outcomes)
priors_primary <- brms::prior(normal(0,0.82), class = b, coef = "Intercept") +
            brms::prior(cauchy(0,0.5), class = sd)

priors_metareg <- brms::prior(normal(0, 1), class = b, coef = "Intercept") +
            brms::prior(cauchy(0,0.5), class = sd) +
            brms::prior(normal(0,0.82), class = b)

  # Run the brms model
m.brm <- brm(yi | se(sei) ~ 0 + Intercept + (1 | author1),
             data = IVdat_del,
             prior = priors_primary,
              iter = 4000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)

m.brm_excluding_decade <- update(m.brm,
                                 newdata = IVdat_del %>% filter(!author == "Turan"))

m.brm_low_rob_excl_decade <- update(m.brm, newdata = IVdat_del %>% filter(!author == "Turan") %>% filter(overall == "+"))

## Create metaregression models

## Dose timing
m.brm_dose_timing <- update(m.brm, formula. = ~ . + dex_dose_timing, newdata = IVdat_del, prior = priors_metareg)

## control agent
m.brm_control_agent <- update(m.brm, formula. = ~ . + control_agent_clean, newdata = IVdat_del, prior = priors_metareg)

# Secondary outcomes
## First, binary secondary outcomes
## Mortality outcome
dat_mortality_na_removed <- dat[!is.na(dat$dex_mortality)&!is.na(dat$control_mortality),] 

IVdat_mortality <- escalc(measure="OR", ai=dex_mortality, bi=dex_no_mortality, 
                ci=control_mortality, di=control_no_mortality, data=dat_mortality_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " ")) 

m.brm_mortality <- update(m.brm, newdata = IVdat_mortality)

## Bradycardia outcome
dat_bradycardia_na_removed <- dat[!is.na(dat$dex_bradycardia)&!is.na(dat$control_bradycardia),]
IVdat_bradycardia <- escalc(measure="OR", ai=dex_bradycardia, bi=dex_no_bradycardia, 
                ci=control_bradycardia, di=control_no_bradycardia, data=dat_bradycardia_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
                    mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " "))  

m.brm_bradycardia <-  update(m.brm, newdata = IVdat_bradycardia)

## hypotension outcome
dat_hypotension_na_removed <- dat[!is.na(dat$dex_hypotension)&!is.na(dat$control_hypotension),]
IVdat_hypotension <- escalc(measure="OR", ai=dex_hypotension, bi=dex_no_hypotension, 
                ci=control_hypotension, di=control_no_hypotension, data=dat_hypotension_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " ")) 

m.brm_hypotension <-  update(m.brm, newdata = IVdat_hypotension)

## arrythmia outcome
dat_arrhythmia_na_removed <- dat[!is.na(dat$dex_arrhythmia)&!is.na(dat$control_arrhythmia),]
IVdat_arrhythmia <- escalc(measure="OR", ai=dex_arrhythmia, bi=dex_no_arrhythmia, 
                ci=control_arrhythmia, di=control_no_arrhythmia, data=dat_arrhythmia_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " ")) 

m.brm_arrhythmia <-  update(m.brm, newdata = IVdat_arrhythmia)

## Now for continous secondary outcomes
## Need to run these continuous outcomes with much more iterations (50,000 vs 4000) because they're not converging.

## See priors for continuous secondary outcomes
priors_cont <- brms::prior(normal(0,1), class = b, coef = "Intercept") +
            brms::prior(cauchy(0,0.5), class = sd)

## delirium duration outcome
dat_del_duration_na_removed <- dat[!is.na(dat$dex_delirium_duration_days_mean)&!is.na(dat$control_delirium_duration_days_mean)
                                   &!is.na(dat$dex_delirium_duration_days_sd)&!is.na(dat$control_delirium_duration_days_sd),]

IVdat_del_duration <- escalc(measure="MD", m1i=dex_delirium_duration_days_mean, sd1i=dex_delirium_duration_days_sd, n1i = dex_del,
                m2i=control_delirium_duration_days_mean, sd2i=control_delirium_duration_days_sd, n2i = control_del,
                data=dat_del_duration_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " ")) 

  # Run the brms model
m.brm_del_duration <- brm(yi | se(sei) ~ 0 + Intercept + (1 | author1),
             data = IVdat_del_duration,
             prior = priors_cont,
              iter = 50000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)

## time to extubation outcome
dat_extub_time_na_removed <- dat[!is.na(dat$dex_timetoextubation_mean)&!is.na(dat$control_timetoextubation_mean)
                                 &!is.na(dat$dex_timetoextubation_sd)&!is.na(dat$control_timetoextubation_sd),]
IVdat_extub_time <- escalc(measure="MD", m1i=dex_timetoextubation_mean, sd1i=dex_timetoextubation_sd, n1i = dex_n,
                m2i=control_timetoextubation_mean, sd2i=control_timetoextubation_sd, n2i = control_n,
                data=dat_extub_time_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " ")) 

m.brm_extub_time <-  update(m.brm_del_duration, newdata = IVdat_extub_time)

## hospital stay outcome
dat_hosp_stay_na_removed <- dat[!is.na(dat$dex_hospital_days_mean)&!is.na(dat$control_hospital_days_mean)
                                 &!is.na(dat$dex_hospital_days_sd)&!is.na(dat$control_hospital_days_sd),]
IVdat_hosp_stay <- escalc(measure="MD", m1i=dex_hospital_days_mean, sd1i=dex_hospital_days_sd, n1i = dex_n,
                m2i=control_hospital_days_mean, sd2i=control_hospital_days_sd, n2i = control_n,
                data=dat_hosp_stay_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " "))

m.brm_hosp_stay <-  update(m.brm_del_duration, newdata = IVdat_hosp_stay)

## ICU stay outcome
dat_icu_stay_na_removed <- dat[!is.na(dat$dex_icu_days_mean)&!is.na(dat$control_icu_days_mean)
                                 &!is.na(dat$dex_icu_days_sd)&!is.na(dat$control_icu_days_sd),]
IVdat_icu_stay <- escalc(measure="MD", m1i=dex_icu_days_mean, sd1i=dex_icu_days_sd, n1i = dex_n,
                m2i=control_icu_days_mean, sd2i=control_icu_days_sd, n2i = control_n,
                data=dat_icu_stay_na_removed, 
                slab=paste(author,year, sep=", ")) %>%
            mutate(sei = sqrt(vi),
                   author1 = paste(author, year, sep = " "))

m.brm_icu_stay <-  update(m.brm_del_duration, newdata = IVdat_icu_stay)

# Excluding high RoB
m.brm_low_rob <- update(m.brm, newdata = IVdat_del %>% filter(!overall == "x"))

m.brm_excluding_decade_low_rob <- update(m.brm, newdata = IVdat_del %>% filter(!overall == "x", !author == "Turan"))

m.brm_dose_timing_low_rob <-  update(m.brm_dose_timing, newdata = IVdat_del %>% filter(!overall == "x"))
m.brm_control_agent_low_rob <-  update(m.brm_control_agent, newdata = IVdat_del %>% filter(!overall == "x"))


## Now to run the sensitivity analysis models
## Create priors for informative and uniform
informative_priors <- brms::prior(normal(0,0.82), class = Intercept) +
            brms::prior(cauchy(0,0.5), class = sd)

vague_priors <- brms::prior(normal(0,4), class = Intercept) +
            brms::prior(cauchy(0,4), class = sd)

turner_etal_priors <- brms::prior(normal(0,0.82), class = Intercept) +
            brms::prior(lognormal(-2.49,1.52), class = sd)

# Now we need to create a series of functions to avoid repeating code for each subgroup
## First, the brm function

m.brm_informative <- brm(yi | se(sei) ~ 1 + (1 | author1),
               data = IVdat_del,
               prior = informative_priors,
               iter = 4000,
               backend = "cmdstanr", 
               cores = parallel::detectCores(),
                chains = 4,
                seed = 123)

m.brm_vague <- update(m.brm_informative, prior = vague_priors)

m.brm_turneretal <- update(m.brm_informative, prior = turner_etal_priors)

theme_nice <- function() {
  theme_minimal(base_family = "Verdana") +
    theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "Verdana", face = "bold"),
          axis.title = element_text(size = 14),
          axis.text = element_text(size = 12),
          strip.text = element_text(family = "Verdana", face = "bold",
                                    size = rel(0.75), hjust = 0),
          strip.background = element_rect(fill = "grey90", color = NA))
}

# Set the ggplot theme
theme_set(theme_nice())

forest_theme <- theme(axis.text.y = element_blank(),
                      plot.title = ggtext::element_textbox_simple(
                                        margin = margin(t = 0, b = 10),
                                        padding = margin(rep(6, 4)),
                                        fill = "grey90",
                                        linetype = 1,
                                        box.color = "black",
                                        r = unit(9, "pt"),
                                        halign = 0,
                                        face = "bold",
                                        lineheight = .9,
                                        size = 12))

```

# Overall forest plot

Below in @fig-forest-all-studies and @fig-forest-low-rob I show the forest plot of all studies, and excluding studies at high risk of bias, respectively.

For meta-analysis, we will employ a Bayesian normal-normal hierarchical model (NNHM). It is a 'normal-normal' model because we assume on the first level that the within-study effects of each trial are normally distributed, and on the second level that the effects across different populations are normally distributed.

Firstly - let's discuss the within-study normality assumption. In the NNHM we assume that each study's observed effect $\hat{\theta}$ is an estimate of the true effect in that trial population ${\theta}$, and the uncertainty in this estimate is modeled with a normal distribution with mean ${\theta}$ and standard deviation ${\sigma}$:

$$
\hat{\theta} \sim Normal({\theta}, {\sigma}^2)
$$ 

In the above case, the standard deviation $\sigma$ is the trial's standard error. As such, estimates from studies with smaller standard errors will have narrower normal distributions and deviate less from the estimated mean effect $\theta$. The purple lines in the forest plot below show the assumed distribution of within study effects described above.

Secondly - let's discuss the between-population normality assumption. Here, we assume that each study's estimate $\theta$ is an approximation of the overall mean effect across different populations, $\mu$. We assume that this normal distribution with mean $\mu$ has a standard deviation $\tau$. So, the second level of our NNHM takes the form:

$$
\theta \sim Normal(\mu, \tau^2)
$$

In a Bayesian analysis, we know $\theta$ using our estimate $\hat{\theta}$, and we assume that $\sigma$ is known (for which use the study's standard error). We need to put priors on both of these $\mu$ and $\tau$ parameters. For our primary analysis, I have used weakly informative priors. That is, they are meant to impart some information about prior belief of the plausible range of true values, without overwhelming the data.

For $\mu$, the prior is a normal distribution with mean 0 and standard deviation 0.82 (on the log odds ratio scale):

$$
\mu \sim Normal(0, 0.82)
$$

This is a weakly informative prior because it makes values closer to null (logOR = 0) more likely but still leaves room for higher and lower values. With this prior, 95% of the density lies between an odds ratio of 0.2 and 5. This is consistent with logic, and prior evidence: we consider it unlikely that dexmedetomidine is a silver bullet for delirium (80% or greater odds reduction) or a significant driver of delirium (500% or greater odds increase).

Below in @fig-prior-plot-effect, I graph the prior on both the logOR (A) and OR scale (B), to visualise the prior distribution. As you can see, for the distribution to be normal on the odds ratio scale, we need to take the logarithm of the x-axis (C).

```{r}
#| label: fig-prior-plot-effect
#| fig-width: 15
#| fig-height: 9
#| fig-cap: |
#|   Plot of the prior for the mean effect, in A) log odds ratio form with continuous x-axis, B) odds ratio form with continuous x-axis, and C) odds ratio form with log10 x-axis.

mu_prior_plot_log = data.frame(prior = distributional::dist_normal(mean = 0, sd = 0.82))
mu_prior_plot_exp = data.frame(prior = exp(distributional::dist_normal(mean = 0, sd = 0.82)))

mu_log <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
  stat_halfeye(aes(xdist = prior), data = mu_prior_plot_log, fill = "lightblue", color = "black",  inherit.aes = FALSE) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_x_continuous(breaks = c(-2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2), expand = c(0, 0)) +    
  coord_cartesian(xlim=c(-2, 2)) +
  annotate("text", x = -1, y =0.8, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 1, y = 0.8,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Log odds ratio (linear scale)", title = "A") +
  ylab(NULL) +
  guides(alpha = "none")

mu <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
  stat_halfeye(aes(xdist = prior), data = mu_prior_plot_exp, fill = "lightblue", color = "black",  inherit.aes = FALSE) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5, 6), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0, 6)) +
  annotate("text", x = 0.5, y = 0.9, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 1.8, y = 0.9,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Odds ratio (linear scale)", title = "B") +
  ylab(NULL) +
  guides(alpha = "none")

mu_exp <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
  stat_halfeye(aes(xdist = prior), data = mu_prior_plot_exp, fill = "lightblue", color = "black",  inherit.aes = FALSE) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7)) +
  annotate("text", x = 0.2, y = 0.8, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 5, y = 0.8,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Odds ratio (log scale)", title = "C") +
  ylab(NULL) +
  guides(alpha = "none")

grid.arrange(mu_log, mu, mu_exp, ncol = 2)

```

For $\tau$, the prior is a half-Cauchy distribution with scale = 0.5:

$$
\tau \sim HalfCauchy(0.5)
$$

We use a half-Cauchy distribution because this is a heavy tailed distribution that only takes positive values (as we only look at 'half'), which is appropriate for a standard deviation parameter. The 'scale' in a half-Cauchy distribution can be thought of as similar to a standard deviation, as it relates to the gradient of the slope (this isn't technically true because the Cauchy distribution has undefined mean and variance, but is okay for purposes of understanding).

We can show our $\tau \sim HalfCauchy(0.5)$ prior graphically. Somewhat arbitrarily, traditional cutoffs for heterogeneity are: Low ($\tau < 0.1$), reasonable ($0.1 < \tau < 0.5$), fairly high ($0.5 < \tau < 1.0$), and fairly extreme ($\tau > 1.0$). We can present the prior probabilities of each level of heterogeneity graphically, as shown in @fig-prior-plot-hetero below.

As you'll notice, the distribution is heavy-tailed, and as such we leave a high probability for significant heterogeneity. This is consistent with our belief that there is likely quite significant heterogeneity in the response to dexmedetomidine among different populations.

```{r}
#| label: fig-prior-plot-hetero
#| fig-width: 11
#| fig-height: 6
#| fig-cap: |
#|   Plot of the prior for heterogeneity parameter tau, with probabilities of each level of heterogeneity shown.

tau_prior_plot = data.frame(prior = distributional::dist_cauchy(location = 0, scale = 0.5))

tau <- distributional::dist_cauchy(location = 0, scale = 0.5)

data <- rhalfcauchy(n = 1000, scale = 0.5)

ggplot(data = data.frame(x = c(-2, 2)), aes(x)) +
  stat_function(
  fun = dhalfcauchy,
  args = list(scale = 0.5),
  color = "blue",
  size = 1) +
  scale_x_continuous(breaks = c(0, 0.1, 0.5, 1, 1.5, 2), expand = c(0, 0)) +    
  coord_cartesian(xlim=c(0, 2)) +
  geom_vline(xintercept = 0.1, linetype = "dashed") +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.05, y = 0.98, label = "Low", fontface = "bold") +
  annotate("text", x = 0.3, y = 0.98, label = "Reasonable", fontface = "bold") +
  annotate("text", x = 0.75, y = 0.98, label = "Fairly high", fontface = "bold") +
  annotate("text", x = 1.5, y = 0.98, label = "Fairly extreme", fontface = "bold") +
  annotate("text", x = 0.05, y = 0.2, label = paste0(sprintf('%.1f', phalfcauchy(0.1, scale = 0.5)*100), "%"), 
           fontface = "bold") +
  annotate("text", x = 0.3, y = 0.2, label = paste0(sprintf('%.1f', (phalfcauchy(0.5, scale = 0.5)*100 - phalfcauchy(0.1, scale = 0.5)*100)), "%"), 
           fontface = "bold") +
  annotate("text", x = 0.75, y = 0.2, label = paste0(sprintf('%.1f', (phalfcauchy(1, scale = 0.5)*100 - phalfcauchy(0.5, scale = 0.5)*100)), "%"), 
           fontface = "bold") +
  annotate("text", x = 1.5, y = 0.1, label = paste0(sprintf('%.1f', (1 - phalfcauchy(1, scale = 0.5))*100), "%"),
           fontface = "bold") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Log odds ratio") +
  ylab(NULL) +
  guides(alpha = "none")


```

Finally, we will conduct metaregression further below, with more details provided. Nonetheless I will show the priors for the regression coefficient here, for completeness. For the regression coefficient we will use the same priors as we use for the intercept above: $\beta \sim Normal(0, 0.82)$

Putting all these together, we can show the following formulas for our NNHM:

$$\hat{\theta} \sim Normal(\theta, \sigma^2)$$
$$\theta \sim Normal(\mu, \tau^2)$$
$$\mu \sim Normal(0,0.82)$$
$$\tau \sim HalfCauchy(0.5)$$
$$\beta \sim Normal(0,0.82)$$

Before we can run the analysis, we need to consider an important issue: two of the studies were registered after enrollment began (Chitnis et al., Soh et al.), meaning there is a possibility of bias. Rather than outright exclude these studies, it would be better to try and model the suspected bias (thanks to Prof James Brophy for this suggestion). To do this, we will run a stepwise procedure. Let's start with the Chitnis study as an example. 

Firstly, the marginal effect size for Chitnis that we calculate is: OR = 0.43, 95%CI: 0.15 to 1.25. On the logOR scale, this is equivalent to logOR = -0.8341, SE: 0.5376802.

As explained above, in a normal-normal hierarchical model model meta-analysis, we assume that each study's true effect size follows a normal distribution with mean = calculated log odds ratio and SD = calculated standard error. So, we can draw random samples from this assumed distribution using the code:

```{r}
#| echo: true

set.seed(123)

effect_dist <- rnorm(1000, -0.8341, 0.5376802)
head(effect_dist)
```

But these estimates need to be modified due to possible bias arising from registration after enrollment beginning. A study by [Deschartres and colleagues](https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-016-0639-x) showed that there approximately a 19% greater effect size in studies that were unregistered or retrospectively registered (combined ROR = 0.81, 95% CI 0.65–1.02, based on 32 contributing meta-analyses). 

Based on this effect size and confidence interval, we can model the 'inflation' component as a normal distribution with mean 0.82 (corresponding to a 1 - 0.81 = 19% increase in effect) and standard deviation = 0.1:

```{r}
#| echo: true

set.seed(123)

inflation_dist <- rnorm(1000, 0.81, 0.1)
```

We can then multiply this bias adjustment by our assumed distribution of effect sizes from Chitnis, and take the mean and SD of the resulting distribution as the revised effect size and SE. We also need to add a for-loop because we're on the logOR scale, with more negative values implying more benefit, so we need to be sure that 'inflating' the effect size means negative values are made less negative and positive values are made more positive. So, in cases where the value for inflation distribution is <1 and the value for the effect size distribution is positive, then the reciprocal of 'inflation' should be used (e.g., 0.80 becomes 1.25). Similarly, if the value for inflation distribution is >1 and the value for effect size distribution is positive, then the reciprocal of inflation should be used:

```{r}
#| echo: true

set.seed(123)

inflation_dist <- rnorm(1000, 0.81, 0.1)
effect_dist <- rnorm(1000, -0.8341, 0.5376802)

result <- numeric(length = 1000)

# Loop through each pair of values
for (i in 1:1000) {
    # Conditionally modify inflation value
    if (inflation_dist[i] < 1 && effect_dist[i] > 0) {
        inflation_adj <- 1 / inflation_dist[i]
    } else if (inflation_dist[i] > 1 && effect_dist[i] > 0) {
        inflation_adj <- 1 / inflation_dist[i]
    } else {
        inflation_adj <- inflation_dist[i]
    }

    # Perform the multiplication
    result[i] <- inflation_adj * effect_dist[i]
}

mean(result)
sd(result)
```

And for Soh et al., the calculated OR is: OR = 0.26, 95%CI: 0.05 to 1.31. on the logOR scale, this is logOR = -1.347074, SE: 0.8266586.

Applying the same procedure to Soh we get mean and SD:

```{r}
#| echo: true

set.seed(123)

inflation_dist <- rnorm(1000, 0.81, 0.1)
effect_dist <- rnorm(1000, -1.347074, 0.8266586)

result <- numeric(length = 1000)

# Loop through each pair of values
for (i in 1:1000) {
    # Conditionally modify inflation value
    if (inflation_dist[i] < 1 && effect_dist[i] > 0) {
        inflation_adj <- 1 / inflation_dist[i]
    } else if (inflation_dist[i] > 1 && effect_dist[i] > 0) {
        inflation_adj <- 1 / inflation_dist[i]
    } else {
        inflation_adj <- inflation_dist[i]
    }

    # Perform the multiplication
    result[i] <- inflation_adj * effect_dist[i]
}

mean(result)
sd(result)
```

Now for the forest plot.

Firstly, the blue curves show the posterior shrinkage estimates of each study; that is, each study's effect is 'shrunk' towards the mean when viewed in light of the other data. [Kruschke and Liddell](https://link.springer.com/article/10.3758/s13423-016-1221-4) explain this best:

> "Hierarchical models are especially useful because the low-level and high-level parameters are estimated simultaneously and are mutually constraining. When data from many low-level units inform the high-level distribution, the high-level distribution constrains the low-level parameters to be mutually consistent. This causes the more extreme low-level cases to be "shrunken" toward the mode(s) of the group. Shrinkage helps prevent false alarms caused by random conspiracies of rogue outlying data. Essentially, the data from the other individuals are acting as simultaneous prior information to rein in estimates of outlying individuals."

The orange line shows the 95%CrI for the prediction interval: the range of values that would be likely to be observed be a future study of this research question. Note this is different to the *credible interval*, which is the range of plausible values for the **mean** effect size. Prediction intervals are perhaps the best summary of heterogeneity because they provide a practical interpretation: what is the range of plausible values I might observe in different patient populations?

On the right hand side we have the risk of bias assessments for each study: the five domains, and the overall assessment. '+' indicates 'Low risk', '-' indicates 'Some concerns', and 'x' indicates 'High risk'.

::: {#forest-plots .panel-tabset style="colour: pink"}
## All studies

```{r fig.width = 15, fig.height = 10}
#| label: fig-forest-all-studies
#| fig-width: 15
#| fig-height: 10
#| fig-cap: |
#|   Forest plot of all studies.

# Calculate the re-weighted estimated of each study
study.draws <- spread_draws(m.brm, r_author1[author1, ], b_Intercept) %>%
    mutate(b_Intercept = r_author1 + b_Intercept)

  # Establish the pooled result
pooled.effect.draws <- spread_draws(m.brm, b_Intercept) %>%
    mutate(author1 = "Pooled Effect")

  # Combine the pooled result with study estimates, then play around with the lexicon (bmrs mucks this up)
forest.data <- bind_rows(study.draws,
                           pooled.effect.draws) %>%
    ungroup() %>%
    mutate(author1 = str_replace_all(author1, "[.]", " "),
           author1 = reorder(author1, b_Intercept)) 
  
  # Calculate median qi based on author1
forest.data.summary1 <- group_by(forest.data, author1) %>%
    median_qi(b_Intercept) 
  
  # Join the two dataframes based on similar author names
forest.data.summary2 <- forest.data.summary1 %>%
    mutate(author_word = str_extract(author1, "^\\S+")) %>%
    left_join(IVdat_del %>% 
                mutate(author_word = str_extract(author1, "^\\S+")) %>%
                dplyr::select(author1, yi, vi, control_del_rate_frac, dex_del_rate_frac, dex_del,
                       dex_n, control_del, control_n, d1:overall, author_word), 
              by = "author_word") %>%
    dplyr::select(-author_word, -author1.y) %>%
  mutate(across(d1:overall, ~as.character(.))) %>%  # Convert factors to characters
  mutate(across(d1:overall, ~ifelse(is.na(.), "", .))) %>%
    mutate(dex_del_rate_frac = ifelse(author1.x == "Pooled Effect",
                                    paste0(sum(IVdat_del$dex_del), "/", sum(IVdat_del$dex_n)),
                                    dex_del_rate_frac),
         control_del_rate_frac = ifelse(author1.x == "Pooled Effect",
                                        paste0(sum(IVdat_del$control_del), "/", sum(IVdat_del$control_n)),
                                        control_del_rate_frac))
  
forest.data.summary <- forest.data.summary2 %>% 
    rename(author1 = author1.x)

# Create the prediction interval
nd = data.frame(author1 = "new", sei = 0)
  
pred_summ <- brms::posterior_predict(object = m.brm,
                          newdata = nd,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_summ_forest <- data.frame(pred_summ)
names(pred_summ_forest) <- "est"

pred_df <- pred_summ |> 
             data.frame() |>
             ggdist::median_hdi(.width = c(.66, .8, .95)) |>
            rename(coeff = 1)

pred_df$author1 <- as.factor(c("Pooled Effect"))
pred_df <- pred_df[c(7, 1:3)] %>%
  rename(pi_median = coeff,
         pi_lower = .lower,
         pi_upper = .upper)

# Extract tau and 95%CI
tau_posterior = 
    m.brm |> 
    tidybayes::tidy_draws() |> 
    ggdist::median_hdi(sd_author1__Intercept)
  
  ## Create the values for shrinkage and actual effect estimates
res_plot_pre <- forest.data.summary %>%
  mutate(weighted_effect = paste0(sprintf('%.2f', exp(b_Intercept)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'),
         unweighted_effect = paste0(sprintf('%.2f', exp(yi)), 
                  ' [', sprintf('%.2f', exp(yi - 1.96*sqrt(vi))),
                  ', ', sprintf('%.2f', exp(yi + 1.96*sqrt(vi))), ']')) %>%
   mutate(unweighted_effect = ifelse(unweighted_effect == "NA [NA, NA]", 
                                   paste0("τ = ", 
                                          sprintf('%.2f', tau_posterior$sd_author1__Intercept), 
                                          " [", sprintf('%.2f', tau_posterior$.lower), ", ",
                                          sprintf('%.2f', tau_posterior$.upper), "]"),
                                          unweighted_effect)) 


new_row <- data.frame(author1 = as.factor("Study"),
                      weighted_effect = "[95%CrI]",
                      unweighted_effect = "[95%CrI]",
                      dex_del_rate_frac = "Delirium (n/total)",
                      control_del_rate_frac = "Delirium (n/total)",
                      d1 = "D1",
                      d2 = "D2",
                      d3 = "D3",
                      d4 = "D4",
                      d5 = "D5",
                      overall = "Overall")

res_plot <- bind_rows(res_plot_pre, new_row) %>%
          mutate(color = ifelse(author1 == "Pooled Effect", "darkblue", "black"),
                 font = ifelse(author1 == "Pooled Effect", "bold", "plain"))

## Add an extra row to res_plot_control because we need more space at the top
new_row_res_plot <- data.frame(author1 = as.factor(""),
                      weighted_effect = "Shrinkage OR",
                      unweighted_effect = "Observed OR",
                      dex_del_rate_frac = "Dexmedetomidine",
                      control_del_rate_frac = "Control",
                      d1 = "",
                      d2 = "",
                      d3 = "",
                      d4 = "",
                      d5 = "",
                      overall = "",
                      color = "black",
                      font = "plain")

res_plot_overall <- bind_rows(res_plot, new_row_res_plot) %>%
  mutate(across(d1:overall, ~ ifelse(. == "–", "?", ifelse(. == "x", "–", .))))


# Now - plotting!
p_forest_overall <- ggplot(aes(exp(b_Intercept), 
           relevel(author1, "Pooled Effect", after=Inf),  alpha = 0.9), 
       data = forest.data) +
  geom_vline(xintercept = exp(fixef(m.brm)[1, 1]), 
             color = "grey60", size = 1) +
  geom_vline(xintercept = exp(fixef(m.brm)[1, 3:4]), 
             color = "grey60", linetype = 2) +
  geom_vline(xintercept = 1, color = "black", 
             size = 0.7) +
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    stat_slab(aes(xdist = exp(distributional::dist_normal(mean = yi, 
                          sd = sqrt(vi)))),
                      data = forest.data.summary,
              fill = NA, color = "purple",
              slab_linewidth = 0.5, alpha = 0.6) +
    geom_pointinterval(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.3),
                      data = pred_df, 
                      colour = "darkorange",
                      size = 6, alpha = 2) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7), ylim=c(1,15)) +
  annotate("text", x = 0.25, y =14.5, label = "Favours\nDEX") +
  annotate("text", x = 3, y = 14.5,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Odds ratio (log scale)") +
  ylab(NULL) +
  guides(alpha = "none") 

p_estimates_overall <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf), color = color), 
                   data = res_plot_overall) +
  geom_text(aes(x = 0, label = weighted_effect), hjust = 0,
            fontface = ifelse(grepl("Shrinkage OR|\\[95%CrI\\]", res_plot_overall$weighted_effect), "bold", "plain")) +
  geom_text(aes(x = 1, label = unweighted_effect), hjust = 0, 
            fontface = ifelse(grepl("Observed OR|\\[95%CrI\\]", res_plot_overall$unweighted_effect), "bold", "plain")) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 2), ylim=c(1,15))

# Map the fill and color aesthetics to the new column in the ggplot call
p_studies_overall <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf), color = color), 
                          data = res_plot_overall) +
  geom_text(aes(x = 0, label = author1), hjust = 0, 
            fontface = ifelse(res_plot_overall$author1 == "Study", "bold",
                              ifelse(res_plot_overall$author1 == "Pooled Effect", "italic", "plain"))) +
  geom_text(aes(x = 2, label = dex_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_overall$dex_del_rate_frac == "Delirium (n/total)" | res_plot_overall$dex_del_rate_frac == "Dexmedetomidine", "bold", "plain")) +
  geom_text(aes(x = 4, label = control_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_overall$control_del_rate_frac == "Delirium (n/total)" | res_plot_overall$control_del_rate_frac == "Control", "bold", "plain")) +
  scale_color_identity() + # Use the specified colors directly for text color
  theme_void(base_family = "Verdana") +
  forest_theme +
  theme(legend.position = "none") +
  labs(title = "A: Study-level and pooled estimates") +
  coord_cartesian(xlim = c(0, 5.5))

point_col_fn <- function(domain) {
  color <- ifelse(domain == "+", "green",
                  ifelse(domain == "?", "yellow3", 
                         ifelse(domain == "–", "red", "white")))
  return(color)
}

text_col_fn <- function(domain, label) {
  colour <- ifelse(domain == "+", "green",
                   ifelse(domain == "?", "yellow3", 
                          ifelse(domain == "–", "red", 
                                 ifelse(domain == label, "black", "white"))))
  return(colour)
}

vjust_fn <- function(domain) { 
  vjust <- ifelse(res_plot_overall[[domain]] == "+", 0.5,
                    ifelse(res_plot_overall[[domain]] == "?", 0.35, 
                    ifelse(res_plot_overall[[domain]] == "–", 0.35, 0.5)))
  return(vjust)
}

rob_plot <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf)), data = res_plot_overall) +
      geom_point(aes(x = 0, color = point_col_fn(d1)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 0, label = d1, color = text_col_fn(d1, "D1")), hjust = 0.5,
                fontface = ifelse(res_plot_overall$d1 == "D1", "bold", "plain"),
                size = ifelse(res_plot_overall$d1 == "D1", 4, 6)) +
      geom_point(aes(x = 0.5, color = point_col_fn(d2)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 0.5, label = d2, color = text_col_fn(d2, "D2")), 
                hjust = 0.5, vjust = vjust_fn("d2"),
                fontface = ifelse(res_plot_overall$d2 == "D2", "bold", "plain"),
                size = ifelse(res_plot_overall$d2 == "D2", 4, 6)) +
      geom_point(aes(x = 1, color = point_col_fn(d3)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 1, label = d3, color = text_col_fn(d3, "D3")), hjust = 0.5,
                vjust = vjust_fn("d3"),
                fontface = ifelse(res_plot_overall$d3 == "D3", "bold", "plain"),
                size = ifelse(res_plot_overall$d3 == "D3", 4, 6)) +
      geom_point(aes(x = 1.5, color = point_col_fn(d4)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 1.5, label = d4, color = text_col_fn(d4, "D4")), hjust = 0.5,
                vjust = vjust_fn("d4"),
                fontface = ifelse(res_plot_overall$d4 == "D4", "bold", "plain"),
                size = ifelse(res_plot_overall$d4 == "D4", 4, 6)) +
      geom_point(aes(x = 2, color = point_col_fn(d5)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 2, label = d5, color = text_col_fn(d5, "D5")), hjust = 0.5,
                vjust = vjust_fn("d5"),
                fontface = ifelse(res_plot_overall$d5 == "D5", "bold", "plain"),
                size = ifelse(res_plot_overall$d5 == "D5", 4, 6)) +
      geom_point(aes(x = 2.5, color = point_col_fn(overall)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 2.5, label = overall, color = text_col_fn(overall, "Overall")), hjust = 0.5,
                vjust = vjust_fn("overall"),
                fontface = ifelse(res_plot_overall$overall == "Overall", "bold", "plain"),
                size = ifelse(res_plot_overall$overall == "Overall", 4, 6)) +
      scale_color_manual(values = c("black", "green", "red", "white", "yellow3")) +
      theme_void(base_family = "Verdana") +
      forest_theme +
      theme(legend.position = "none") +
      coord_cartesian(xlim = c(0, 3))

post.samples <- as_draws_df(m.brm, c("b_Intercept", "sd_author1__Intercept"))

mu_prior_plot = data.frame(prior = exp(distributional::dist_normal(mean = 0, sd = 0.82)))

mu_df <- m.brm %>%
  spread_draws(b_Intercept) %>%
  median_qi(.width = c(.66, .8, .95))

mu <- ggplot(aes(x = exp(b_Intercept), alpha = 1), data = post.samples) +
  stat_slab(aes(fill = after_stat(level)), color = "darkblue",
                .width = c(.66, .80, .95, 1), position = "dodgejust") +
  scale_fill_brewer(na.translate = FALSE, name = "Probability") +
  geom_pointintervalh(aes(xmin = exp(.lower), 
                          xmax = exp(.upper), 
                          x = exp(b_Intercept)),
                      data = mu_df, 
                      col = "darkblue", alpha = 1) +
  stat_slab(aes(xdist = prior), data = mu_prior_plot, fill = NA, color = "grey",  inherit.aes = FALSE) +
  stat_slab(aes(x = exp(est)), fill = NA, colour = "darkorange", data = pred_summ_forest, alpha = 1) +
  geom_pointinterval(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.035),
                      data = pred_df, 
                      colour = "darkorange",
                      size = 1, alpha = 2) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2,4), expand = c(0, 0)) + 
  ggdist::scale_thickness_shared() +
  coord_cartesian(xlim=c(0.1, 4), ylim = c(0,1)) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.35, y = 0.8, label = "Favours\ndexmedetomidine", family = "Verdana") +
  annotate("text", x = 2, y = 0.8,  label = "Favours\ncontrol", family = "Verdana") +
  annotate("text", x = 2, y = 0.2, label = "Mean effect prior", fontface = "bold", family = "Verdana", colour = "grey30", angle=-8) +
  annotate("text", x = 0.24, y = 0.16, label = "Mean effect\nprediction interval", fontface = "bold", family = "Verdana", colour = "darkorange", angle= 8) +
  annotate("text", x = 0.65, y = 0.98, label = "Mean effect\nposterior", fontface = "bold", family = "Verdana", colour = "darkblue") +
  theme_nice() +
  forest_theme +
  labs(x="Odds ratio (log scale)", title = "B: Posterior for the mean effect") +
  ylab(NULL) +
  guides(alpha = "none")

tau_prior_plot = data.frame(prior = distributional::dist_cauchy(location = 0, scale = 0.5))

tau <- ggplot(aes(x = sd_author1__Intercept, alpha = 1), data = post.samples) +
  stat_slab(aes(fill = after_stat(ifelse(x < 0.1, "Low", ifelse(x < 0.5, "Reasonable",ifelse(x < 1, "Fairly high", "Fairly extreme"))))), position = "dodgejust") +
  stat_pointinterval(.width = c(.66, .8, .95), alpha = 1) +
  stat_slab(aes(xdist = prior), 
                data = tau_prior_plot, fill = NA, color = "grey", inherit.aes = FALSE) +
  ggdist::scale_thickness_shared() +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                                 guide = guide_legend(reverse = TRUE),
                     name = "Heterogeneity") + 
  geom_vline(xintercept = 0.1, linetype = "dashed") +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.05, y = 0.98, label = "Low", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.05, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept < 0.1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.3, y = 0.98, label = "Reasonable", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.3, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >= 0.1 & post.samples$sd_author1__Intercept <= 0.5)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.75, y = 0.98, label = "Fairly high", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.75, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >= 0.5 & post.samples$sd_author1__Intercept <= 1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 1.1, y = 0.98, label = "Fairly\nextreme", fontface = "bold", family = "Verdana") +
  annotate("text", x = 1.1, y = 0.85, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 1, y = 0.1, label = "Heterogeneity prior", fontface = "bold", family = "Verdana", colour = "grey30", angle = -2) +
  scale_x_continuous(breaks = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.2), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0, 1.2), ylim = c(0,1)) +
  theme_nice() +
  forest_theme +
  theme(legend.position = "none") +
  labs(x="Log odds ratio", title = "C: Posterior for heterogeneity") +
  ylab(NULL) +
  guides(alpha = "none")

library(patchwork)

layout <- c(
  patchwork::area(t = 0, l = 0, b = 14, r = 34),
  patchwork::area(t = 0, l = 35.5, b = 14, r = 50), 
  patchwork::area(t = 0, l = 52, b = 14, r = 73),
  patchwork::area(t = 0, l = 73, b = 14, r = 90),
  patchwork::area(t = 16, l = 0, b = 24, r = 42),
  patchwork::area(t = 16, l = 46, b = 24, r = 88))

p_studies_overall + p_forest_overall + p_estimates_overall + rob_plot + mu + tau + plot_layout(design = layout)


```


## Excluding studies at high risk of bias

```{r fig.width: 15, fig.height = 10}
#| label: fig-forest-low-rob
#| fig-width: 15
#| fig-height: 10
#| fig-cap: |
#|   Forest plot excluding studies at high risk of bias.

# Calculate the re-weighted estimated of each study
study.draws <- spread_draws(m.brm_low_rob, r_author1[author1, ], b_Intercept) %>%
    mutate(b_Intercept = r_author1 + b_Intercept)

  # Establish the pooled result
pooled.effect.draws <- spread_draws(m.brm_low_rob, b_Intercept) %>%
    mutate(author1 = "Pooled Effect")

  # Combine the pooled result with study estimates, then play around with the lexicon (bmrs mucks this up)
forest.data <- bind_rows(study.draws,
                           pooled.effect.draws) %>%
    ungroup() %>%
    mutate(author1 = str_replace_all(author1, "[.]", " "),
           author1 = reorder(author1, b_Intercept)) 
  
  # Calculate median qi based on author1
forest.data.summary1 <- group_by(forest.data, author1) %>%
    median_qi(b_Intercept) 
  
  # Join the two dataframes based on similar author names
forest.data.summary2 <- forest.data.summary1 %>%
    mutate(author_word = str_extract(author1, "^\\S+")) %>%
    left_join(IVdat_del %>% 
                mutate(author_word = str_extract(author1, "^\\S+")) %>%
                dplyr::select(author1, yi, vi, control_del_rate_frac, dex_del_rate_frac, dex_del,
                       dex_n, control_del, control_n, d1:overall, author_word), 
              by = "author_word") %>%
    dplyr::select(-author_word, -author1.y) %>%
  mutate(across(d1:overall, ~as.character(.))) %>%  # Convert factors to characters
  mutate(across(d1:overall, ~ifelse(is.na(.), "", .))) %>%
    mutate(dex_del_rate_frac = ifelse(author1.x == "Pooled Effect",
                                    paste0(sum(IVdat_del$dex_del), "/", sum(IVdat_del$dex_n)),
                                    dex_del_rate_frac),
         control_del_rate_frac = ifelse(author1.x == "Pooled Effect",
                                        paste0(sum(IVdat_del$control_del), "/", sum(IVdat_del$control_n)),
                                        control_del_rate_frac))
  
forest.data.summary <- forest.data.summary2 %>% 
    rename(author1 = author1.x)

# Create the prediction interval
nd = data.frame(author1 = "new", sei = 0)
  
pred_summ <- brms::posterior_predict(object = m.brm_low_rob,
                          newdata = nd,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_summ_forest <- data.frame(pred_summ)
names(pred_summ_forest) <- "est"

pred_df <- pred_summ |> 
             data.frame() |>
             ggdist::median_hdi(.width = c(.66, .8, .95)) |>
            rename(coeff = 1)

pred_df$author1 <- as.factor(c("Pooled Effect"))
pred_df <- pred_df[c(7, 1:3)] %>%
  rename(pi_median = coeff,
         pi_lower = .lower,
         pi_upper = .upper)

# Extract tau and 95%CI
tau_posterior = 
    m.brm_low_rob |> 
    tidybayes::tidy_draws() |> 
    ggdist::median_hdi(sd_author1__Intercept)
  
  ## Create the values for shrinkage and actual effect estimates
res_plot_pre <- forest.data.summary %>%
  mutate(weighted_effect = paste0(sprintf('%.2f', exp(b_Intercept)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'),
         unweighted_effect = paste0(sprintf('%.2f', exp(yi)), 
                  ' [', sprintf('%.2f', exp(yi - 1.96*sqrt(vi))),
                  ', ', sprintf('%.2f', exp(yi + 1.96*sqrt(vi))), ']')) %>%
   mutate(unweighted_effect = ifelse(unweighted_effect == "NA [NA, NA]", 
                                   paste0("τ = ", 
                                          sprintf('%.2f', tau_posterior$sd_author1__Intercept), 
                                          " [", sprintf('%.2f', tau_posterior$.lower), ", ",
                                          sprintf('%.2f', tau_posterior$.upper), "]"),
                                          unweighted_effect)) 


new_row <- data.frame(author1 = as.factor("Study"),
                      weighted_effect = "[95%CrI]",
                      unweighted_effect = "[95%CrI]",
                      dex_del_rate_frac = "Delirium (n/total)",
                      control_del_rate_frac = "Delirium (n/total)",
                      d1 = "D1",
                      d2 = "D2",
                      d3 = "D3",
                      d4 = "D4",
                      d5 = "D5",
                      overall = "Overall")

res_plot <- bind_rows(res_plot_pre, new_row) %>%
          mutate(color = ifelse(author1 == "Pooled Effect", "darkblue", "black"),
                 font = ifelse(author1 == "Pooled Effect", "bold", "plain"))

## Add an extra row to res_plot_control because we need more space at the top
new_row_res_plot <- data.frame(author1 = as.factor(""),
                      weighted_effect = "Shrinkage OR",
                      unweighted_effect = "Observed OR",
                      dex_del_rate_frac = "Dexmedetomidine",
                      control_del_rate_frac = "Control",
                      d1 = "",
                      d2 = "",
                      d3 = "",
                      d4 = "",
                      d5 = "",
                      overall = "",
                      color = "black",
                      font = "plain")


res_plot_overall <- bind_rows(res_plot, new_row_res_plot) %>%
  mutate(across(d1:overall, ~ ifelse(. == "–", "?", .)))

# Now - plotting!
p_forest_overall <- ggplot(aes(exp(b_Intercept), 
           relevel(author1, "Pooled Effect", after=Inf),  alpha = 0.9), 
       data = forest.data) +
  # Add vertical lines for pooled effect and CI
  geom_vline(xintercept = exp(fixef(m.brm_low_rob)[1, 1]), 
             color = "grey60", size = 1) +
  geom_vline(xintercept = exp(fixef(m.brm_low_rob)[1, 3:4]), 
             color = "grey60", linetype = 2) +
  geom_vline(xintercept = 1, color = "black", 
             size = 0.7) +
  # Add densities
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    stat_slab(aes(xdist = exp(distributional::dist_normal(mean = yi, 
                          sd = sqrt(vi)))),
                      data = forest.data.summary,
              fill = NA, color = "purple",
              slab_linewidth = 0.5, alpha = 0.6) +
    geom_pointinterval(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.3),
                      data = pred_df, 
                      colour = "darkorange",
                      size = 6, alpha = 2) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7), ylim=c(1,13)) +
  annotate("text", x = 0.25, y =12.5, label = "Favours\nDEX") +
  annotate("text", x = 3, y = 12.5,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Odds ratio (log scale)") +
  ylab(NULL) +
  guides(alpha = "none") 

p_estimates_overall <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf), color = color), 
                   data = res_plot_overall) +
  geom_text(aes(x = 0, label = weighted_effect), hjust = 0,
            fontface = ifelse(grepl("Shrinkage OR|\\[95%CrI\\]", res_plot_overall$weighted_effect), "bold", "plain")) +
  geom_text(aes(x = 1, label = unweighted_effect), hjust = 0, 
            fontface = ifelse(grepl("Observed OR|\\[95%CrI\\]", res_plot_overall$unweighted_effect), "bold", "plain")) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 2), ylim=c(1,13))

# Map the fill and color aesthetics to the new column in the ggplot call
p_studies_overall <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf), color = color), 
                          data = res_plot_overall) +
  geom_text(aes(x = 0, label = author1), hjust = 0, 
            fontface = ifelse(res_plot_overall$author1 == "Study", "bold",
                              ifelse(res_plot_overall$author1 == "Pooled Effect", "italic", "plain"))) +
  geom_text(aes(x = 2, label = dex_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_overall$dex_del_rate_frac == "Delirium (n/total)" | res_plot_overall$dex_del_rate_frac == "Dexmedetomidine", "bold", "plain")) +
  geom_text(aes(x = 4, label = control_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_overall$control_del_rate_frac == "Delirium (n/total)" | res_plot_overall$control_del_rate_frac == "Control", "bold", "plain")) +
  scale_color_identity() + # Use the specified colors directly for text color
  theme_void(base_family = "Verdana") +
  forest_theme +
  theme(legend.position = "none") +
  labs(title = "A: Study-level and pooled estimates") +
  coord_cartesian(xlim = c(0, 5.5))

point_col_fn <- function(domain) {
  color <- ifelse(domain == "+", "green",
                  ifelse(domain == "?", "yellow3", "white"))
  return(color)
}

text_col_fn <- function(domain, label) {
  colour <- ifelse(domain == "+", "green",
                   ifelse(domain == "?", "yellow3", 
                                 ifelse(domain == label, "black", "white")))
  return(colour)
}

vjust_fn <- function(domain) { 
  vjust <- ifelse(res_plot_overall[[domain]] == "+", 0.5,
                    ifelse(res_plot_overall[[domain]] == "?", 0.35, 
                    ifelse(res_plot_overall[[domain]] == "–", 0.35, 0.5)))
  return(vjust)
}

rob_plot <- ggplot(aes(y = relevel(author1, "Pooled Effect", after=Inf)), data = res_plot_overall) +
      geom_point(aes(x = 0, color = point_col_fn(d1)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 0, label = d1, color = text_col_fn(d1, "D1")), hjust = 0.5,
                fontface = ifelse(res_plot_overall$d1 == "D1", "bold", "plain"),
                size = ifelse(res_plot_overall$d1 == "D1", 4, 6)) +
      geom_point(aes(x = 0.5, color = point_col_fn(d2)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 0.5, label = d2, color = text_col_fn(d2, "D2")), 
                hjust = 0.5, vjust = vjust_fn("d2"),
                fontface = ifelse(res_plot_overall$d2 == "D2", "bold", "plain"),
                size = ifelse(res_plot_overall$d2 == "D2", 4, 6)) +
      geom_point(aes(x = 1, color = point_col_fn(d3)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 1, label = d3, color = text_col_fn(d3, "D3")), hjust = 0.5,
                vjust = vjust_fn("d3"),
                fontface = ifelse(res_plot_overall$d3 == "D3", "bold", "plain"),
                size = ifelse(res_plot_overall$d3 == "D3", 4, 6)) +
      geom_point(aes(x = 1.5, color = point_col_fn(d4)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 1.5, label = d4, color = text_col_fn(d4, "D4")), hjust = 0.5,
                vjust = vjust_fn("d4"),
                fontface = ifelse(res_plot_overall$d4 == "D4", "bold", "plain"),
                size = ifelse(res_plot_overall$d4 == "D4", 4, 6)) +
      geom_point(aes(x = 2, color = point_col_fn(d5)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 2, label = d5, color = text_col_fn(d5, "D5")), hjust = 0.5,
                vjust = vjust_fn("d5"),
                fontface = ifelse(res_plot_overall$d5 == "D5", "bold", "plain"),
                size = ifelse(res_plot_overall$d5 == "D5", 4, 6)) +
      geom_point(aes(x = 2.5, color = point_col_fn(overall)),
                 size = 8, shape = 21, fill = "white", hjust = 0.5) +
      geom_text(aes(x = 2.5, label = overall, color = text_col_fn(overall, "Overall")), hjust = 0.5,
                vjust = vjust_fn("overall"),
                fontface = ifelse(res_plot_overall$overall == "Overall", "bold", "plain"),
                size = ifelse(res_plot_overall$overall == "Overall", 4, 6)) +
      scale_color_manual(values = c("black", "green", "white", "yellow3")) +
      theme_void(base_family = "Verdana") +
      forest_theme +
      theme(legend.position = "none") +
      labs(title = "B: RoB assessments") +
      coord_cartesian(xlim = c(0, 3))

post.samples <- as_draws_df(m.brm_low_rob, c("b_Intercept", "sd_author1__Intercept"))

mu_prior_plot = data.frame(prior = exp(distributional::dist_normal(mean = 0, sd = 0.82)))

mu_df <- m.brm_low_rob %>%
  spread_draws(b_Intercept) %>%
  median_qi(.width = c(.66, .8, .95))

mu <- ggplot(aes(x = exp(b_Intercept), alpha = 1), data = post.samples) +
  stat_slab(aes(fill = after_stat(level)),
                .width = c(.66, .80, .95, 1), position = "dodgejust") +
  scale_fill_brewer(na.translate = FALSE, name = "Probability") +
  geom_pointintervalh(aes(xmin = exp(.lower), 
                          xmax = exp(.upper), 
                          x = exp(b_Intercept)),
                      data = mu_df, 
                      col = "black", alpha = 1) +
  stat_slab(aes(x = exp(est)), fill = NA, colour = "darkorange", data = pred_summ_forest, alpha = 1) +
  stat_slab(aes(xdist = prior), data = mu_prior_plot, fill = NA, color = "grey",  inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.25, 0.5, 1, 2,4), expand = c(0, 0)) + 
  ggdist::scale_thickness_shared() +
  coord_cartesian(xlim=c(0.25, 4), ylim = c(0,1)) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.35, y = 0.8, label = "Favours\ndexmedetomidine", family = "Verdana") +
  annotate("text", x = 2, y = 0.8,  label = "Favours\ncontrol", family = "Verdana") +
  annotate("text", x = 2, y = 0.2, label = "Mean effect prior", fontface = "bold", family = "Verdana", colour = "grey30", angle=-8) +
  theme_nice() +
  forest_theme +
  labs(x="Odds ratio (log scale)", title = "C: Posterior for the mean effect") +
  ylab(NULL) +
  guides(alpha = "none")

tau_prior_plot = data.frame(prior = distributional::dist_cauchy(location = 0, scale = 0.5))

tau <- ggplot(aes(x = sd_author1__Intercept, alpha = 1), data = post.samples) +
  stat_slab(aes(fill = after_stat(ifelse(x < 0.1, "Low", ifelse(x < 0.5, "Reasonable",ifelse(x < 1, "Fairly high", "Fairly extreme"))))), position = "dodgejust") +
  stat_pointinterval(.width = c(.66, .8, .95), alpha = 1) +
  stat_slab(aes(xdist = prior), 
                data = tau_prior_plot, fill = NA, color = "grey", inherit.aes = FALSE) +
  ggdist::scale_thickness_shared() +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                                 guide = guide_legend(reverse = TRUE),
                     name = "Heterogeneity") + 
  geom_vline(xintercept = 0.1, linetype = "dashed") +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  geom_vline(xintercept = 1, linetype = "dashed") +
  annotate("text", x = 0.05, y = 0.98, label = "Low", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.05, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept < 0.1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.3, y = 0.98, label = "Reasonable", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.3, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >= 0.1 & post.samples$sd_author1__Intercept <= 0.5)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.75, y = 0.98, label = "Fairly high", fontface = "bold", family = "Verdana") +
  annotate("text", x = 0.75, y = 0.90, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >= 0.5 & post.samples$sd_author1__Intercept <= 1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 1.1, y = 0.98, label = "Fairly\nextreme", fontface = "bold", family = "Verdana") +
  annotate("text", x = 1.1, y = 0.85, label = paste0(sprintf('%.1f', 100*mean(post.samples$sd_author1__Intercept >1)), "%"),
           fontface = "bold", family = "Verdana") +
  annotate("text", x = 1, y = 0.1, label = "Heterogeneity prior", fontface = "bold", family = "Verdana", colour = "grey30", angle = -2) +
  scale_x_continuous(breaks = c(0, 0.1, 0.25, 0.5, 0.75, 1, 1.2), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0, 1.2), ylim = c(0,1)) +
  theme_nice() +
  forest_theme +
  theme(legend.position = "none") +
  labs(x="Log odds ratio", title = "D: Posterior for heterogeneity") +
  ylab(NULL) +
  guides(alpha = "none")

library(patchwork)

layout <- c(
  patchwork::area(t = 0, l = 0, b = 14, r = 34),
  patchwork::area(t = 0, l = 35.5, b = 14, r = 50), 
  patchwork::area(t = 0, l = 52, b = 14, r = 73),
  patchwork::area(t = 0, l = 73, b = 14, r = 90),
  patchwork::area(t = 16, l = 0, b = 24, r = 42),
  patchwork::area(t = 16, l = 46, b = 24, r = 88))

p_studies_overall + p_forest_overall + p_estimates_overall + rob_plot + mu + tau + plot_layout(design = layout)

```
:::

# Probability of benefit calculations

Now to calculate the probability of dexmedetomidine having certain effect sizes. In order to do this we need to transform the odds ratio into an interpretable effect size: the absolute risk reduction (ARR), or risk difference.

To go from the OR ➜ ARR, you must first use the OR to calculate the risk in the treatment group (R~t~), as shown in @eq-1.

$$
R_t = \frac{R_c \times OR}{R_c(OR - 1) + 1}
$$ {#eq-1}

Where R~t~ is the risk in the treatment group and R~c~ is the risk in the control group. For R~c~, we use the median control group rate across all studies, with a different median rate for each subgroup.

The overall median delirium rate is: `r paste0(sprintf("%.1f", median(IVdat_del$control_del_rate*100)), "%")`

We are consider a SMD of 0.1 (equivalent to a logOR of |0.18|) to be the MCID. So assuming the above control group rate, and an OR of $exp(-0.18) = 0.84$ to be the MCID for benefit and an OR of $exp(0.18) = 1.20$ for harm, we can say that the R~t~ with the MCID for benefit will be:

$$
R_t = \frac{0.16 \times 0.84}{0.16(0.84 - 1) + 1} = 0.137
$$
And the R~t~ for harm will be:

$$
R_t = \frac{0.16 \times 1.20}{0.16(1.20 - 1) + 1} = 0.185
$$
Then, we can calculate the risk difference (R~d~) in @eq-2:

$$
R_d = R_t - R_c
$$ {#eq-2}

The typical workflow is all well and good but we can't use it for our purposes. What we need is to calculate the required odds ratio for a given ARR and then estimate the probability of our data suggesting the odds ratio is greater or lower than that value.

So we rearrange @eq-1 to obtain @eq-4:

$$
OR = \frac{R_t(R_c - 1)}{R_c(R_t - 1))}
$$ {#eq-4}

We are able to calculate R~t~ in the equation above using @eq-5:

$$
R_t = R_c - R_d
$$ {#eq-5}

These calculations are shown below in @tbl-benefit-probs-all, with tabs for all studies.

```{r}
#| label: tbl-benefit-probs-all
#| tbl-cap: Probability of various ARRs, including all studies

Rc_overall <- median(IVdat_del$control_del_rate)
rt_mcid <- (median(IVdat_del$control_del_rate)*exp(-0.18))/(median(IVdat_del$control_del_rate)*(exp(-0.18)-1) + 1)

rd_mcid <- Rc_overall - rt_mcid

arr_mcid_or_overall <- (rt_mcid*(Rc_overall - 1))/(Rc_overall*(rt_mcid - 1))

probs_overall = 
  m.brm |> 
  tidy_draws() |> 
  summarise(any_benefit_overall = 100*mean(b_Intercept < log(1)),
            rrr_mcid_overall = 100*mean(b_Intercept < log(arr_mcid_or_overall)))

# Intraoop
probs_intraop = 
  spread_draws(m.brm_dose_timing, b_Intercept) %>%
  summarise(any_benefit_intraop = 100*mean(b_Intercept < log(1)),
            rrr_mcid_intraop = 100*mean(b_Intercept < log(arr_mcid_or_overall)))

# Intraoop and postop
probs_intraop_postop = 
  spread_draws(m.brm_dose_timing, b_Intercept, b_dex_dose_timingintraop_and_postop) %>%
  mutate(b_dex_dose_timingintraop_and_postop = b_Intercept + b_dex_dose_timingintraop_and_postop) %>% 
  summarise(any_benefit_intraop_postop = 100*mean(b_dex_dose_timingintraop_and_postop < log(1)),
            rrr_mcid_intraop_postop = 100*mean(b_dex_dose_timingintraop_and_postop < log(arr_mcid_or_overall)))

# postop
probs_postop = 
  spread_draws(m.brm_dose_timing, b_Intercept, b_dex_dose_timingpostop) %>%
  mutate(b_dex_dose_timingpostop = b_Intercept + b_dex_dose_timingpostop) %>% 
  summarise(any_benefit_postop = 100*mean(b_dex_dose_timingpostop < log(1)),
            rrr_mcid_postop = 100*mean(b_dex_dose_timingpostop < log(arr_mcid_or_overall)))

# morphine
probs_morphine = 
  spread_draws(m.brm_control_agent, b_Intercept) %>%
  summarise(any_benefit_intraop = 100*mean(b_Intercept < log(1)),
            rrr_mcid_intraop = 100*mean(b_Intercept < log(arr_mcid_or_overall)))

# saline
probs_saline = 
  spread_draws(m.brm_control_agent, b_Intercept, b_control_agent_cleanNormalsaline) %>%
  mutate(b_control_agent_cleanNormalsaline = b_Intercept + b_control_agent_cleanNormalsaline) %>% 
  summarise(any_benefit_intraop_postop = 100*mean(b_control_agent_cleanNormalsaline < log(1)),
            rrr_mcid_intraop_postop = 100*mean(b_control_agent_cleanNormalsaline < log(arr_mcid_or_overall)))

# propofol
probs_propofol = 
  spread_draws(m.brm_control_agent, b_Intercept, b_control_agent_cleanPropofol) %>%
  mutate(b_control_agent_cleanPropofol = b_Intercept + b_control_agent_cleanPropofol) %>% 
  summarise(any_benefit_postop = 100*mean(b_control_agent_cleanPropofol < log(1)),
            rrr_mcid_postop = 100*mean(b_control_agent_cleanPropofol < log(arr_mcid_or_overall)))

prob_tbl1 <- as.data.frame(rbind("Overall" = c("Overall", "Overall", Rc_overall, probs_overall),
     "Intraoperative" = c("Intraoperative", "Dose timing", Rc_overall, probs_intraop),
     "Intraoperative + postoperative" = c("Intraoperative + postoperative", "Dose timing", Rc_overall, probs_intraop_postop),
     "Postoperative" = c("Postoperative", "Dose timing", Rc_overall, probs_postop),
     "Morphine" = c("Morphine", "Control agent", Rc_overall, probs_morphine),
     "Normal saline" = c("Normal saline", "Control agent", Rc_overall, probs_saline),
     "Propofol" = c("Propofol", "Control agent", Rc_overall, probs_propofol))) %>%
  mutate_at(vars(3:5), as.numeric) %>%
  rename(`Subgroup` = V1,
         `group` = V2,
          `median_rate` = V3) %>%
  mutate(`median_rate` = `median_rate` * 100) %>%
  mutate_at(vars(3:5), ~sprintf("%.1f", .))

colnames(prob_tbl1) <- c("Subgroup", "Group", "Median control group rate (%)", "Probability of any benefit (%)", 
                         paste0("Probability of ARR >MCID (", sprintf("%.1f", rd_mcid*100), "%)"))

tab <- prob_tbl1 %>%
  gt(rowname_col = "Subgroup", groupname_col = "Group") %>%
  tab_footnote(footnote = "Calculated by converting our specified MCID of a standardised mean difference of 0.1 to a log odds ratio (logOR = 0.18), then combining this with the specified control group rate of 16% to obtain the required ARR",
               locations = cells_column_labels(columns = starts_with("Probability of ARR")))

tab %>% 
  gt::gtsave(., "prob_arrs_overall.rtf")

tab
```

# Sensitivity using other priors

Now to see if our results are sensitive to the choice of prior for 𝝁 and 𝛕.

@tbl-prior-sensitivity below shows the results using three different sets of priors. First is the informative prior, which is the prior we used for our primary analysis in @fig-forest-all-studies:

$${\mu} ∽ Normal(0, 0.82)$$
$${\tau} ∽ HalfCauchy(0.5)$$


The second is the vague prior, which essentially imparts no information on the posterior estimate.: 

$${\mu} ∽ Normal(0, 4)$$
$${\tau} ∽ HalfCauchy(4)$$

Finally, we have the `Turner et al.` prior. Basically, in 2015 a bunch of people got together and calculated a long list of possible priors for ${\tau}$ depending on the outcome you're looking at and the type of intervention. We're looking at 'pharmacological vs. placebo/control' and the outcome type closet to our purpose is 'infection/onset of new disease'. For this, Turner et al. recommend the prior: ${\tau} \sim Lognormal(-2.49, 1.51)$. For the mean effect we will use the weakly informative prior ${\mu} \sim Normal(0, 0.82)$. So this gives us:

$${\mu} \sim Normal(0, 0.82)$$
$${\tau} \sim Lognormal(-2.49, 1.51)$$

As you can see below in @tbl-prior-sensitivity, the choice of prior doesn't really make a difference.

```{r}
#| label: tbl-prior-sensitivity
#| tbl-cap: Sensitivity analysis using weakly informative, vague, and Turner et al. priors for this meta-analysis. 

# First make a function to extract 95% CrI's
CrI <- function(model){
  model |> 
    brms::fixef(summary = F) |>
    ggdist::median_hdi() |>
    mutate(estimate = paste0(sprintf('%.2f', exp(y)), 
                  ' [', sprintf('%.2f', exp(ymin)),
                  ', ', sprintf('%.2f', exp(ymax)), ']')) |>
    dplyr::select(estimate)
}

## The create a function for prediction intervals:

predictions = function(model){
  
  nd = data.frame(author1 = "new", sei = 0)
  
  set.seed(123)
  
  brms::posterior_predict(object = model,
                          newdata = nd,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") |> 
    data.frame() |>
    ggdist::median_hdi() |> 
    rename(y = 1) |>
    mutate(estimate = paste0(sprintf('%.2f', exp(y)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']')) |>
    dplyr::select(estimate)
}

## Create a function for tau
#Create the text for tau
tau_text <- function(model) {
  
  posterior = 
    model |> 
    tidybayes::tidy_draws() |> 
    ggdist::median_hdi(sd_author1__Intercept) |>
    mutate(estimate = paste0(sprintf('%.2f', sd_author1__Intercept), 
                  ' [', sprintf('%.2f', .lower),
                  ', ', sprintf('%.2f', .upper), ']')) |>
    dplyr::select(estimate)
}


inform_row <- cbind(CrI(m.brm_informative), predictions(m.brm_informative), tau_text(m.brm_informative))
vague_row <- cbind(CrI(m.brm_vague), predictions(m.brm_vague), tau_text(m.brm_vague))
turneretal_row <- cbind(CrI(m.brm_turneretal), predictions(m.brm_turneretal), tau_text(m.brm_turneretal))

combined_tbl <- rbind(inform_row, vague_row, turneretal_row)

## Put row names in (corresponding to each model)
combined_tbl$model <- c("Informative",  "Vague", "Turner et al.")

## rearrange table to put models as first row
combined_tbl <- combined_tbl[c(4, 1:3)]

## Combine the dataframe into a gt()
 tab <- combined_tbl %>%
              gt(rowname_col = "model") %>%
              tab_stubhead(label = "Statistical Model") %>%
              cols_label(
                estimate = "Odds ratio (median [95%CrI])",
                estimate.1 = "Odds ratio (median [95%CrI])",
                estimate.2 = "Median [95%CrI])") %>%
              tab_spanner(
                label = "\u03C4",
                columns = estimate.2) %>%
              tab_spanner(
                label = "Credible interval",
                columns = estimate) %>%
              tab_spanner(
                label = "Prediction interval",
                columns = estimate.1) %>%
              tab_footnote(
                footnote = paste0("\u03BC prior: ", informative_priors$prior[[1]], "; \u03C4 prior: ", informative_priors$prior[[2]]),
                locations = cells_stub(rows = model == "Informative"),
                placement = "right") %>%
              tab_footnote(
                footnote = paste0("\u03BC prior: ", vague_priors$prior[[1]], "; \u03C4 prior: ", vague_priors$prior[[2]]),
                locations = cells_stub(rows = model == "Vague"),
                placement = "right") %>%
              tab_footnote(
                footnote = paste0("\u03BC prior: ", turner_etal_priors$prior[[1]], "; \u03C4 prior: ", turner_etal_priors$prior[[2]]),
                locations = cells_stub(rows = model == "Turner et al."),
                placement = "right") %>%
              opt_footnote_marks(
                marks = "standard")
 
 tab %>% 
  gt::gtsave(., "priors_sensitivity.rtf")

tab
```

# Bayesian re-analysis of DECADE

Now to re-analyse the findings of the DECADE trial. Below is an overview of what we will do in this section:

1.  Calculate priors and the minimum clinically important difference (MCID) for the DECADE trial. For priors, we will use reference and data-derived priors. Reference priors are based on possible attitudes towards this research question, and are guided by the MCID. The MCID is the minimum absolute log odds ratio above which we would consider an effect to be 'meaningful.' Data-derived priors are obtained from the meta-analysis excluding the DECADE trial.

2.  Calculate the probabilities of any benefit or harm of dexmedetomidine in the DECADE trial, and effects exceeding the MCID, using the priors in step 1.

3.  Present and compare empirical cumulative distribution function (ECDF) curves for A) the meta-analysis including all studies, B) the meta-analysis excluding the DECADE trial, C) the DECADE trial alone, and D) the shrinkage estimate of the DECADE trial.

4.  Calculate the average treatment effect (ATE) (in the form of a risk difference and credible interval) from the DECADE trial using the priors in step 1.

For our re-analysis we will use the `brms` package to perform logistic regression (outcome: `delirium`, predictor: `group`).

::: callout-note
They additionally control for cardiac history in the DECADE trial (given this was 'unmatched' at baseline between the two groups as per their definition of 'unmatched') but we do not have these data, so we can't do this. The effect on the results appears minimal.
:::

A logit-binomial regression model is used: binomial family with logit link function. The output of this analysis is a log odds ratio - which is convenient for us, because the output of our meta-analysis is a log odds ratio, meaning we don't have to do any interim conversions. Turan et al. report relative risks with the log link function in their GLM but this is not really best practice. See [Doi et al.'s 2022 paper](https://www.jclinepi.com/article/S0895-4356(21)00241-9/fulltext). For our purposes it's appropriate to use odds ratios, especially because the odds ratio is transportable across different baseline risks (unlike the RR). However, note that this particular assertion, championed by Suhail Doi, is controversial ([see this long, heated argument](https://discourse.datamethods.org/t/should-one-derive-risk-difference-from-the-odds-ratio/4403)). 

We need to consider priors for the 'group' coefficient for the logistic regression.

::: callout-note
You'll notice there is a discrepancy between the prior family and the likelihood family; our prior is a normal distribution but the regression family uses a binomial (or Bernoulli) distribution. The normal distribution should approximate the binomial distribution with 794 data points, so it's appropriate that we use normally distributed priors.
:::

There are two approaches to informative priors here: reference priors, and data-derived priors. For these analyses I borrow various ideas from [Albuquerque and Brophy](https://www.sciencedirect.com/science/article/pii/S016752732200328X#f0015), [Zampieri et al.](https://ccforum.biomedcentral.com/articles/10.1186/s13054-022-04120-y#Sec12), [Goligher et al.](https://jamanetwork.com/journals/jama/article-abstract/2709620), and [Andersen-Ranberg et al](https://pubmed.ncbi.nlm.nih.gov/36971791/).

First, the data-derived priors.

Here, we run a Bayesian meta-analysis excluding the DECADE trial. We use a weakly informative prior for the mean effect, ${\mu}$, which is a normal distribution with mean 0 and standard deviation 0.82: $Normal(0, 0.82)$. We also use a weakly informative prior for heterogeneity SD, ${\tau}$, which is a half-Cauchy distribution with a 0.5 scale parameter: $HalfCauchy(0.5)$. These are the exact same priors we used for the primary analysis in @fig-forest-all-studies.

The code below is for the meta-analysis. It's the same code that is used for all the other meta-analytic models in this document. `IVdat_del` is an `escalc()` object with effect sizes and variances for studies in the meta-analysis, excluding the DECADE trial.

``` r
priors_meta_analysis <- brms::prior(normal(0,0.82), class = b, coef = "Intercept") +
                        brms::prior(cauchy(0,0.5), class = sd)
            
meta_analysis_brm <- brms::brm(yi | se(sei) ~ 0 + Intercept + (1 | author1),
              data = IVdat_del,
              prior = priors_meta_analysis,
              iter = 4000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)
```

As discussed above, the normal-normal hierarchical model for meta-analysis (which we are using here) assumes that each individual study's effects are normally distributed (the first 'normal'), but also that the overall effects across different populations follows a normal distribution with mean ${\mu}$ and standard deviation ${\tau}$ (the second 'normal'). This has the notation: $N({\mu}, {\tau}^2)$. This is why ${\tau}$ is a measure of heterogeneity; it quantifies variability in effects across patient populations.

Now, what we have done below is make the prior for the `treatment` coefficient in logistic regression for the DECADE trial a normal distribution with mean $\mu$ and standard deviation $\tau$ (both obtained from the meta-analysis (MA)):

$$
\beta_\text{treatment} \sim Normal(\mu_\text{MA}, {\tau}^2_\text{MA})
$$

We set the Intercept prior (the odds of delirium when all predictor variables are held at their reference value) to $N(0, 1)$.

So the logistic regression model for DECADE's results that I call in `brms` is as follows:

``` r
priors_regression <- brms::prior(normal(𝛍,𝛕), coef = "groupdexmedetomidine") +
                     brms::prior(normal(0,1), class = b)

logstic_regression.brm <- brms::brm(delirium ~ 0 + Intercept + group,
              data = df,
              family = bernoulli(link = "logit"),
              prior = priors_regression,
              iter = 4000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)
```

We also want to present analyses re-weighting the effect of the meta-analysis prior. This is done to account for perceived issues with the meta-analysis - such as publication bias (which we have assessed to be very significant), and the inclusion of low-quality studies. To do this, we present a publication-bias adjusted prior, and a prior including only low risk of bias studies. 

Now for the 'reference' priors.

Reference priors are meant to reflect various prior attitudes towards the research question: from very sceptical to very optimistic. References priors are informed by a consideration of the minimal clinically important difference (MCID). I am going to use the MCID in two ways, which we describe in detail below:

1.  Inform the *specification of reference priors* for the DECADE trial's results.

2.  Aid with *interpretation of the clinical significance* of the posterior estimates of the DECADE trial's results.

The MCID is the threshold value for which we would consider an effect meaningful. This is a little difficult with odds ratios because most people can't intuitively think of what a 'meaningful' odds ratio would be. For example if you picked a 30% odds reduction, this would decrease the rate of delirium from 40% to 32% (almost certainly meaningful) or from 5% to 3.6% (potentially not meaningful).

One way to determine the MCID is to consider the effect on the Cohen's d (standardised mean difference (SMD)) scale. This is a standardised scale where a Cohen's d of 0.2, 0.5, and 0.8 (somewhat arbitrarily) correspond to a small, medium, and large effect size, respectively.

[Kruschke](https://nyu-cdsc.github.io/learningr/assets/kruschke_bayesian_in_R.pdf) suggests that in the absence of better information, an SMD of 0.1 is a good starting point for the MCID. This is half of what would constitute a 'small' effect size according to Cohen. We can (approximately) convert the SMD to the log odds ratio using the formula:

$$
\text{SMD} = log(OR) × \frac{{\pi}}{\sqrt{3}}
$$

This results in an MCID of \|0.18\| on the log odds ratio scale. This is equivalent to an odds ratio of 0.84, or a 16% reduction in the odds of delirium. Using the control delirium rate in the DECADE trial of 12%, this means we would consider a 2% absolute risk reduction (to a rate of 10% in the dexmedetomidine group) as a 'meaningful' reduction.

This also allows us to specify the **region of practical equivalence** (ROPE). This is the range of values which, from a practical perspective, are equivalent to the null (zero effect). The decision rules for the ROPE were described by [Kruschke](https://nyu-cdsc.github.io/learningr/assets/kruschke_bayesian_in_R.pdf) (note these are not universally embraced):

> "A parameter value is declared to be not credible, or rejected, if its entire ROPE lies outside the 95% highest density interval (HDI) of the posterior distribution of that parameter ... Notice that when the HDI excludes the ROPE, we are not rejecting all values within the ROPE; we are rejecting only the null value."

So, if our posterior 95% CrI does not overlap with the ROPE we would conclude that dexmedetomidine has a non-zero effect on delirium.

And we are also provided with the flip side of this analysis:

> "A parameter value is declared to be accepted for practical purposes if that value's ROPE completely contains the 95% HDI of the posterior of that parameter."

So, if our posterior 95% CrI falls completely with the ROPE, we would conclude that dexmedetomidine has no effect on delirium.

And finally, what is the 95%CrI and ROPE overlap?

> "When the HDI and ROPE overlap, with the ROPE not completely containing the HDI, then neither of the above decision rules is satisfied, and we withhold a decision. This means merely that the current data are insufficient to yield a clear decision one way or the other, according to the stated decision criteria."

The ROPE relates to the MCID as the upper and lower limits of the ROPE will be the values for the MCID. The specification of the limits of the ROPE is obviously subject to considerable debate. [Kruschke](https://nyu-cdsc.github.io/learningr/assets/kruschke_bayesian_in_R.pdf) tells us:

> "In some applications, the ROPE can be specified with respect to the magnitude of conventionally"small" effect sizes for the domain of research ... But just as the labeling of effect sizes as "small" depends on conventional practice, the setting of a ROPE must be made in the context of current theory, measurement abilities, and the practical purpose of the decision."

So we've chosen a logOR change of 0.18 as our 'small' effect size. That means our ROPE is $-0.18 < {\mu} < 0.18$ on the log odds ratio scale. But we need to check if our conclusions are robust to difference limits for the ROPE; as stated above, it is clear that wide ROPEs will favour accepting the null while narrow ROPEs will favour rejection. So, we will also consider an MCID of $0.18 × 1.5 = 0.27$, i.e., 1.5 times greater than the original MCID, which would make our ROPE $-0.27 < {\mu} < 0.27$.

So that covers the mean for our reference priors. But what about the prior variance? For this we consider 'RCT equivalents'. This idea is taken from [Goligher et al.](https://jamanetwork.com/journals/jama/article-abstract/2709620)'s Bayesian re-analysis in JAMA.

Basically, for the reference prior we pretend that there has been a theoretical prior RCT that reported a certain effect size (corresponding to the MCID stuff above) and enrolled a certain number of participants. We can calculate the standard error of the log odds ratio of that trial using the formula:

$$
se_i = \sqrt{\frac{1}{a_i} + \frac{1}{b_i} + \frac{1}{c_i} + \frac{1}{d_i}}
$$ {#eq-logor-var}

Where a, b, c, and d correspond to the 2x2 table from the *i*th two-group RCT analysing a binary outcome:

|                 | Delirium present | Delirium absent |
|-----------------|------------------|-----------------|
| Control         | a                | b               |
| Dexmedetomidine | c                | d               |

For priors that are 'sceptical' or 'optimistic', we hypothesised a 1000-participant RCT showing a mean effect (on the log odds ratio scale) of: ${\theta} = 1.5 × MCID = 0.27$.

Now for calculating the standard error of the hypothetical trials. To start off, we used the formula mentioned earlier for calculating the treatment group risk $R_t$ for each hypothetical RCT.

$$
R_t = \frac{R_c × OR}{R_c × (OR - 1) + 1}
$$

In the above equation, for $R_c$ we used the control group delirium rate in DECADE of 12% for all calculations.

Once we have $R_t$ and $R_c$, we can multiply these by the number of participants in that arm of the hypothetical RCT. So, for an RCT of $n$ participants, there would be $\frac{n}{2}$ people in each arm, so our 2x2 table would be:

|                 | Delirium present        | Delirium absent             |
|-----------------|-------------------------|-----------------------------|
| Control         | $a = R_c × \frac{n}{2}$ | $b = (1-R_c) × \frac{n}{2}$ |
| Dexmedetomidine | $c = R_t × \frac{n}{2}$ | $d = (1-R_t) × \frac{n}{2}$ |

Then we calculate the standard error using the above formula in @eq-logor-var with the corresponding values for a, b, c, and d.

With all that in mind, we have used the following reference priors for the DECADE's results:

-   Vague: $Normal(0, 10)$. This is an essentially flat prior which imparts no information on the posterior estimate.
-   Sceptical: $Normal(0.27, 0.186)$. Equivalent to an RCT enrolling 1000 people and showing a 31% increase in the odds of delirium ($MCID × 1.5$) with dexmedetomidine.
-   Neutral: $Normal(0, 0.355)$. 95% of the probability density lies between an odds ratio of 0.5 to 2.0. This is a reasonable prior to reflect the attitude of someone who thinks dexmedetomidine is equally likely to have a beneficial or harmful effect, and smaller effects are more likely than bigger ones.
-   Optimistic: $Normal(-0.27, 0.206)$. Equivalent to an RCT enrolling 1000 people and showing a 24% reduction in the odds of delirium ($MCID × 1.5$) with dexmedetomidine.

## Posterior probabilities with different priors

@fig-priors-plots-all shows the distributions of the priors. The top two panels show the distribution of the (A) reference priors, and (B) meta-analysis priors. The bottom forest plot shows the posterior distribution of DECADE's results for each prior. The grey region denotes the ROPE. The purple lines show the DECADE's findings when analysed alone. The grey lines represent the prior. Regions of the posterior that suggest benefit (OR \< 1) are shaded in blue and those that suggest harm (OR \> 1) are shaded in red. The probabilities of any harm or benefit, and the harm or benefit exceeding the MCID, are shown for each prior.

```{r fig.width = 12, fig.height = 10}
#| label: fig-priors-plots-all
#| fig-width: 12
#| fig-height: 10
#| cache: TRUE
#| results: 'hide'
#| message: FALSE
#| warning: FALSE
#| errors: FALSE
#| fig-cap: |
#|   Plots of the distributions of the reference and meta-analysis priors.

## Create a dataframe with the DECADE trial's results
treatment <- c(rep("dexmedetomidine", 398), rep("placebo", 396))
delirium <- c(rep(1, 67), rep(0, 331), rep(1, 46), rep(0, 350))
df <- data.frame(treatment, delirium)

df$treatment <- factor(df$treatment, levels = c("placebo", "dexmedetomidine"))

## First create our MA priors with all studies
## start with the fully weighted MA prior
median_mu_excl_decade <- m.brm_excluding_decade %>%
  spread_draws(b_Intercept) %>%
  median_qi() %>%
  dplyr::select(b_Intercept)
#  -0.480

median_tau_excl_decade <- m.brm_excluding_decade %>%
  spread_draws(sd_author1__Intercept) %>%
  median_qi() %>%
  dplyr::select(sd_author1__Intercept)
# 0.191

##Now create our MA priors with low RoB studies
median_mu_excl_decade <- m.brm_low_rob_excl_decade %>%
  spread_draws(b_Intercept) %>%
  median_qi() %>%
  dplyr::select(b_Intercept)
#  -0.515

median_tau_excl_decade <- m.brm_low_rob_excl_decade %>%
  spread_draws(sd_author1__Intercept) %>%
  median_qi() %>%
  dplyr::select(sd_author1__Intercept)
# 0.228

## Make a function to extract the posterior estimates

draws_fn <- function(brm) {
  brm %>%
  spread_draws(b_treatmentdexmedetomidine) %>%
  median_qi() %>% 
  mutate(estimate = paste0(sprintf('%.2f', exp(b_treatmentdexmedetomidine)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'))
}

# Also we need a function to extract the draws for the forest plot
forest_draws_fn <- function(brm, prior) {
  brm %>%
  spread_draws(b_treatmentdexmedetomidine) %>%
    dplyr::select(b_treatmentdexmedetomidine) %>%
    mutate(subgroup = prior)
    
}

## and a function to calculate probability of benefit
benefit_fn <- function(brm) {
  brm %>% 
  tidy_draws() %>% 
  summarise(prob_benefit = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine < 0)),
            prob_harm = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine > 0)),
            prob_mcid_harm = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine > 0.18)),
            prob_mcid_benefit = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine < -0.18)))
}


full_weight_ma_priors <- brms::prior(normal(-0.480, 0.191), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_full_weight.brm <- brm(delirium ~ 1 + treatment,
             data = df,
             family = bernoulli(link = "logit"),
             prior = full_weight_ma_priors,
              iter = 4000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)

ma_full_weight_draws <- draws_fn(ma_full_weight.brm)

ma_full_weight_forest_draws <- forest_draws_fn(ma_full_weight.brm, "MA (all studies)")
ma_full_weight_benefit <- benefit_fn(ma_full_weight.brm)

## Now for the 50% weight (get this by multiplying SD by 2)

low_rob_ma_priors <- brms::prior(normal(-0.515, 0.228), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_low_rob.brm <- update(ma_full_weight.brm, prior = low_rob_ma_priors)

ma_low_rob_draws <- draws_fn(ma_low_rob.brm)
ma_low_rob_forest_draws <- forest_draws_fn(ma_low_rob.brm, "MA (low RoB)")
ma_low_rob_benefit <- benefit_fn(ma_low_rob.brm)

# Now for the bias-adjusted model
library(RoBMA)
robma_no_decade <- RoBMA(logOR = IVdat_del[IVdat_del$author != "Turan", ]$yi, v = IVdat_del[IVdat_del$author != "Turan", ]$vi,
               priors_effect = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.82)),
               priors_heterogeneity = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.5),
                                            truncation = list(lower = 0, upper = Inf)), 
               prior_scale = "logOR",
               effect_direction = "negative")

bias_sum <- summary(robma_no_decade, conditional = TRUE)$estimates_conditional

bias_sum_mean <- bias_sum[1,1]
## 0.02761012

bias_sum_sd <- (abs(bias_sum[1,3]) + abs(bias_sum[1,4]))/3.92
## 0.3182868

bias_ma_priors <- brms::prior(normal(0.02761012, 0.3182868), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_bias.brm <- update(ma_full_weight.brm, prior = bias_ma_priors)

ma_bias_draws <- draws_fn(ma_bias.brm)
ma_bias_forest_draws <- forest_draws_fn(ma_bias.brm, "MA (bias adj.)")
ma_bias_benefit <- benefit_fn(ma_bias.brm)

## Now for our reference priors
# Start with vague with SD = 10
vague_priors <- brms::prior(normal(0,10), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

vague.brm <- update(ma_full_weight.brm, prior = vague_priors)

vague_draws <- draws_fn(vague.brm)
vague_forest_draws <- forest_draws_fn(vague.brm, "Vague")
vague_benefit <- benefit_fn(vague.brm)

# Now sceptical

## We want an RCT of 100 people showing a 0.27 logOR increase in delirium (1.5*MCID of Cohen's D = 0.1)
# First, to calculate the SE of the RCT we need to calculate the risk in treatment and control groups using formula: Rt = Rc*OR/Rc*(OR - 1) + 1
rt <- (0.12*exp(0.27))/(0.12*(exp(0.27) - 1) + 1)
## [1] 0.1515584

## So the risk would increased from 12% to 15.156%. 
## To obtain a prior RCT of n = 1000 showing no effect using the base rate of 12% delirium from DECADE
## We need to use the formula: SE = sqrt(1/a + 1/b + 1/c + 1d)

se_sceptical <- sqrt((1/60) + (1/440) + (1/76) + (1/424))
## 0.1856227

sceptical_priors <- brms::prior(normal(0.27, 0.1856227), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
sceptical.brm <- update(ma_full_weight.brm, prior = sceptical_priors)

sceptical_draws <- draws_fn(sceptical.brm)
sceptical_forest_draws <- forest_draws_fn(sceptical.brm, "Sceptical")
sceptical_benefit <- benefit_fn(sceptical.brm)

## Now, for neutral priors
# neutral prior is defined so that 0.95 of the probability mass ranges from an odds ratio between 0.5 and 2.0. 
# As done in https://ccforum.biomedcentral.com/articles/10.1186/s13054-022-04120-y#Sec12
se_neutral <- 0.355
neutral_priors <- brms::prior(normal(0, 0.355), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
neutral.brm <- update(ma_full_weight.brm, prior = neutral_priors)

neutral_draws <- draws_fn(neutral.brm)
neutral_forest_draws <- forest_draws_fn(neutral.brm, "Neutral")
neutral_benefit <- benefit_fn(neutral.brm)

## Now for optimistic - an RCT of 1000 people showing a -0.27 logOR reduction
# First, to calculate the SE of the RCT we need to calculate the risk in treatment and control groups using formula: Rt = Rc*OR/Rc*(OR - 1) + 1
rt <- (0.12*exp(-0.27))/(0.12*(exp(-0.27) - 1) + 1)
## [1] 0.09428264

# So our trial will have 12% event rate in control and 9.4% event rate in DEX group

se_optimistic <- sqrt((1/60) + (1/440) + (1/47) + (1/453))
## [1] 0.2059696

optimistic_priors <- brms::prior(normal(-0.27, 0.2059696), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
optimistic.brm <- update(ma_full_weight.brm, prior = optimistic_priors)

optimistic_draws <- draws_fn(optimistic.brm)
optimistic_forest_draws <- forest_draws_fn(optimistic.brm, "Optimistic")
optimistic_benefit <- benefit_fn(optimistic.brm)

## Now let's make the plots
# First let's graph the priors
reference_priors <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
  geom_vline(xintercept = 1, color = "black", size = 1) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = 0, sd = 10)), color = "vague", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = 0.27, sd = se_sceptical)), color = "sceptical", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = 0, sd = se_neutral)), color = "neutral", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = -0.27, sd = se_optimistic)), color = "optimistic", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.1, 7), ylim = c(1, 2)) +
  ggdist::scale_thickness_shared() +
  theme_nice() +
  theme(
    axis.text.y = element_blank(),
    legend.position = c(0.95, 0.9),  
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "lightgrey", color = "black")) +
  labs(x = "Odds ratio (log scale)", title = "A: Reference priors for logistic regression") +
  ylab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set2"),
                     breaks = c("vague","sceptical", "neutral", "optimistic"),
                     labels = c("Vague", 
                                "Sceptical", "Neutral", "Optimistic"),
                     name = "Prior") +
  guides(color = guide_legend(override.aes = list(linetype = "solid", shape = NA)))

ma_priors <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
  geom_vline(xintercept = 1, color = "black", size = 1) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = -0.480, sd = 0.191)), color = "metafull", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = -0.515, sd = 0.228)), color = "metalowrob", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = -0.02761012, sd = 0.3182868)), color = "metabias", y = 1),
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.1, 7), ylim = c(1, 2)) +
  ggdist::scale_thickness_shared() +
  theme_nice() +
  theme(
    axis.text.y = element_blank(),
    legend.position = c(0.8, 0.9),  
    legend.justification = c(0.5, 1),
    legend.background = element_rect(fill = "lightgrey", color = "black")) +
  labs(x = "Odds ratio (log scale)", title = "B: MA priors for logistic regression") +
  ylab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                     breaks = c("metafull", "metalowrob", "metabias"),
                     labels = c("All studies", 
                                "Low risk of bias\nstudies only", 
                                "Publication-bias\ncorrected"),
                     name = "Prior") +
  guides(color = guide_legend(override.aes = list(linetype = "solid", shape = NA)))

# Now let's plot the posterior distributions of the odds ratios for each of these priors
# First let's make a dataframe called tabdat with all of our things of interest
tabdat_pre <- data.frame(subgroup = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                           "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")),
                     decade_posterior_mean = IVdat_del$yi[IVdat_del$author1 == "Turan 2020 (DECADE)"],
                     decade_posterior_sd = IVdat_del$sei[IVdat_del$author1 == "Turan 2020 (DECADE)"],
                     prior_mean = c(0, 0.27, 0, -0.27, -0.480, -0.515, -0.02761012),
                     prior_sd = c(10, se_sceptical, se_neutral,
                                  se_optimistic, 0.191, 0.228, 0.3182868),
                     posterior_estimate = c(vague_draws$estimate, sceptical_draws$estimate,
                                            neutral_draws$estimate, optimistic_draws$estimate, 
                                            ma_full_weight_draws$estimate, ma_low_rob_draws$estimate, ma_bias_draws$estimate),
                     p_benefit = c(vague_benefit$prob_benefit, sceptical_benefit$prob_benefit,
                                            neutral_benefit$prob_benefit, optimistic_benefit$prob_benefit, 
                                            ma_full_weight_benefit$prob_benefit, ma_low_rob_benefit$prob_benefit, 
                                            ma_bias_benefit$prob_benefit),
                     p_harm = c(vague_benefit$prob_harm, sceptical_benefit$prob_harm,
                                            neutral_benefit$prob_harm, optimistic_benefit$prob_harm, 
                                            ma_full_weight_benefit$prob_harm, ma_low_rob_benefit$prob_harm, 
                                             ma_bias_benefit$prob_harm),
                     p_mcid_harm = c(vague_benefit$prob_mcid_harm, sceptical_benefit$prob_mcid_harm,
                                            neutral_benefit$prob_mcid_harm, optimistic_benefit$prob_mcid_harm, 
                                            ma_full_weight_benefit$prob_mcid_harm, ma_low_rob_benefit$prob_mcid_harm, 
                                            ma_bias_benefit$prob_mcid_harm),
                     p_mcid_benefit = c(vague_benefit$prob_mcid_benefit, sceptical_benefit$prob_mcid_benefit,
                                            neutral_benefit$prob_mcid_benefit, optimistic_benefit$prob_mcid_benefit, 
                                            ma_full_weight_benefit$prob_mcid_benefit, ma_low_rob_benefit$prob_mcid_benefit, 
                                           ma_bias_benefit$prob_mcid_benefit)) %>%
                    mutate(prior_mean_exp = as.numeric(sprintf('%.2f', exp(prior_mean))),
                          prior_sd = as.numeric(sprintf('%.2f', prior_sd)),
                          prior_mean_sd = paste0(sprintf('%.2f',prior_mean_exp), " ± ", prior_sd),
                          p_benefit = paste0(p_benefit, "%"),
                          p_harm = paste0(p_harm, "%"),
                          p_mcid_benefit = paste0(p_mcid_benefit, "%"),
                          p_mcid_harm = paste0(p_mcid_harm, "%"))

# Make a table which I will need to make the geom_pointintervals
draws_df <- rbind(vague_draws, sceptical_draws, neutral_draws,
                  optimistic_draws, ma_full_weight_draws, ma_low_rob_draws, ma_bias_draws)

draws_df <- cbind(subgroup = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                    "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")), draws_df) %>%
  mutate(subgroup = factor(subgroup, levels = c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                                "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

new_row <- data.frame(subgroup = factor("Prior belief"),
                      decade_posterior_mean = "",
                     decade_posterior_sd = "",
                     prior_mean = "",
                     prior_mean_exp = "",
                     prior_sd = "",
                     prior_mean_sd = "Prior mean±SD",
                    posterior_estimate = "Posterior 95%CrI",
                     p_benefit = "P(any benefit)",
                     p_mcid_benefit = "P(benefit >MCID)",
                     p_harm = "P(any harm)",
                     p_mcid_harm = "P(harm >MCID)")

tabdat <- rbind(new_row, tabdat_pre) %>%
  mutate(subgroup = factor(subgroup, levels = c("Prior belief", "Vague", 
                                "Sceptical", "Neutral", "Optimistic", 
                                 "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

# Now let's make a forest dataframe with our data for posterior estimates
# First we need to combine all our forest draws into one long dataframe

forest.data <- rbind(vague_forest_draws, sceptical_forest_draws, neutral_forest_draws,
                     optimistic_forest_draws, ma_full_weight_forest_draws, 
                     ma_low_rob_forest_draws,  ma_bias_forest_draws) %>%
  mutate(subgroup = factor(subgroup, levels = c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                            "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

forest <- ggplot(aes(exp(b_treatmentdexmedetomidine), 
           y = fct_relevel(subgroup, rev)), 
       data = forest.data) +
  geom_vline(xintercept = 1, color = "black", 
             size = 0.7) +
  stat_slab(aes(fill = after_stat(x < 1)), slab_colour = "black") +
  geom_pointintervalh(aes(xmin = exp(.lower), 
                          xmax = exp(.upper), 
                          x = exp(b_treatmentdexmedetomidine)),
                      data = draws_df, 
                      col = "black", alpha = 1, position = position_nudge(y = -0.1)) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = decade_posterior_mean, sd = decade_posterior_sd)),
                y = fct_relevel(subgroup, rev)), 
            data = tabdat_pre, color = "purple", fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = prior_mean, sd = prior_sd)),
                y = fct_relevel(subgroup, rev)), 
            data = tabdat_pre, color = "grey30", fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.25, 4), ylim=c(1,8)) +
  annotate("text", x = 0.5, y = 8, label = "Favours\nDEX") +
  annotate("text", x = 2, y = 8,  label = "Favours\ncontrol") +
  ggdist::scale_thickness_shared() +
  theme_nice() +
  theme(axis.text.y = element_blank()) +
  labs(x= "Odds ratio (log scale)", title = "D: Forest plot") +
  ylab(NULL) +
  theme(legend.position = "none")  +
  guides(alpha = "none") +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2)

prior_details <- ggplot(aes(y = fct_relevel(subgroup, rev)), 
                   data = tabdat) +
  geom_text(aes(x = 0, label = subgroup), hjust = 0,
                        fontface = ifelse(tabdat$subgroup == "Prior belief", "bold", "plain")) +
  geom_text(aes(x = 2, label = prior_mean_sd), hjust = 0, 
            fontface = ifelse(tabdat$prior_mean_sd == "Prior mean±SD", "bold", "plain")) +
  labs(title = "C: Prior information") +
  scale_color_identity() +
  ylab(NULL) +
  theme_void(base_family = "Verdana") +
  theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "Verdana", face = "bold", size = 16)) +
  coord_cartesian(xlim = c(0, 4))

posteriors <- ggplot(aes(y = fct_relevel(subgroup, rev)), 
                   data = tabdat) +
  geom_text(aes(x = 0, label = posterior_estimate), hjust = 0,
                        fontface = ifelse(tabdat$posterior_estimate == "Posterior 95%CrI", "bold", "plain")) +
  geom_text(aes(x = 1, label = p_benefit), hjust = 0,
                        fontface = ifelse(tabdat$p_benefit == "P(any benefit)", "bold", "plain")) +
  geom_text(aes(x = 1.8, label = p_mcid_benefit), hjust = 0,
                        fontface = ifelse(tabdat$p_mcid_benefit == "P(benefit >MCID)", "bold", "plain")) +
  geom_text(aes(x = 2.8, label = p_harm), hjust = 0,
                        fontface = ifelse(tabdat$p_harm == "P(any harm)", "bold", "plain")) +
  geom_text(aes(x = 3.6, label = p_mcid_harm), hjust = 0,
                        fontface = ifelse(tabdat$p_mcid_harm == "P(harm >MCID)", "bold", "plain")) +
  scale_color_identity() +
  labs(title = "E: Posterior probability of benefit/harm") +
  ylab(NULL) +
  theme_void(base_family = "Verdana") +
  theme(panel.grid.minor = element_blank(),
          plot.title = element_text(family = "Verdana", face = "bold", size = 16)) +
  coord_cartesian(xlim = c(0, 4.2))

library(patchwork)

layout <- c(
  patchwork::area(t = 0, l = 0, b = 15, r = 30),
  patchwork::area(t = 0, l = 32, b = 15, r = 60), 
  patchwork::area(t = 16, l = 0, b = 42, r = 15),
  patchwork::area(t = 16, l = 15, b = 42, r = 28), 
  patchwork::area(t = 16, l = 29, b = 42, r = 60))

reference_priors + ma_priors + prior_details + forest + posteriors + plot_layout(design = layout)
```

## Priors explanations

```{r}
tabdat <- data.frame(prior = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")),
                     Group = c("Reference priors", "Reference priors","Reference priors","Reference priors",
                               "Meta-analysis priors", "Meta-analysis priors", 
                               "Meta-analysis priors"),
                     prior_equivalent = c("No information imposed on posterior estimate", 
                                          "Equivalent to a hypothetical n = 1000 RCT showing a 31% increase in odds of delirium",
                                          "95% of the density lies between an odds ratio of 0.5 to 2.0",
                                          "Equivalent to a hypothetical n = 1000 RCT showing a 24% decrease in odds of delirium",
                                          "Meta-analysis of n = 2745 participants across 11 trials",
                                          "Meta-analysis of n = 787 participants across 3 trials",
                                          "Meta-analysis of n = 2745 participants across 11 trials averaged across models accounting for publication bias"),
                     rationale = c("Does not favour one prior belief over another", 
                                          "This effect size is 1.5 times the MCID for harm (logOR of 0.27)",
                                          "Plausible values for the effect are likely, with values closer to the null most likely",
                                           "This effect size is the 1.5 times MCID for benefit (logOR of -0.27)",
                                   "This is analogous to the result of a standard meta-analysis of all 12 studies, including the DECADE trial",
                                   "This attempts to attenuate the effects of various research bias parameters but using only high-quality studies",
                                   "This attempts to attenuate the influence of publication bias in the literature"))

colnames(tabdat) <- c("Prior", "Group", "Prior equivalent", "Rationale for prior")
                     
tab <- tabdat %>%
          gt(groupname_col = "Group")

tab %>% 
  gt::gtsave(., "priors_explanation.rtf")

tab
                       
```


## ARR table

Below we provide direct probability statements for the DECADE trial's results given each priors we specified above. 

We have chosen to present the risk of any harm or benefit, and the harm exceeding the MCID for benefit and harm (calculated by conversion of a logOR of +/-0.18 using the median control group rate of delirium in the DECADE trial).

All ARRs in @tbl-arr below use `avg_comparisons()` function from the `marginaleffects` package to obtain risk differences as the measure of effect. It does this via g-computation.

```{r}
#| label: tbl-arr
#| tbl-cap: Explanations for priors for DECADE and the corresponding probabilities of changes in absolute risk of delirium.

Rc_overall <- median(IVdat_del$control_del_rate)
rt_mcid_benefit <- (median(IVdat_del$control_del_rate)*exp(-0.18))/(median(IVdat_del$control_del_rate)*(exp(-0.18)-1) + 1)
rt_mcid_harm <- (median(IVdat_del$control_del_rate)*exp(0.18))/(median(IVdat_del$control_del_rate)*(exp(0.18)-1) + 1)

rd_mcid_benefit <- rt_mcid_benefit - Rc_overall

rd_mcid_harm <- rt_mcid_harm - Rc_overall

probs_fn <- function(brm) {
      brm %>% 
       marginaleffects::avg_comparisons() %>%
       marginaleffects::posterior_draws() %>%
       summarise(
            arr_mcid = 100*mean(draw < rd_mcid_benefit),
            arr_below_0 = 100*mean(draw < 0),
            arr_above_0 = 100*mean(draw > 0),
            ari_mcid = 100*mean(draw > rd_mcid_harm),
  )
}

probs <- rbind(probs_fn(vague.brm),  probs_fn(sceptical.brm),
               probs_fn(neutral.brm), probs_fn(optimistic.brm), 
               probs_fn(ma_full_weight.brm), probs_fn(ma_low_rob.brm), probs_fn(ma_bias.brm)) %>%
  mutate(across(where(is.numeric), ~sprintf("%.1f", .)))

blah <- IVdat_del %>% 
  filter(!author == "Turan") %>% 
    summarise(sum_total_number_participants = sum(as.numeric(total_number_participants)))

tabdat <- data.frame(prior = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")),
                     Group = c("Reference priors", "Reference priors","Reference priors","Reference priors",
                               "Meta-analysis priors", "Meta-analysis priors", 
                               "Meta-analysis priors"),
                     probs)

colnames(tabdat) <- c("Prior", "Group", "ARR >MCID for benefit (ARR = 2.3%)", "ARR >0%", "ARI >0%", "ARI >MCID for harm (ARI = 2.5%)")

tab <- tabdat %>%
    gt(rowname_col = "Prior", groupname_col = "Group") %>%
  tab_spanner(
    label = "Posterior probability that the change in absolute risk from DECADE is above/below a certain threshold",
    columns = starts_with("AR")) %>%
  gt::tab_style(
    style = gt::cell_text(weight = "bold"),
    locations = gt::cells_row_groups(groups = everything())) %>%
  tab_style(
    style = list(
      cell_fill(color = "grey"),
      cell_text(weight = "bold")
      ),
    locations = cells_row_groups()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels())

tab %>% 
  gt::gtsave(., "decade_arrs.rtf")

tab
                     
```

## Shrinkage OR estimation + ECDFs

Now let's zoom on the relative distributions of the mean effect when we include and exclude the DECADE trial from the meta-analysis. For this we will use empirical cumulative distribution function (ECDF) plots.

I consider four density functions: meta-analysis including DECADE, meta-analysis excluding DECADE, DECADE alone, and the DECADE shrinkage estimate from the meta-analysis.

The x-axis is common to the upper and lower graphs so one is able to read off the probability of any odds ratio for any of the four curves. @fig-ecdfs shows the results. The grey region denotes the ROPE ($log(OR) = ± 0.18$).

::: panel-tabset
## All studies

```{r}
#| label: fig-ecdfs
#| fig-width: 10
#| fig-height: 10
#| fig-cap: |
#|   Empirical cumulative distribution function (ECDF) plots including and excluding DECADE.

## First, the MA with the DECADE trial

post.samples_decade <- as_draws_df(m.brm, c("b_Intercept", "sd_author1__Intercept"))

study.draws_decade <- spread_draws(m.brm, r_author1[author1,], b_Intercept) %>% 
  mutate(b_Intercept = r_author1 + b_Intercept)

pooled.effect.draws_decade <- spread_draws(m.brm, b_Intercept) %>% 
  mutate(author1 = "Pooled Effect")

forest.data_decade <- bind_rows(study.draws_decade, 
                         pooled.effect.draws_decade) %>% 
   ungroup() %>%
   mutate(author1 = str_replace_all(author1, "[.]", " ")) %>% 
   mutate(author1 = reorder(author1, b_Intercept)) %>%
   filter(author1 == c("Turan 2020 (DECADE)", "Pooled Effect"))

## Now, without DECADE
## First, the MA with the DECADE trial
post.samples_no_decade <- as_draws_df(m.brm_excluding_decade, c("b_Intercept", "sd_author1__Intercept"))

study.draws_no_decade <- spread_draws(m.brm_excluding_decade, r_author1[author1,], b_Intercept) %>% 
  mutate(b_Intercept = r_author1 + b_Intercept)

pooled.effect.draws_no_decade <- spread_draws(m.brm_excluding_decade, b_Intercept) %>% 
  mutate(author1 = "Pooled Effect")

forest.data_no_decade <- bind_rows(study.draws_no_decade, 
                         pooled.effect.draws_no_decade) %>% 
   ungroup() %>%
   mutate(author1 = str_replace_all(author1, "[.]", " ")) %>% 
   mutate(author1 = reorder(author1, b_Intercept)) %>%
   filter(author1 == c("Pooled Effect"))

## Now to make the plot combining the 4 curves of interest
decade_posterior_mean <-  IVdat_del$yi[IVdat_del$author1 == "Turan 2020 (DECADE)"]
decade_posterior_sd <- IVdat_del$sei[IVdat_del$author1 == "Turan 2020 (DECADE)"]

ma_curves <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
    stat_slab(aes(x = exp(b_Intercept), color = "pooled_incl_decade"), data = forest.data_decade %>% filter(author1 == "Pooled Effect"),
                      slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
   stat_slab(aes(x = exp(b_Intercept), color = "decade_shrink"), data = forest.data_decade %>% filter(author1 == "Turan 2020 (DECADE)"), 
                    slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
   stat_slab(aes(x = exp(b_Intercept), color = "pooled_excl_decade"), data = forest.data_no_decade, 
                    slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = decade_posterior_mean, sd = decade_posterior_sd)), color = "decade_alone"), 
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.25, 4)) +
  ggdist::scale_thickness_shared() +
  geom_vline(xintercept=1) +
  annotate("text", x = 0.35, y = 0.9, label = "Favours\ndexmedetomidine", hjust = 0, size = 4) +
  annotate("text", x = 2, y = 0.9, label = "Favours\ncontrol", hjust = 0, size = 4) +
  theme_light() +
  theme(
    axis.text.y = element_blank(),
    legend.position = "none") +
  labs(x = "Odds ratio") +
  ylab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                     breaks = c("pooled_incl_decade", "decade_shrink", "pooled_excl_decade",
                                "decade_alone"),
                     labels = c("Pooled including DECADE", "DECADE shrinkage", 
                                "Pooled excluding DECADE", "DECADE alone"),
                     name = "Posterior") 

## Now for the ECDFs

# Compute density values for the normal curve of DECADE
x <- seq(-2, 2, length.out = 100000)
density <- rnorm(x, mean = IVdat_del[IVdat_del$author == "Turan", "yi"], 
                 sd = IVdat_del[IVdat_del$author == "Turan", "sei"])
df_density <- data.frame(x = x, density = density)

library(scales)

ecdfs <- ggplot(aes(x = exp(b_Intercept), color = "pooled_excl_decade"), data = forest.data_no_decade) +
  stat_ecdf(geom = "step") +
  stat_ecdf(aes(x = exp(b_Intercept), color = "pooled_incl_decade"), data = forest.data_decade %>% filter(author1 == "Pooled Effect"), geom = "step") +
  stat_ecdf(aes(x = exp(b_Intercept), color = "decade_shrink"), data = forest.data_decade %>% filter(author1 == "Turan 2020 (DECADE)"), geom = "step") +
  stat_ecdf(aes(x = exp(density), color = "decade_alone"), data = df_density, geom = "step") +
  scale_y_continuous(name = "Probability that mean OR < x", limits = c(0, 1), breaks = seq(0, 1, 0.1), labels = percent_format(),
                     sec.axis = sec_axis(~ 1 - ., name = "Probability that mean OR > x",
                                          breaks = seq(0, 1, 0.1), labels = percent_format())) +
  geom_vline(xintercept = 1) +
  scale_x_log10(breaks = c(0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.25, 4)) +
  theme_light() +
  theme(
    legend.position = c(0.9, 0.5),  
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "lightgrey", color = "black")) +
  theme(axis.line = element_blank(),           # remove axis lines
        axis.text.x = element_blank(),         # remove x-axis tick labels
        axis.ticks.x = element_blank()) +
  xlab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                     breaks = c("pooled_incl_decade", "decade_shrink", "pooled_excl_decade",
                                "decade_alone"),
                     labels = c("Pooled including DECADE", "DECADE shrinkage", 
                                "Pooled excluding DECADE", "DECADE alone"),
                     name = "Posterior") +
  guides(color = guide_legend(override.aes = list(linetype = "solid", shape = NA)))

layout <- c(
  area(t = 0, l = 0, b = 12, r = 30),
  area(t = 13, l = 0, b = 20, r = 30))

ecdfs + ma_curves + plot_layout(design = layout)

```

## Excluding studies at high risk of bias

```{r}
#| label: fig-ecdfs-low-rob
#| fig-width: 10
#| fig-height: 10
#| fig-cap: |
#|   Empirical cumulative distribution function (ECDF) plots including and excluding DECADE, and excluding studies at high risk of bias.

## First, the MA with the DECADE trial

post.samples_decade <- as_draws_df(m.brm_low_rob, c("b_Intercept", "sd_author1__Intercept"))

study.draws_decade <- spread_draws(m.brm_low_rob, r_author1[author1,], b_Intercept) %>% 
  mutate(b_Intercept = r_author1 + b_Intercept)

pooled.effect.draws_decade <- spread_draws(m.brm_low_rob, b_Intercept) %>% 
  mutate(author1 = "Pooled Effect")

forest.data_decade <- bind_rows(study.draws_decade, 
                         pooled.effect.draws_decade) %>% 
   ungroup() %>%
   mutate(author1 = str_replace_all(author1, "[.]", " ")) %>% 
   mutate(author1 = reorder(author1, b_Intercept)) %>%
   filter(author1 == c("Turan 2020 (DECADE)", "Pooled Effect"))

## Now, without DECADE
## First, the MA with the DECADE trial
post.samples_no_decade <- as_draws_df(m.brm_excluding_decade_low_rob, c("b_Intercept", "sd_author1__Intercept"))

study.draws_no_decade <- spread_draws(m.brm_excluding_decade_low_rob, r_author1[author1,], b_Intercept) %>% 
  mutate(b_Intercept = r_author1 + b_Intercept)

pooled.effect.draws_no_decade <- spread_draws(m.brm_excluding_decade_low_rob, b_Intercept) %>% 
  mutate(author1 = "Pooled Effect")

forest.data_no_decade <- bind_rows(study.draws_no_decade, 
                         pooled.effect.draws_no_decade) %>% 
   ungroup() %>%
   mutate(author1 = str_replace_all(author1, "[.]", " ")) %>% 
   mutate(author1 = reorder(author1, b_Intercept)) %>%
   filter(author1 == c("Pooled Effect"))

## Now to make the plot combining the 4 curves of interest
decade_posterior_mean <-  IVdat_del_low_rob$yi[IVdat_del_low_rob$author1 == "Turan 2020 (DECADE)"]
decade_posterior_sd <- IVdat_del_low_rob$sei[IVdat_del_low_rob$author1 == "Turan 2020 (DECADE)"]

ma_curves <- ggplot(data = data.frame(x = c(-10, 10)), aes(x)) +
    stat_slab(aes(x = exp(b_Intercept), color = "pooled_incl_decade"), data = forest.data_decade %>% filter(author1 == "Pooled Effect"),
                      slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
   stat_slab(aes(x = exp(b_Intercept), color = "decade_shrink"), data = forest.data_decade %>% filter(author1 == "Turan 2020 (DECADE)"), 
                    slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
   stat_slab(aes(x = exp(b_Intercept), color = "pooled_excl_decade"), data = forest.data_no_decade, 
                    slab_linewidth = 0.9, fill = NA, alpha = 0.7) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = decade_posterior_mean, sd = decade_posterior_sd)), color = "decade_alone"), 
            fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.25, 4)) +
  ggdist::scale_thickness_shared() +
  geom_vline(xintercept=1) +
  annotate("text", x = 0.35, y = 0.9, label = "Favours\ndexmedetomidine", hjust = 0, size = 4) +
  annotate("text", x = 2, y = 0.9, label = "Favours\ncontrol", hjust = 0, size = 4) +
  theme_light() +
  theme(
    axis.text.y = element_blank(),
    legend.position = "none") +
  labs(x = "Odds ratio") +
  ylab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                     breaks = c("pooled_incl_decade", "decade_shrink", "pooled_excl_decade",
                                "decade_alone"),
                     labels = c("Pooled including DECADE", "DECADE shrinkage", 
                                "Pooled excluding DECADE", "DECADE alone"),
                     name = "Posterior") 

## Now for the ECDFs

# Compute density values for the normal curve of DECADE
x <- seq(-2, 2, length.out = 100000)
density <- rnorm(x, mean = IVdat_del_low_rob[IVdat_del_low_rob$author == "Turan", "yi"], 
                 sd = IVdat_del_low_rob[IVdat_del_low_rob$author == "Turan", "sei"])
df_density <- data.frame(x = x, density = density)

library(scales)

ecdfs <- ggplot(aes(x = exp(b_Intercept), color = "pooled_excl_decade"), data = forest.data_no_decade) +
  stat_ecdf(geom = "step") +
  stat_ecdf(aes(x = exp(b_Intercept), color = "pooled_incl_decade"), data = forest.data_decade %>% filter(author1 == "Pooled Effect"), geom = "step") +
  stat_ecdf(aes(x = exp(b_Intercept), color = "decade_shrink"), data = forest.data_decade %>% filter(author1 == "Turan 2020 (DECADE)"), geom = "step") +
  stat_ecdf(aes(x = exp(density), color = "decade_alone"), data = df_density, geom = "step") +
  scale_y_continuous(name = "Probability that mean OR < x", limits = c(0, 1), breaks = seq(0, 1, 0.1), labels = percent_format(),
                     sec.axis = sec_axis(~ 1 - ., name = "Probability that mean OR > x",
                                          breaks = seq(0, 1, 0.1), labels = percent_format())) +
  geom_vline(xintercept = 1) +
  scale_x_log10(breaks = c(0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +
  coord_cartesian(xlim = c(0.25, 4)) +
  theme_light() +
  theme(
    legend.position = c(0.9, 0.5),  
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "lightgrey", color = "black")) +
  theme(axis.line = element_blank(),           # remove axis lines
        axis.text.x = element_blank(),         # remove x-axis tick labels
        axis.ticks.x = element_blank()) +
  xlab(NULL) +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey", alpha = 0.2) +
  scale_color_manual(values = RColorBrewer::brewer.pal(4, "Set1"),
                     breaks = c("pooled_incl_decade", "decade_shrink", "pooled_excl_decade",
                                "decade_alone"),
                     labels = c("Pooled including DECADE", "DECADE shrinkage", 
                                "Pooled excluding DECADE", "DECADE alone"),
                     name = "Posterior") +
  guides(color = guide_legend(override.aes = list(linetype = "solid", shape = NA)))

layout <- c(
  area(t = 0, l = 0, b = 12, r = 30),
  area(t = 13, l = 0, b = 20, r = 30))

ecdfs + ma_curves + plot_layout(design = layout)

```
:::

## Average treatment effect estimation

To this point, we have been using odds ratios (from logistic regression) in various fancy ways to generate other helpful statistics (probabilities of harm, benefit, etc.).

But odds ratios are not infallible. Firstly, there is the issue of noncollapsibility.

As [Sander Greenland explains](https://www.jclinepi.com/article/S0895-4356(21)00182-7/fulltext):

> "Noncollapsibility is a noncausal phenomenon in which a measurement on a group does not equal a designated average of the same measurement over its constituents, as illustrated by how group odds are not simple averages of individual odds when the odds vary across individuals"

Blogs by [Cameron Patrick](https://cameronpatrick.com/post/2023/07/logit-rd-rr/#fnref6) and [Solomun Kurz](https://solomonkurz.netlify.app/blog/2023-04-24-causal-inference-with-logistic-regression/#fnref:9) provide excellent overviews of non-collapsiblity and obtaining non-odds ratio estimates from logistic regression. See also [Frank Harrell's comments](https://www.fharrell.com/post/marg/) for a great example of non-collapsbility.

For our purposes, the noncollapsbility of ORs means that our *marginal OR from DECADE is not a weighted average of possible hidden subpopulations.* Another effect of non-collapsiblity is that the *effect estimate will change when adjusting for a variable that is not a confounder*, while it does not change for collapsible measures (e.g., relative risk).

Another issue is that odds ratios are not a true measure of the 'average treatment effect (ATE)'. Some have also referred to the ATE as the "difference in probabilities", "discrete differences," or "discrete change." The ATE is a population-level summary of the effect of an intervention. A true measure of the ATE is, for example, the risk difference.

### ATE table

So, let's get into estimating the ATE, in the form of the risk differences obtained from an ANOVA-type logistic regression model. For this we will use the `avg_comparisons()` function in the `marginaleffects` package, which calculates estimates from brms (and frequentist) models.

```{r}
#| label: tbl-ate
#| tbl-cap: Average treatment effect of dexmedetomidine in the DECADE trial
library(marginaleffects)

arr_fn <- function(brm, name) {
  data.frame(marginaleffects::avg_comparisons(brm)) %>%
    dplyr::select(3:5) %>%
    mutate(across(everything(), ~ . * 100)) %>%
    mutate(across(where(is.numeric), ~sprintf("%.1f", .))) %>%
    mutate(Model = name,
           confint = paste0(conf.low, ", ", conf.high)) %>%
    dplyr::select(4, 1, 5)
}

dat_ma <- rbind(arr_fn(ma_full_weight.brm, "MA (all studies)"), 
                arr_fn(ma_low_rob.brm, "MA (low RoB)"), 
                arr_fn(ma_bias.brm, "MA (bias adj.)"))
                
dat_reference <- rbind(arr_fn(vague.brm, "Vague"), arr_fn(sceptical.brm, "Sceptical"),
             arr_fn(neutral.brm, "Neutral"), arr_fn(optimistic.brm, "Optimistic"))

dat_all <- rbind(dat_reference, dat_ma) %>%
  mutate(Group = c("Reference priors", "Reference priors","Reference priors","Reference priors",
                               "Meta-analysis priors", "Meta-analysis priors", 
                               "Meta-analysis priors"))

tab <- dat_all %>%
  rename("Risk difference % (DEX - placebo)" = estimate,
         "95% CrI" = confint) %>%
  gt(rowname_col = "Model", groupname_col = "Group") %>%
  tab_style(
    style = list(
      cell_fill(color = "grey"),
      cell_text(weight = "bold")
      ),
    locations = cells_row_groups()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels())

tab %>% 
  gt::gtsave(., "ate_tab.rtf")

tab
```

## Combined plot

```{r fig.width = 12, fig.height = 8}
#| label: comb_decade_plot
#| fig-width: 12
#| fig-height: 8
#| cache: TRUE
#| results: 'hide'
#| message: FALSE
#| warning: FALSE
#| errors: FALSE

## Create a dataframe with the DECADE trial's results
treatment <- c(rep("dexmedetomidine", 398), rep("placebo", 396))
delirium <- c(rep(1, 67), rep(0, 331), rep(1, 46), rep(0, 350))
df <- data.frame(treatment, delirium)

df$treatment <- factor(df$treatment, levels = c("placebo", "dexmedetomidine"))

## First create our MA priors
## start with the fully weighted MA prior
median_mu_excl_decade <- m.brm_excluding_decade %>%
  spread_draws(b_Intercept) %>%
  median_qi() %>%
  dplyr::select(b_Intercept)
#  -0.480

median_tau_excl_decade <- m.brm_excluding_decade %>%
  spread_draws(sd_author1__Intercept) %>%
  median_qi() %>%
  dplyr::select(sd_author1__Intercept)
# 0.191

##Now create our MA priors with low RoB studies
median_mu_excl_decade <- m.brm_low_rob_excl_decade %>%
  spread_draws(b_Intercept) %>%
  median_qi() %>%
  dplyr::select(b_Intercept)
#  -0.515

median_tau_excl_decade <- m.brm_low_rob_excl_decade %>%
  spread_draws(sd_author1__Intercept) %>%
  median_qi() %>%
  dplyr::select(sd_author1__Intercept)
# 0.228

## Make a function to extract the posterior estimates

draws_fn <- function(brm) {
  brm %>%
  spread_draws(b_treatmentdexmedetomidine) %>%
  median_qi() %>% 
  mutate(estimate = paste0(sprintf('%.2f', exp(b_treatmentdexmedetomidine)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'))
}

# Also we need a function to extract the draws for the forest plot
forest_draws_fn <- function(brm, prior) {
  brm %>%
  spread_draws(b_treatmentdexmedetomidine) %>%
    dplyr::select(b_treatmentdexmedetomidine) %>%
    mutate(subgroup = prior)
    
}

## and a function to calculate probability of benefit
benefit_fn <- function(brm) {
  brm %>% 
  tidy_draws() %>% 
  summarise(prob_benefit = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine < 0)),
            prob_harm = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine > 0)),
            prob_mcid_harm = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine > 0.18)),
            prob_mcid_benefit = sprintf('%.1f', 100*mean(b_treatmentdexmedetomidine < -0.18)))
}


full_weight_ma_priors <- brms::prior(normal(-0.480, 0.191), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_full_weight.brm <- brm(delirium ~ 1 + treatment,
             data = df,
             family = bernoulli(link = "logit"),
             prior = full_weight_ma_priors,
              iter = 4000,
              backend = "cmdstanr", 
              cores = parallel::detectCores(),
              chains = 4,
              seed = 123)

ma_full_weight_draws <- draws_fn(ma_full_weight.brm)

ma_full_weight_forest_draws <- forest_draws_fn(ma_full_weight.brm, "MA (all studies)")
ma_full_weight_benefit <- benefit_fn(ma_full_weight.brm)

## Now for the 50% weight (get this by multiplying SD by 2)

low_rob_ma_priors <- brms::prior(normal(-0.515, 0.228), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_low_rob.brm <- update(ma_full_weight.brm, prior = low_rob_ma_priors)

ma_low_rob_draws <- draws_fn(ma_low_rob.brm)
ma_low_rob_forest_draws <- forest_draws_fn(ma_low_rob.brm, "MA (low RoB)")
ma_low_rob_benefit <- benefit_fn(ma_low_rob.brm)


# Now for the bias-adjusted model
library(RoBMA)
robma_no_decade <- RoBMA(logOR = IVdat_del[IVdat_del$author != "Turan", ]$yi, v = IVdat_del[IVdat_del$author != "Turan", ]$vi,
               priors_effect = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.82)),
               priors_heterogeneity = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.5),
                                            truncation = list(lower = 0, upper = Inf)), 
               prior_scale = "logOR",
               effect_direction = "negative")

bias_sum <- summary(robma_no_decade, conditional = TRUE)$estimates_conditional

bias_sum_mean <- bias_sum[1,1]
## 0.02761012

bias_sum_sd <- (abs(bias_sum[1,3]) + abs(bias_sum[1,4]))/3.92
## 0.3182868

bias_ma_priors <- brms::prior(normal(0.02761012, 0.3182868), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

ma_bias.brm <- update(ma_full_weight.brm, prior = bias_ma_priors)

ma_bias_draws <- draws_fn(ma_bias.brm)
ma_bias_forest_draws <- forest_draws_fn(ma_bias.brm, "MA (bias adj.)")
ma_bias_benefit <- benefit_fn(ma_bias.brm)

## Now for our reference priors
# Start with vague with SD = 10
vague_priors <- brms::prior(normal(0,10), class = b, coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)

vague.brm <- update(ma_full_weight.brm, prior = vague_priors)

vague_draws <- draws_fn(vague.brm)
vague_forest_draws <- forest_draws_fn(vague.brm, "Vague")
vague_benefit <- benefit_fn(vague.brm)

# Now sceptical

## We want an RCT of 100 people showing a 0.27 logOR increase in delirium (1.5*MCID of Cohen's D = 0.1)
# First, to calculate the SE of the RCT we need to calculate the risk in treatment and control groups using formula: Rt = Rc*OR/Rc*(OR - 1) + 1
rt <- (0.12*exp(0.27))/(0.12*(exp(0.27) - 1) + 1)
## [1] 0.1515584

## So the risk would increased from 12% to 15.156%. 
## To obtain a prior RCT of n = 1000 showing no effect using the base rate of 12% delirium from DECADE
## We need to use the formula: SE = sqrt(1/a + 1/b + 1/c + 1d)

se_sceptical <- sqrt((1/60) + (1/440) + (1/76) + (1/424))
## 0.1856227

sceptical_priors <- brms::prior(normal(0.27, 0.1856227), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
sceptical.brm <- update(ma_full_weight.brm, prior = sceptical_priors)

sceptical_draws <- draws_fn(sceptical.brm)
sceptical_forest_draws <- forest_draws_fn(sceptical.brm, "Sceptical")
sceptical_benefit <- benefit_fn(sceptical.brm)

## Now, for neutral priors
# neutral prior is defined so that 0.95 of the probability mass ranges from an odds ratio between 0.5 and 2.0. 
# As done in https://ccforum.biomedcentral.com/articles/10.1186/s13054-022-04120-y#Sec12
se_neutral <- 0.355
neutral_priors <- brms::prior(normal(0, 0.355), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
neutral.brm <- update(ma_full_weight.brm, prior = neutral_priors)

neutral_draws <- draws_fn(neutral.brm)
neutral_forest_draws <- forest_draws_fn(neutral.brm, "Neutral")
neutral_benefit <- benefit_fn(neutral.brm)

## Now for optimistic - an RCT of 1000 people showing a -0.27 logOR reduction
# First, to calculate the SE of the RCT we need to calculate the risk in treatment and control groups using formula: Rt = Rc*OR/Rc*(OR - 1) + 1
rt <- (0.12*exp(-0.27))/(0.12*(exp(-0.27) - 1) + 1)
## [1] 0.09428264

# So our trial will have 12% event rate in control and 9.4% event rate in DEX group

se_optimistic <- sqrt((1/60) + (1/440) + (1/47) + (1/453))
## [1] 0.2059696

optimistic_priors <- brms::prior(normal(-0.27, 0.2059696), coef = "treatmentdexmedetomidine") +
                brms::prior(normal(0,1), class = Intercept)
  
optimistic.brm <- update(ma_full_weight.brm, prior = optimistic_priors)

optimistic_draws <- draws_fn(optimistic.brm)
optimistic_forest_draws <- forest_draws_fn(optimistic.brm, "Optimistic")
optimistic_benefit <- benefit_fn(optimistic.brm)


# Now let's plot the posterior distributions of the odds ratios for each of these priors
# First let's make a dataframe called tabdat with all of our things of interest
tabdat_pre <- data.frame(subgroup = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                           "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")),
                     decade_posterior_mean = IVdat_del$yi[IVdat_del$author1 == "Turan 2020 (DECADE)"],
                     decade_posterior_sd = IVdat_del$sei[IVdat_del$author1 == "Turan 2020 (DECADE)"],
                     prior_mean = c(0, 0.27, 0, -0.27, -0.480, -0.515, -0.02761012),
                     prior_sd = c(10, se_sceptical, se_neutral,
                                  se_optimistic, 0.191, 0.228, 0.3182868),
                     posterior_estimate = c(vague_draws$estimate, sceptical_draws$estimate,
                                            neutral_draws$estimate, optimistic_draws$estimate, 
                                            ma_full_weight_draws$estimate, ma_low_rob_draws$estimate, ma_bias_draws$estimate),
                     p_benefit = c(vague_benefit$prob_benefit, sceptical_benefit$prob_benefit,
                                            neutral_benefit$prob_benefit, optimistic_benefit$prob_benefit, 
                                            ma_full_weight_benefit$prob_benefit, ma_low_rob_benefit$prob_benefit, 
                                            ma_bias_benefit$prob_benefit),
                     p_harm = c(vague_benefit$prob_harm, sceptical_benefit$prob_harm,
                                            neutral_benefit$prob_harm, optimistic_benefit$prob_harm, 
                                            ma_full_weight_benefit$prob_harm, ma_low_rob_benefit$prob_harm, 
                                             ma_bias_benefit$prob_harm),
                     p_mcid_harm = c(vague_benefit$prob_mcid_harm, sceptical_benefit$prob_mcid_harm,
                                            neutral_benefit$prob_mcid_harm, optimistic_benefit$prob_mcid_harm, 
                                            ma_full_weight_benefit$prob_mcid_harm, ma_low_rob_benefit$prob_mcid_harm, 
                                            ma_bias_benefit$prob_mcid_harm),
                     p_mcid_benefit = c(vague_benefit$prob_mcid_benefit, sceptical_benefit$prob_mcid_benefit,
                                            neutral_benefit$prob_mcid_benefit, optimistic_benefit$prob_mcid_benefit, 
                                            ma_full_weight_benefit$prob_mcid_benefit, ma_low_rob_benefit$prob_mcid_benefit, 
                                           ma_bias_benefit$prob_mcid_benefit)) %>%
                    mutate(prior_mean_exp = as.numeric(sprintf('%.2f', exp(prior_mean))),
                          prior_sd = as.numeric(sprintf('%.2f', prior_sd)),
                          prior_mean_sd = paste0(sprintf('%.2f',prior_mean_exp), " ± ", prior_sd),
                          p_benefit = paste0(p_benefit, "%"),
                          p_harm = paste0(p_harm, "%"),
                          p_mcid_benefit = paste0(p_mcid_benefit, "%"),
                          p_mcid_harm = paste0(p_mcid_harm, "%"))

# Make a table which I will need to make the geom_pointintervals
draws_df <- rbind(vague_draws, sceptical_draws, neutral_draws,
                  optimistic_draws, ma_full_weight_draws, ma_low_rob_draws, ma_bias_draws)

draws_df <- cbind(subgroup = factor(c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                    "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")), draws_df) %>%
  mutate(subgroup = factor(subgroup, levels = c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                                "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

new_row <- data.frame(subgroup = factor("Prior belief"),
                      decade_posterior_mean = "",
                     decade_posterior_sd = "",
                     prior_mean = "",
                     prior_mean_exp = "",
                     prior_sd = "",
                     prior_mean_sd = "Prior mean±SD",
                    posterior_estimate = "Posterior 95%CrI",
                     p_benefit = "P(any benefit)",
                     p_mcid_benefit = "P(benefit >MCID)",
                     p_harm = "P(any harm)",
                     p_mcid_harm = "P(harm >MCID)")

tabdat <- rbind(new_row, tabdat_pre) %>%
  mutate(subgroup = factor(subgroup, levels = c("Prior belief", "Vague", 
                                "Sceptical", "Neutral", "Optimistic", 
                                 "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

# Now let's make a forest dataframe with our data for posterior estimates
# First we need to combine all our forest draws into one long dataframe

forest.data <- rbind(vague_forest_draws, sceptical_forest_draws, neutral_forest_draws,
                     optimistic_forest_draws, ma_full_weight_forest_draws, 
                     ma_low_rob_forest_draws,  ma_bias_forest_draws) %>%
  mutate(subgroup = factor(subgroup, levels = c("Vague", "Sceptical", "Neutral", "Optimistic", 
                                            "MA (all studies)", "MA (low RoB)", "MA (bias adj.)")))

forest <- ggplot(aes(exp(b_treatmentdexmedetomidine), 
           y = fct_relevel(subgroup, rev)), 
       data = forest.data) +
  geom_vline(xintercept = 1, color = "black", 
             size = 0.7) +
  stat_slab(aes(fill = after_stat(x < 1)), slab_colour = "black") +
  geom_pointintervalh(aes(xmin = exp(.lower), 
                          xmax = exp(.upper), 
                          x = exp(b_treatmentdexmedetomidine)),
                      data = draws_df, 
                      col = "black", alpha = 1, position = position_nudge(y = -0.1)) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = decade_posterior_mean, sd = decade_posterior_sd)),
                y = fct_relevel(subgroup, rev)), 
            data = tabdat_pre, color = "purple", fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  stat_slab(aes(xdist = exp(distributional::dist_normal(mean = prior_mean, sd = prior_sd)),
                y = fct_relevel(subgroup, rev)), 
            data = tabdat_pre, color = "grey30", fill = NA, slab_linewidth = 0.9, inherit.aes = FALSE) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.25, 4), ylim=c(1,8)) +
  annotate("text", x = 0.5, y = 8, label = "Favours\nDEX") +
  annotate("text", x = 2.5, y = 8,  label = "Favours\ncontrol") +
  ggdist::scale_thickness_shared() +
  theme_nice() +
  forest_theme +
  theme(axis.text.y = element_blank()) +
  labs(x= "Odds ratio (log scale)", title = "B: Forest plot") +
  ylab(NULL) +
  theme(legend.position = "none")  +
  guides(alpha = "none") +
  geom_vline(xintercept = c(0.84, 1.20), linetype = "dotted", color = "grey30") +
  annotate("rect", xmin = 0.84, xmax = 1.20, ymin = -Inf, ymax = Inf, fill = "grey30", alpha = 0.2)

prior_details <- ggplot(aes(y = fct_relevel(subgroup, rev)), 
                   data = tabdat) +
  geom_text(aes(x = 0, label = subgroup), hjust = 0,
                        fontface = ifelse(tabdat$subgroup == "Prior belief", "bold", "plain")) +
  geom_text(aes(x = 2, label = prior_mean_sd), hjust = 0, 
            fontface = ifelse(tabdat$prior_mean_sd == "Prior mean±SD", "bold", "plain")) +
  labs(title = "A: Prior information") +
  scale_color_identity() +
  ylab(NULL) +
  theme_void(base_family = "Verdana") +
  forest_theme +
  coord_cartesian(xlim = c(0, 3.7))

posteriors <- ggplot(aes(y = fct_relevel(subgroup, rev)), 
                   data = tabdat) +
  geom_text(aes(x = 0, label = posterior_estimate), hjust = 0,
                        fontface = ifelse(tabdat$posterior_estimate == "Posterior 95%CrI", "bold", "plain")) +
  geom_text(aes(x = 1, label = p_benefit), hjust = 0,
                        fontface = ifelse(tabdat$p_benefit == "P(any benefit)", "bold", "plain")) +
  geom_text(aes(x = 1.8, label = p_mcid_benefit), hjust = 0,
                        fontface = ifelse(tabdat$p_mcid_benefit == "P(benefit >MCID)", "bold", "plain")) +
  geom_text(aes(x = 2.8, label = p_harm), hjust = 0,
                        fontface = ifelse(tabdat$p_harm == "P(any harm)", "bold", "plain")) +
  geom_text(aes(x = 3.6, label = p_mcid_harm), hjust = 0,
                        fontface = ifelse(tabdat$p_mcid_harm == "P(harm >MCID)", "bold", "plain")) +
  scale_color_identity() +
  labs(title = "C: Posterior probability of benefit/harm") +
  ylab(NULL) +
  theme_void(base_family = "Verdana") +
  forest_theme +
  coord_cartesian(xlim = c(0, 4.2))

probs_fn <- function(brm, prior) {
      brm %>% 
       marginaleffects::avg_comparisons() %>%
       marginaleffects::posterior_draws() %>%
       dplyr::select(draw) %>%
      mutate(prior = prior,
             draw = draw * 100)
}

label_vector <- c("Vague", 
                  "Sceptical", "Neutral", "Optimistic", 
                  "MA (all studies)", 
                  "MA (low RoB)", "MA (bias adj.)")

probs <- rbind(probs_fn(vague.brm, "Vague"), 
               probs_fn(sceptical.brm, "Sceptical"),
               probs_fn(neutral.brm, "Neutral"), 
               probs_fn(optimistic.brm, "Optimistic"), 
               probs_fn(ma_full_weight.brm, "MA (all studies)"), 
               probs_fn(ma_low_rob.brm, "MA (low RoB)"), 
               probs_fn(ma_bias.brm, "MA (bias adj.)")) %>%
  mutate(prior = factor(prior, levels = label_vector))

ate_plot <- ggplot(aes(x = draw, y = fct_relevel(prior, rev), color = prior), data = probs) +
  stat_pointinterval(.width = c(0.95)) +
  scale_x_continuous(breaks = c(-7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10, 12.5), expand = c(0, 0)) +
  coord_cartesian(xlim = c(-7.5, 15)) +
  geom_vline(xintercept=0) +
  annotate("text", x = -4, y = 5, label = "Favours\ndexmedetomidine", size = 4) +
  annotate("text", x = 10, y = 5, label = "Favours\ncontrol",  size = 4) +
  theme_nice() +
  forest_theme +
  theme(
    legend.position = c(0.95, 1),  
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "grey95", color = "black")) +
   labs(x = "Risk difference (%, DEX - control)", title = "D: Average treatment effects from the DECADE trial") +
  scale_color_manual(values = RColorBrewer::brewer.pal(7, "Set2"),
                     breaks = label_vector,
                     labels = label_vector,
                     name = "Prior") +
  ylab(NULL)

library(patchwork)

layout <- c(
  patchwork::area(t = 0, l = 0, b = 26, r = 13),
  patchwork::area(t = 0, l = 14.5, b = 26, r = 28), 
  patchwork::area(t = 0, l = 29, b = 26, r = 61),
  patchwork::area(t = 27, l = 0, b = 42, r = 60))

prior_details + forest + posteriors + ate_plot + plot_layout(design = layout)
```

# Metaregression

Now let's consider how the effect of dexmedetomidine may across populations vary due to various factors. This is called metaregression, which is just the meta-analysis equivalent of multivariable linear regression. By glancing at it, it just looks like subgroup analysis, which is correct. *Subgroup analysis is just a form of metaregression with a categorical moderator.*

Below I've used similar priors as I used for our primary analysis. Although, here we are interested in the `moderator` coefficient, rather than the intercept coefficient. So my prior for the coefficient of interest is $N(0, 0.82)$ while for the intercept coefficient it is $N(0, 1)$. Given it's the treatment coefficient we're interested in, we're using the $Normal(0,0.82)$ prior for the same reason as described above for the primary analysis. I also retain the same ${\tau}$ priors as in our primary analysis: $Cauchy(0, 0.5)$. In summary, our priors are:

$$Intercept \sim Normal(0, 1)$$
$$\tau \sim HalfCauchy(0.5)$$
$$\beta_\text{treatment} \sim Normal(0, 0.82)$$

And the code for priors using `brms` is:

``` r
priors_metareg <- brms::prior(normal(0, 1), class = b, coef = "Intercept") +
                  brms::prior(cauchy(0,0.5), class = sd) +
                  brms::prior(normal(0,0.82), class = b)
```

The results in the following code for the model (where 'covariate' is the moderator variable):

``` r
m.brm_covariate <- brm(yi | se(sei) ~ 0 + Intercept + covariate + (1 | author1),
                       data = IVdat_del, 
                       prior = priors_metareg,
                       iter = 4000,
                       backend = "cmdstanr", 
                       cores = parallel::detectCores(),
                       chains = 4,
                       seed = 123))
```

In the plot below @fig-metareg-brms, the blue curve is the posterior distribution of the regression coefficient draws for each outcome. The orange line is the prediction interval.

## Forest plot all subgroups

```{r fig.wdith = 13, fig.height = 5}
#| label: fig-metareg-brms
#| fig-width: 13
#| fig-height: 5
#| fig-cap: |
#|   Metaregression plots.

## Then make a function to calculate the number of studies for each outcome
count_na <- function(column_name, column_value) {
  return(IVdat_del %>% filter(!!sym(column_name) == column_value) %>% nrow())
}
                  
## And finally get the total number of participants for each outcome
## First, delirium in the DEX group
sum_dex_or_control_ratio <- function(column_name, column_value, type) {
  if (type == "dex") {
    column_del <- "dex_del"
    column_n <- "dex_n"
  } else if (type == "control") {
    column_del <- "control_del"
    column_n <- "control_n"
  }
  
  if (length(column_value) == 1) {
    # If a single column value is passed, filter for that value
    metareg_df <- IVdat_del %>%
      filter(!!sym(column_name) == column_value)
    
    return(paste0(sum(metareg_df[[column_del]], na.rm=TRUE), "/",
                  sum(metareg_df[[column_n]], na.rm=TRUE)))
  } else {
    # If multiple column values are passed, filter for all values and combine
    metareg_df <- IVdat_del %>%
      filter(!!sym(column_name) %in% column_value)
    
    return(paste0(sum(metareg_df[[column_del]], na.rm=TRUE), "/",
                  sum(metareg_df[[column_n]], na.rm=TRUE)))
  }
}

# Extract the pooled result data
pooled.effect.draws_intraop <- spread_draws(m.brm_dose_timing, b_Intercept) %>%
  mutate(author1 = "Intraop") %>%
  rename(coeff = b_Intercept)

pooled.effect.draws_postop <- spread_draws(m.brm_dose_timing, b_dex_dose_timingpostop, b_Intercept) %>%
   mutate(author1 = "Postop",
          b_dex_dose_timingpostop = b_Intercept + b_dex_dose_timingpostop) %>%
  rename(coeff = b_dex_dose_timingpostop) %>%
  dplyr::select(-b_Intercept)

pooled.effect.draws_intraop_and_postop <- spread_draws(m.brm_dose_timing, b_dex_dose_timingintraop_and_postop, b_Intercept) %>%
    mutate(author1 = "Intraop + postop",
           b_dex_dose_timingintraop_and_postop = b_Intercept + b_dex_dose_timingintraop_and_postop) %>%
  rename(coeff = b_dex_dose_timingintraop_and_postop) %>%
  dplyr::select(-b_Intercept)

# Combine the pooled result with study estimates, then play around with the lexicon (bmrs mucks this up)
forest.data_dose_timing <- bind_rows(pooled.effect.draws_intraop, pooled.effect.draws_postop, pooled.effect.draws_intraop_and_postop) %>%
    mutate(author1 = str_replace_all(author1, "[.]", " ")) %>%
    mutate(author1 = as.factor(author1))
  
# Calculate median qi based on author1
forest.data.summary_dose_timing <- group_by(forest.data_dose_timing, author1) %>%
    median_qi(coeff) 

# Now create the PIs for dex dose timing
nd_intraop = data.frame(author1 = "new", dex_dose_timing = "intraop", sei = 0)
  
pred_intraop_df <- brms::posterior_predict(object = m.brm_dose_timing,
                          newdata = nd_intraop,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_intraop_summ <- pred_intraop_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
            rename(coeff = 1)

nd_postop = data.frame(author1 = "new", dex_dose_timing = "postop", sei = 0)
  
pred_postop_df <- brms::posterior_predict(object = m.brm_dose_timing,
                          newdata = nd_postop,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_postop_summ <- pred_postop_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
            rename(coeff = 1)

nd_intraop_and_postop = data.frame(author1 = "new", dex_dose_timing = "intraop_and_postop", sei = 0)
  
pred_intraop_and_postop_df <- brms::posterior_predict(object = m.brm_dose_timing,
                          newdata = nd_intraop_and_postop,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_intraop_and_postop_summ <- pred_intraop_and_postop_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
            rename(coeff = 1)

# Cbome the PI's for each dose level and the difference
pred_df_dose_timing <- rbind(pred_intraop_summ, pred_postop_summ, pred_intraop_and_postop_summ)
pred_df_dose_timing$author1 <- as.factor(c("Intraop", "Postop", "Intraop + postop"))
pred_df_dose_timing <- pred_df_dose_timing[c(7, 1:3)] %>%
  rename(pi_median = coeff,
         pi_lower = .lower,
         pi_upper = .upper)

# Now combine PI with previous estimates
forest.data.summary_dose_timing_comb <- left_join(forest.data.summary_dose_timing, pred_df_dose_timing, by = "author1") %>%
  mutate(author1 = as.factor(author1),
         dex_del_rate_frac = c(sum_dex_or_control_ratio("dex_dose_timing", "intraop", "dex"), 
                               sum_dex_or_control_ratio("dex_dose_timing", "intraop_and_postop", "dex"),
                               sum_dex_or_control_ratio("dex_dose_timing", "postop", "dex")),
         control_del_rate_frac = c(sum_dex_or_control_ratio("dex_dose_timing", "intraop", "control"),
                               sum_dex_or_control_ratio("dex_dose_timing", "intraop_and_postop", "control"),
                               sum_dex_or_control_ratio("dex_dose_timing", "postop", "control")),
         study_number = as.character(c(count_na("dex_dose_timing", "intraop"), 
                                       count_na("dex_dose_timing", "intraop_and_postop"),
                                       count_na("dex_dose_timing", "postop"))),
         unweighted_effect = paste0(sprintf('%.2f', exp(coeff)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'),
          prediction_int = paste0(sprintf('%.2f', exp(pi_median)), 
                  ' [', sprintf('%.2f', exp(pi_lower)),
                  ', ', sprintf('%.2f', exp(pi_upper)), ']')) %>%
         mutate(prediction_int = ifelse(prediction_int == "NA [NA, NA]", "", prediction_int))

new_row <- data.frame(author1 = as.factor("Dex dose timing"),
                      unweighted_effect = "OR [95%CrI]",
                      dex_del_rate_frac = "Delirium (n/total)",
                      control_del_rate_frac = "Delirium (n/total)",
                      study_number = "No. Studies",
                      prediction_int = "OR [95%CrI]")

new_row_res_plot <- data.frame(author1 = as.factor("Subgroup"),
                      unweighted_effect = "Credible interval",
                      dex_del_rate_frac = "DEX",
                      control_del_rate_frac = "Control",
                      study_number = "",
                      prediction_int = "Prediction interval")


res_plot_dose_timing <- bind_rows(forest.data.summary_dose_timing_comb, new_row, new_row_res_plot)

## Finally, dose_timing
dose_timing_forest <- ggplot(aes(exp(coeff), relevel(author1, "Intraop + postop", after=Inf)), 
       data = forest.data_dose_timing) +
  geom_vline(xintercept = 1, color = "black", 
             size = 1) +
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    geom_pointintervalh(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.25),
                      data = pred_df_dose_timing, 
                      col = "darkorange",
                      size = 4) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7), ylim=c(1,4)) +
  annotate("text", x = 0.35, y =4, label = "Favours\nDEX") +
  annotate("text", x = 3, y = 4,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.line = element_blank(),           # remove axis lines
        axis.text.x = element_blank(),         # remove x-axis tick labels
        axis.ticks.x = element_blank(),        # remove x-axis ticks
        axis.text.y = element_blank()) +
   xlab(NULL) +
  ylab(NULL)

dose_timing_estimates <- ggplot(aes(y = relevel(author1, "Intraop + postop", after=Inf)), 
                   data = res_plot_dose_timing) +
  geom_text(aes(x = 0, label = unweighted_effect), hjust = 0,
            fontface = ifelse(res_plot_dose_timing$unweighted_effect == "Credible interval" | res_plot_dose_timing$unweighted_effect == "OR [95%CrI]", "bold", "plain")) +
  geom_text(aes(x = 2, label = prediction_int), hjust = 0,
            fontface = ifelse(res_plot_dose_timing$prediction_int == "Prediction interval" | res_plot_dose_timing$prediction_int == "OR [95%CrI]", "bold", "plain")) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 4))

dose_timing_studies <- ggplot(aes(y = relevel(author1, "Intraop + postop", after=Inf)), 
                          data = res_plot_dose_timing) +
  geom_text(aes(x = 0, label = author1), hjust = 0, 
            fontface = ifelse(res_plot_dose_timing$author1 == "Subgroup" | res_plot_dose_timing$author1 == "Dex dose timing", "bold", "plain")) +
  geom_text(aes(x = 2, label = dex_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_dose_timing$dex_del_rate_frac == "Delirium (n/total)" | res_plot_dose_timing$dex_del_rate_frac == "DEX", "bold", "plain")) +
  geom_text(aes(x = 4, label = control_del_rate_frac), hjust = 0, 
            fontface = ifelse(res_plot_dose_timing$control_del_rate_frac == "Delirium (n/total)" | res_plot_dose_timing$control_del_rate_frac == "Control", "bold", "plain")) +
  geom_text(aes(x = 6, label = study_number), hjust = 0, 
            fontface = ifelse(res_plot_dose_timing$study_number == "No. Studies", "bold", "plain")) +
  scale_color_identity() + # Use the specified colors directly for text color
  theme_void() +
  coord_cartesian(xlim = c(0, 8))

## Now repeat the above for control agent

# Extract the pooled result data
pooled.effect.draws_morphine <- spread_draws(m.brm_control_agent, b_Intercept) %>%
  mutate(author1 = "Morphine") %>%
  rename(coeff = b_Intercept)

pooled.effect.draws_propofol <- spread_draws(m.brm_control_agent, b_control_agent_cleanPropofol, b_Intercept) %>%
   mutate(author1 = "Propofol",
          b_control_agent_cleanPropofol = b_Intercept + b_control_agent_cleanPropofol) %>%
  rename(coeff = b_control_agent_cleanPropofol) %>%
  dplyr::select(-b_Intercept)

pooled.effect.draws_ns <- spread_draws(m.brm_control_agent, b_control_agent_cleanNormalsaline, b_Intercept) %>%
    mutate(author1 = "Normal saline",
           b_control_agent_cleanNormalsaline = b_Intercept + b_control_agent_cleanNormalsaline) %>%
  rename(coeff = b_control_agent_cleanNormalsaline) %>%
  dplyr::select(-b_Intercept)

# Combine the pooled result with study estimates, then play around with the lexicon (bmrs mucks this up)
forest.data_control_agent <- bind_rows(pooled.effect.draws_morphine, pooled.effect.draws_propofol, pooled.effect.draws_ns) %>%
    mutate(author1 = str_replace_all(author1, "[.]", " ")) %>%
    mutate(author1 = as.factor(author1))
  
# Calculate median qi based on author1
forest.data.summary_control_agent <- group_by(forest.data_control_agent, author1) %>%
    median_qi(coeff) 

# Now create the PIs for dex dose timing
nd_morphine = data.frame(author1 = "new", control_agent_clean = "Morphine", sei = 0)
  
pred_morphine_df <- brms::posterior_predict(object = m.brm_control_agent,
                          newdata = nd_morphine,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_morphine_summ <- pred_morphine_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
             rename(coeff = 1)

nd_propofol = data.frame(author1 = "new", control_agent_clean = "Propofol", sei = 0)
  
pred_propofol_df <- brms::posterior_predict(object = m.brm_control_agent,
                          newdata = nd_propofol,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_propofol_summ <- pred_propofol_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
            rename(coeff = 1)

nd_ns = data.frame(author1 = "new", control_agent_clean = "Normal saline", sei = 0)
  
pred_ns_df <- brms::posterior_predict(object = m.brm_control_agent,
                          newdata = nd_ns,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

pred_ns_summ <- pred_ns_df |> 
             data.frame() |>
             ggdist::median_hdi() |>
            rename(coeff = 1)

# Cbome the PI's for each dose level and the difference
pred_df_control_agent <- rbind(pred_morphine_summ, pred_propofol_summ, pred_ns_summ)
pred_df_control_agent$author1 <- as.factor(c("Morphine", "Propofol", "Normal saline"))
pred_df_control_agent <- pred_df_control_agent[c(7, 1:3)] %>%
  rename(pi_median = coeff,
         pi_lower = .lower,
         pi_upper = .upper)

# Now combine PI with previous estimates
forest.data.summary_control_agent_comb <- left_join(forest.data.summary_control_agent, pred_df_control_agent, by = "author1") %>%
  mutate(author1 = as.factor(author1),
         dex_del_rate_frac = c(sum_dex_or_control_ratio("control_agent_clean", "Morphine", "dex"), 
                               sum_dex_or_control_ratio("control_agent_clean", "Normal saline", "dex"),
                               sum_dex_or_control_ratio("control_agent_clean", "Propofol", "dex")),
         control_del_rate_frac = c(sum_dex_or_control_ratio("control_agent_clean", "Morphine", "control"),
                               sum_dex_or_control_ratio("control_agent_clean", "Normal saline", "control"),
                               sum_dex_or_control_ratio("control_agent_clean", "Propofol", "control")),
         study_number = as.character(c(count_na("control_agent_clean", "Morphine"), 
                                       count_na("control_agent_clean", "Normal saline"),
                                       count_na("control_agent_clean", "Propofol"))),
         unweighted_effect = paste0(sprintf('%.2f', exp(coeff)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'),
          prediction_int = paste0(sprintf('%.2f', exp(pi_median)), 
                  ' [', sprintf('%.2f', exp(pi_lower)),
                  ', ', sprintf('%.2f', exp(pi_upper)), ']')) %>%
         mutate(prediction_int = ifelse(prediction_int == "NA [NA, NA]", "", prediction_int))

new_row <- data.frame(author1 = as.factor("Control agent"),
                      unweighted_effect = "",
                      dex_del_rate_frac = "",
                      control_del_rate_frac = "",
                      study_number = "",
                      prediction_int = "")


res_plot_control_agent <- bind_rows(forest.data.summary_control_agent_comb, new_row)

## Finally, dose_timing
control_agent_forest <- ggplot(aes(exp(coeff), relevel(author1, "Morphine", after=Inf)), 
       data = forest.data_control_agent) +
  geom_vline(xintercept = 1, color = "black", 
             size = 1) +
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    geom_pointintervalh(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.25),
                      data = pred_df_control_agent, 
                      col = "darkorange",
                      size = 4) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7), ylim=c(1,4)) +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  xlab("Odds ratio (log scale)") +
  ylab(NULL)

control_agent_estimates <- ggplot(aes(y = relevel(author1, "Morphine", after=Inf)), 
                   data = res_plot_control_agent) +
  geom_text(aes(x = 0, label = unweighted_effect), hjust = 0) +
  geom_text(aes(x = 2, label = prediction_int), hjust = 0) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 4))

control_agent_studies <- ggplot(aes(y = relevel(author1, "Morphine", after=Inf)), 
                          data = res_plot_control_agent) +
  geom_text(aes(x = 0, label = author1), hjust = 0, 
            fontface = ifelse(res_plot_control_agent$author1 == "Control agent", "bold", "plain")) +
  geom_text(aes(x = 2, label = dex_del_rate_frac), hjust = 0) +
  geom_text(aes(x = 4, label = control_del_rate_frac), hjust = 0) +
  geom_text(aes(x = 6, label = study_number), hjust = 0) +
  scale_color_identity() + 
  theme_void() +
  coord_cartesian(xlim = c(0, 8))

layout <- c(
  patchwork::area(t = 0, l = 0, b = 12, r = 40),
  patchwork::area(t = 0, l = 38, b = 12, r = 60), 
  patchwork::area(t = 0, l = 62, b = 12, r = 85),
  patchwork::area(t = 14, l = 0, b = 24, r = 40),
  patchwork::area(t = 14, l = 38, b = 24, r = 60), 
  patchwork::area(t = 14, l = 62, b = 24, r = 85))


dose_timing_studies + dose_timing_forest + dose_timing_estimates + control_agent_studies + control_agent_forest + control_agent_estimates + plot_layout(design = layout)

```

## Explained variability

Now to look at how much heterogeneity our moderators actually explain. A great overview is provided by [Wolfgang Vietchbauer](https://stat.ethz.ch/pipermail/r-sig-meta-analysis/2019-April/001499.html). 

Basically, we can compare the values for $\tau^2$ in the adjusted and unadjusted model.

To calculate the proportion of explained variability (pseudo$R^2$), we can use the formula:

$$
R^2 = \frac{\tau^2 (\text{unadjusted model}) - \tau^2 (\text{adjusted model})}{\tau^2 (\text{unadjusted model})}
$$

Given we have a distribution of posteriors for $\tau$, rather than an estimate (as they do in frequentist analysis), let's use the median $\tau$ from our distribution. 

``` {r}
#| label: tbl-explained-variation
#| tbl-cap: |
#|   Proportion of explain variation by the metaregressors.

tau_draws_fn <- function(brm, name) {
  brm %>% 
        tidybayes::tidy_draws() %>% 
        ggdist::median_hdi(sd_author1__Intercept) %>%
         mutate(median_tau_sq = as.numeric(sd_author1__Intercept^2),
                subgroup = name) %>%
         dplyr::select(median_tau_sq, subgroup)
}
  
tau_draws <- rbind(tau_draws_fn(m.brm, "Overall"),
                   tau_draws_fn(m.brm_dose_timing, "Dose timing"),
                   tau_draws_fn(m.brm_control_agent, "Control agent")) 

overall_tau_sq <- as.numeric(tau_draws[1,1])

tabdat <- tau_draws %>%
  mutate(rsq = 100*((overall_tau_sq - median_tau_sq)/overall_tau_sq)) %>%
  mutate(rsq = ifelse(rsq == 0, NA, ifelse(rsq < 0, 0, rsq))) %>%
  mutate(rsq = ifelse(is.na(rsq), NA, sprintf("%.1f%%", rsq))) %>%
  mutate(median_tau_sq = sprintf('%.2f', median_tau_sq)) %>%
  rename("Median τ²" = median_tau_sq, "Proportion of R²" = rsq)

tab <- tabdat %>%
  gt(rowname_col = "subgroup")  %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(columns = everything())) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_stub(rows = everything()))

 tab %>% 
  gt::gtsave(., "explained_variability.rtf")

tab
```

## Comparing subgroups

The idea for this analysis was obtained [here](https://discourse.mc-stan.org/t/testing-moderator-comparisons-in-bayesian-meta-analysis/22355). 

We will conduct hypothesis tests to compare the levels of the factor in the multilevel model.

### Figure

Let's start by plotting the posterior distributions for each of the variables' levels.

``` {r fig.width = 10, fig.height = 10}
#| label: fig-dose-timing-comp
#| fig-width: 10
#| fig-height: 10
#| fig-cap: |
#|   Comparison of effect with different dose timing.

fit_draws_dose_timing <- spread_draws(m.brm_dose_timing, `b_.*` ,regex = TRUE) %>%
  mutate(intraop = b_Intercept,
         intraop_and_postop = b_Intercept + b_dex_dose_timingintraop_and_postop,
         postop = b_Intercept + b_dex_dose_timingpostop) %>%
  dplyr::select(-c(b_Intercept, b_dex_dose_timingintraop_and_postop, b_dex_dose_timingpostop)) %>% 
  pivot_longer(cols = -c(.chain,.iteration,.draw)) %>% 
  arrange(name,.draw)

fit_draws_dose_timing$name <- factor(fit_draws_dose_timing$name)

dose_timing <- ggplot(fit_draws_dose_timing, aes(fill = name, x = exp(value), color = name, fill = NA)) +
  geom_vline(xintercept = 1, color = "black", 
             size = 1) +
  stat_slab(slab_linewidth = 0.9, fill = NA) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 4)) +
  annotate("text", x = 0.25, y =0.8, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 1.5, y = 0.8,  label = "Favours\ncontrol") +
  theme_light() +
  labs(x = "Odds ratio (log scale)") +
  theme(axis.line = element_blank(),  
        axis.text.y = element_blank()) +
  ylab(NULL) +
  scale_color_manual(values = RColorBrewer::brewer.pal(3, "Set2"),
                     breaks = c("intraop", "intraop_and_postop", "postop"),
                     labels = c("Intraoperative", "Intraoperative and\npostoperative", "Postoperative"),
                     name = "Dexmedetomidine timing")

fit_draws_control_agent <- spread_draws(m.brm_control_agent, `b_.*` ,regex = TRUE) %>%
  mutate(morphine = b_Intercept,
         propofol = b_Intercept + b_control_agent_cleanPropofol,
         ns = b_Intercept + b_control_agent_cleanNormalsaline) %>%
  dplyr::select(-c(b_Intercept, b_control_agent_cleanPropofol, b_control_agent_cleanNormalsaline)) %>% 
  pivot_longer(cols = -c(.chain,.iteration,.draw)) %>% 
  arrange(name,.draw)

fit_draws_control_agent$name <- factor(fit_draws_control_agent$name)

control_agent <- ggplot(fit_draws_control_agent, aes(fill = name, x = exp(value), color = name, fill = NA)) +
  geom_vline(xintercept = 1, color = "black", 
             size = 1) +
  stat_slab(slab_linewidth = 0.9, fill = NA) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 4)) +
  annotate("text", x = 0.25, y =0.8, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 1.5, y = 0.8,  label = "Favours\ncontrol") +
  theme_light() +
  labs(x = "Odds ratio (log scale)") +
  theme(axis.line = element_blank(),  
        axis.text.y = element_blank()) +
  ylab(NULL) +
  scale_color_manual(values = RColorBrewer::brewer.pal(3, "Set1"),
                     breaks = c("morphine", "propofol", "ns"),
                     labels = c("Morphine", "Propofol", "Normal saline"),
                     name = "Control agent")
  
grid.arrange(dose_timing, control_agent, ncol = 1)

```

### Tablulated

Now let's use the brms function `brms::hypothesis()` to compare levels of the variables.

The includes the (one-sided hypothesis test) evidence ratio, which is described by Paul Buerkner as:

> "That is, when the hypothesis is of the form a > b, the evidence ratio is the ratio of the posterior probability of a > b and the posterior probability of a < b. In this example, values greater than one indicate that the evidence in favor of a > b is larger than evidence in favor of a < b."

``` {r}
#| label: tbl-dose-timing-comp-table
#| tbl-cap: |
#|   Comparison of effect with different dose timing.
   
intraop_lessthan_0 <- hypothesis(m.brm_dose_timing, 
                          "Intercept < 0")$hypothesis # Intraop greater than 0?
intraop_postop_lessthan_0 <- hypothesis(m.brm_dose_timing, 
                          "Intercept + dex_dose_timingintraop_and_postop < 0")$hypothesis # Intraop + postop greater than 0?
postop_lessthan_0 <- hypothesis(m.brm_dose_timing, 
           "Intercept + dex_dose_timingpostop < 0")$hypothesis # Postop greater than 0?

intraop_postop_superto_intraop <- hypothesis(m.brm_dose_timing, 
                                              "Intercept + dex_dose_timingintraop_and_postop < Intercept")$hypothesis # Intraop greater than intraop + postop?
intraop_postop_superto_postop <- hypothesis(m.brm_dose_timing, 
                                            "Intercept + dex_dose_timingintraop_and_postop < Intercept + dex_dose_timingpostop")$hypothesis
## Intraop + postop greater than postop?
postop_superto_intraop <- hypothesis(m.brm_dose_timing, 
                                            "Intercept + dex_dose_timingpostop < Intercept")$hypothesis # Postop greater than intraop?


## Now for control agent
morphine_lessthan_0 <- hypothesis(m.brm_control_agent, 
                          "Intercept < 0")$hypothesis # Morphine greater than 0?
propofol_lessthan_0 <- hypothesis(m.brm_control_agent, 
                          "Intercept + control_agent_cleanPropofol < 0")$hypothesis # Propofol greater than 0?
ns_lessthan_0 <- hypothesis(m.brm_control_agent, 
           "Intercept + control_agent_cleanNormalsaline < 0")$hypothesis # NS greater than 0?

propofol_superto_morphine <- hypothesis(m.brm_control_agent, 
                                              "Intercept + control_agent_cleanPropofol < Intercept")$hypothesis # morphine greater than propofol?
propofol_superto_ns <- hypothesis(m.brm_control_agent, 
                                            "Intercept + control_agent_cleanPropofol < Intercept + control_agent_cleanNormalsaline")$hypothesis
## NS greater than morphine?
ns_superto_morphine <- hypothesis(m.brm_control_agent, 
                                            "Intercept + control_agent_cleanNormalsaline < Intercept")$hypothesis

tabdat_dose_timing <- rbind(intraop_lessthan_0, intraop_postop_lessthan_0, postop_lessthan_0,
                intraop_postop_superto_intraop, intraop_postop_superto_postop, postop_superto_intraop)

tabdat_dose_timing$group <- "Dose timing"

tabdat_control_agent <- rbind(morphine_lessthan_0, propofol_lessthan_0, ns_lessthan_0,
                propofol_superto_morphine, propofol_superto_ns, ns_superto_morphine)

tabdat_control_agent$group <- "Control agent"

tab <- rbind(tabdat_dose_timing, tabdat_control_agent) %>%
  mutate(across(where(is.numeric), ~ sprintf("%.2f", round(.x, 2)))) %>%
  mutate(est_ci = paste0(Estimate, " (", CI.Lower, " to ", CI.Upper, ")"),
         Hypothesis = c("Intraoperative (any benefit)", "Intraoperative + posteropative (any benefit)",
                        "Postoperative (any benefit)", "Intraoperative + postoperative superior to intraoperative",
                        "Intraoperative + postoperative superior to postoperative",
                        "Postoperative superior to intraoperative",
                        "Morphine (any benefit)", "Propofol (any benefit)",
                        "Normal saline (any benefit)", "Propofol superior to morphine",
                        "Propofol superior to normal saline",
                        "Normal saline superior to morphine")) %>%
  dplyr::select(-c(Estimate:CI.Upper, Star)) %>%
  gt(groupname_col = "group", rowname_col = "Hypothesis") %>%
  cols_label(Evid.Ratio = "Evidence ratio", 
             Post.Prob = "Posterior probability",
              est_ci = "Estimate (95% CrI)")  %>%
  tab_footnote(
    footnote = "This is the ratio of the posterior probability of a > b and the posterior probability of a < b. Values >1 are evidence in favour of the specified hypothesis.",
    locations = cells_column_labels(columns = Evid.Ratio),
    placement = "right")

 tab %>% 
  gt::gtsave(., "evidence_ratios.rtf")

tab

```

# Secondary outcomes

Now for the secondary outcomes. For these we used the same priors as in our primary analysis for binary outcomes.

For the continuous secondary outcomes, slightly different priors were required. Our NNHM remains the same, but now we need to specify a meaningful prior for a mean difference rather than an odds ratio. We have chosen a normal prior with mean 0 and standard deviation 1. That is, 95% of the density is around -2 to 2. This again is a weakly informative prior - we expect that dexmedetomidine may affect outcomes such as length of hospital stay, but it is unlikely that the magnitude of effect is greater than a 2 day difference. We will use the same prior for the coefficient $\beta$ in metaregression of continuous secondary outcomes. We will use the same priors for $\tau$. So, for our continuous secondary outcomes, the formulas for our NNHM are:

$$\hat{\theta} \sim Normal(\theta, \sigma^2)$$
$$\theta \sim Normal(\mu, \tau^2)$$
$$\mu \sim Normal(0,1)$$
$$\tau \sim HalfCauchy(0.5)$$
$$\beta \sim Normal(0,1)$$

## Forest plot

For the 'Mean (SD)' columns for the continuous outcomes, we used the unweighted grand mean (means of all the studys' means and SDs). As such, these numbers as essentially arbitrary (because means from tiny studies are weighted equally to means from massive studies). We just present these numbers to give the reader an idea of the sorts of values that were observed in the included studies.

```{r fig.width = 12, fig.height = 7}
#| label: fig-secondary-plots
#| fig-width: 12
#| fig-height: 7
#| fig-cap: |
#|   Forest plot of the secondary outcomes.

## First let's start of with our binary secondary outcomes
df_mortality <-  spread_draws(m.brm_mortality, b_Intercept) %>%
  mutate(outcome = "Mortality")

df_bradycardia <-  spread_draws(m.brm_bradycardia, b_Intercept) %>%
  mutate(outcome = "Bradycardia")

df_hypotension <-  spread_draws(m.brm_hypotension, b_Intercept) %>%
  mutate(outcome = "Hypotension")

df_arrhythmia <-  spread_draws(m.brm_arrhythmia, b_Intercept) %>%
  mutate(outcome = "Arrhythmia")

forest.data_secondary_dichot <- rbind(df_mortality, df_bradycardia, df_hypotension, df_arrhythmia) %>%
  mutate(outcome = as.factor(outcome))

pred_fn <- function(m.brm, outcome) {
  nd = data.frame(author1 = "new", sei = 0)
  
  pred_summ <- brms::posterior_predict(object = m.brm,
                          newdata = nd,
                          re_formula = NULL,
                          allow_new_levels = TRUE,
                          sample_new_levels = "gaussian") 

  pred_df <- pred_summ |> 
             data.frame() |>
             ggdist::median_hdi(.width = c(.95)) |>
            rename(coeff = 1)

  pred_df$outcome <- as.factor(c(outcome))
  pred_df <- pred_df[c(7, 1:3)] %>%
  rename(pi_median = coeff,
         pi_lower = .lower,
         pi_upper = .upper)
}

# Combine the prediction intervals into a dataframe
pred_df_secondary_dichot <- rbind(pred_fn(m.brm_mortality, "Mortality"), pred_fn(m.brm_bradycardia, "Bradycardia"), pred_fn(m.brm_hypotension, "Hypotension"), 
                           pred_fn(m.brm_arrhythmia, "Arrhythmia"))

# Extract odds ratios and 95% CIs
est_fn_dichot <- function(m.brm_secondary) {
  spread_draws(m.brm_secondary, b_Intercept) %>%
    median_qi() %>%
    mutate(effect = paste0(sprintf('%.2f', exp(b_Intercept)), 
                  ' [', sprintf('%.2f', exp(.lower)),
                  ', ', sprintf('%.2f', exp(.upper)), ']'))
}

tau_fn_secondary <- function(m.brm_secondary) {
  spread_draws(m.brm_secondary, sd_author1__Intercept) %>%
    median_qi() %>%
    mutate(tau = paste0(sprintf('%.2f', sd_author1__Intercept), 
                  ' [', sprintf('%.2f', .lower),
                  ', ', sprintf('%.2f', .upper), ']'))
}

estimates_secondary_dichot <- rbind(est_fn_dichot(m.brm_mortality), est_fn_dichot(m.brm_bradycardia), 
                             est_fn_dichot(m.brm_hypotension), est_fn_dichot(m.brm_arrhythmia))
tau_secondary_dichot <- rbind(tau_fn_secondary(m.brm_mortality), tau_fn_secondary(m.brm_bradycardia), 
                       tau_fn_secondary(m.brm_hypotension), tau_fn_secondary(m.brm_arrhythmia))

comb_estimates_tau_dichot <- cbind(estimates_secondary_dichot, tau_secondary_dichot) %>%
  dplyr::select(effect, tau)

## Then make a function to calculate the number of studies for each outcome
count_na <- function(name) {
  return(dat %>% filter(!is.na(!!sym(paste0("dex_", name)))) %>% nrow())
}
study_number_dichot <- c(count_na("mortality"), count_na("bradycardia"), count_na("hypotension"), count_na("arrhythmia"))

## And finally get the total number of participants for each outcome
sum_dex_ratio <- function(name) {
  return(paste0(sum(dat[!is.na(dat[[paste0("dex_", name)]]),][[paste0("dex_", name)]], na.rm=TRUE), "/",
                sum(dat[!is.na(dat[[paste0("dex_", name)]]),][["dex_n"]], na.rm=TRUE)))
}

sum_control_ratio <- function(name) {
  return(paste0(sum(dat[!is.na(dat[[paste0("control_", name)]]),][[paste0("control_", name)]], na.rm=TRUE), "/",
                sum(dat[!is.na(dat[[paste0("control_", name)]]),][["control_n"]], na.rm=TRUE)))
}

dex_number <- c(sum_dex_ratio("mortality"), sum_dex_ratio("bradycardia"), 
                        sum_dex_ratio("hypotension"), sum_dex_ratio("arrhythmia"))

control_number <- c(sum_control_ratio("mortality"), sum_control_ratio("bradycardia"), 
                        sum_control_ratio("hypotension"), sum_control_ratio("arrhythmia"))

## Combine all these into a dataframe
tabdat_pre <- data.frame("outcome" = as.factor(c("Mortality", "Bradycardia", "Hypotension",
                                "Arrhythmia")),
                     "study_number" = as.character(study_number_dichot),
                     "dex_number" = dex_number,
                     "control_number" = control_number,
                      comb_estimates_tau_dichot)

new_row <- data.frame(outcome = as.factor("Outcome"),
                      effect = "[95%CrI]",
                      tau = "[95%CrI]",
                      dex_number = "n/total",
                      control_number = "n/total",
                      study_number = "No. Studies")

## Add an extra row because we need more space at the top
new_row_tabdat <- data.frame(outcome = as.factor(""),
                      effect = "Odds ratio",
                      tau = "τ",
                      dex_number = "DEX",
                      control_number = "Control",
                      study_number = "")

tabdat_dichot <- bind_rows(tabdat_pre, new_row, new_row_tabdat)

p_forest_secondary_dichot <- ggplot(aes(exp(b_Intercept), 
           relevel(outcome, "Arrhythmia", after=Inf)), 
       data = forest.data_secondary_dichot) +
  geom_vline(xintercept = 1, color = "black", 
             size = 0.7) +
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    geom_pointintervalh(aes(xmin = exp(pi_lower), 
                          xmax = exp(pi_upper), 
                          x = exp(pi_median)),
                      position = position_nudge(y = -0.2),
                      data = pred_df_secondary_dichot, 
                      col = "darkorange",
                      size = 6) +
  scale_x_log10(breaks = c(0.1, 0.25, 0.5, 1, 2, 4, 7), expand = c(0, 0)) +           
  coord_cartesian(xlim=c(0.1, 7), ylim=c(1,6)) +
  annotate("text", x = 0.35, y =5.5, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 3, y = 5.5,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Odds ratio (log scale)") +
  ylab(NULL) +
  guides(alpha = "none")

p_estimates_secondary_dichot <- ggplot(aes(y = relevel(outcome, "Arrhythmia", after=Inf)), 
                   data = tabdat_dichot) +
  geom_text(aes(x = 0, label = effect), hjust = 0,
            fontface = ifelse(grepl("Odds ratio|\\[95%CrI\\]", tabdat_dichot$effect), "bold", "plain")) +
  geom_text(aes(x = 1, label = tau), hjust = 0, 
            fontface = ifelse(grepl("τ|\\[95%CrI\\]", tabdat_dichot$tau), "bold", "plain")) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 2))

# Map the fill and color aesthetics to the new column in the ggplot call
p_studies_secondary_dichot <- ggplot(aes(y = relevel(outcome, "Arrhythmia", after=Inf)), 
                          data = tabdat_dichot) +
  geom_text(aes(x = 0, label = outcome), hjust = 0, 
            fontface = ifelse(tabdat_dichot$outcome == "Outcome", "bold","plain")) +
  geom_text(aes(x = 2, label = study_number), hjust = 0, 
            fontface = ifelse(tabdat_dichot$study_number == "No. Studies", "bold", "plain")) +
  geom_text(aes(x = 4, label = dex_number), hjust = 0, 
            fontface = ifelse(tabdat_dichot$dex_number == "n/total" | tabdat_dichot$dex_number == "DEX", "bold", "plain")) +
  geom_text(aes(x = 6, label = control_number), hjust = 0, 
            fontface = ifelse(tabdat_dichot$control_number == "n/total" | tabdat_dichot$control_number == "Control", "bold", "plain")) +
  scale_color_identity() + # Use the specified colors directly for text color
  theme_void() +
  coord_cartesian(xlim = c(0, 8))

## Now let's look at our continous secondary outcomes
df_del_duration <-  spread_draws(m.brm_del_duration, b_Intercept) %>%
  mutate(outcome = "Delirium duration")

df_extub_time <-  spread_draws(m.brm_extub_time, b_Intercept) %>%
  mutate(outcome = "Time to extubation")

df_hosp_stay <-  spread_draws(m.brm_hosp_stay, b_Intercept) %>%
  mutate(outcome = "Hospital stay")

df_icu_stay <-  spread_draws(m.brm_icu_stay, b_Intercept) %>%
  mutate(outcome = "ICU stay")

forest.data_secondary_cont <- rbind(df_del_duration, df_extub_time, df_hosp_stay, df_icu_stay) %>%
  mutate(outcome = as.factor(outcome))

# Combine the prediction intervals into a dataframe
pred_df_secondary_cont <- rbind(pred_fn(m.brm_del_duration, "Delirium duration"), pred_fn(m.brm_extub_time, "Time to extubation"), pred_fn(m.brm_hosp_stay, "Hospital stay"), 
                           pred_fn(m.brm_icu_stay, "ICU stay"))


# Extract MDs and 95% CIs
est_fn_cont <- function(m.brm_secondary) {
  spread_draws(m.brm_secondary, b_Intercept) %>%
    median_qi() %>%
    mutate(effect = paste0(sprintf('%.2f', b_Intercept), 
                  ' [', sprintf('%.2f', .lower),
                  ', ', sprintf('%.2f', .upper), ']'))
}

estimates_secondary_cont <- rbind(est_fn_cont(m.brm_del_duration), est_fn_cont(m.brm_extub_time), 
                             est_fn_cont(m.brm_hosp_stay), est_fn_cont(m.brm_icu_stay))
tau_secondary_cont <- rbind(tau_fn_secondary(m.brm_del_duration), tau_fn_secondary(m.brm_extub_time), 
                       tau_fn_secondary(m.brm_hosp_stay), tau_fn_secondary(m.brm_icu_stay))

comb_estimates_tau_cont <- cbind(estimates_secondary_cont, tau_secondary_cont) %>%
  dplyr::select(effect, tau)

count_na_cont <- function(name_mean, name_sd) {
  return(dat %>% filter(!is.na(!!sym(paste0("dex_", name_mean)))) %>% 
            filter(!is.na(!!sym(paste0("dex_", name_sd)))) %>% nrow())
}

study_number_cont <- c(count_na_cont("delirium_duration_days_mean", "delirium_duration_days_sd"), 
                       count_na_cont("timetoextubation_mean", "timetoextubation_sd"), 
                       count_na_cont("hospital_days_mean", "hospital_days_sd"), 
                       count_na_cont("icu_days_mean", "icu_days_sd"))

## And finally get the overall grand mean for each outcome
dex_mean_fn <- function(study_mean, study_sd) {
  return(paste0(sprintf('%.2f', mean(dat[!is.na(dat[[paste0("dex_", study_mean)]]),][[paste0("dex_", study_mean)]], na.rm=TRUE)), " (",
                sprintf('%.2f', mean(dat[!is.na(dat[[paste0("dex_", study_sd)]]),][[paste0("dex_", study_sd)]], na.rm=TRUE)), ")"))
}

control_mean_fn <- function(study_mean, study_sd) {
  return(paste0(sprintf('%.2f', mean(dat[!is.na(dat[[paste0("control_", study_mean)]]),][[paste0("control_", study_mean)]], na.rm=TRUE)), " (",
                sprintf('%.2f', mean(dat[!is.na(dat[[paste0("control_", study_sd)]]),][[paste0("control_", study_sd)]], na.rm=TRUE)), ")"))
}

dex_mean <- c(dex_mean_fn("delirium_duration_days_mean", "delirium_duration_days_sd"), 
              dex_mean_fn("timetoextubation_mean", "timetoextubation_sd"), 
              dex_mean_fn("hospital_days_mean", "hospital_days_sd"), 
              dex_mean_fn("icu_days_mean", "icu_days_sd"))

control_mean <- c(control_mean_fn("delirium_duration_days_mean", "delirium_duration_days_sd"), 
              control_mean_fn("timetoextubation_mean", "timetoextubation_sd"), 
              control_mean_fn("hospital_days_mean", "hospital_days_sd"), 
              control_mean_fn("icu_days_mean", "icu_days_sd"))

## Combine all these into a dataframe
tabdat_pre <- data.frame("outcome" = as.factor(c("Delirium duration", "Time to extubation", "Hospital stay",
                                "ICU stay")),
                     "study_number" = as.character(study_number_cont),
                     "dex_number" = dex_mean,
                     "control_number" = control_mean,
                     comb_estimates_tau_cont)

new_row <- data.frame(outcome = as.factor("Outcome"),
                      effect = "[95%CrI]",
                      tau = "[95%CrI]",
                      dex_number = "Mean (SD)",
                      control_number = "Mean (SD)",
                      study_number = "No. Studies")

## Add an extra row because we need more space at the top
new_row_tabdat <- data.frame(outcome = as.factor(""),
                      effect = "Mean difference",
                      tau = "τ",
                      dex_number = "DEX",
                      control_number = "Control",
                      study_number = "")

tabdat_cont <- bind_rows(tabdat_pre, new_row, new_row_tabdat)

p_forest_secondary_cont <- ggplot(aes(b_Intercept, 
           relevel(outcome, "ICU stay", after=Inf)), 
       data = forest.data_secondary_cont) +
  geom_vline(xintercept = 0, color = "black", 
             size = 0.7) +
  stat_halfeye(interval_colour = "darkblue", slab_colour = "blue", point_colour = "darkblue", fill = "lightblue",
               slab_linewidth = 0.9) +
    geom_pointintervalh(aes(xmin = pi_lower, 
                          xmax = pi_upper, 
                          x = pi_median),
                      position = position_nudge(y = -0.2),
                      data = pred_df_secondary_cont, 
                      col = "darkorange",
                      size = 6) +
  scale_x_continuous(expand = c(0, 0)) +           
  coord_cartesian(xlim=c(-6, 6), ylim=c(1,6)) +
  annotate("text", x = -3, y =5.5, label = "Favours\ndexmedetomidine") +
  annotate("text", x = 3, y = 5.5,  label = "Favours\ncontrol") +
  theme_light() +
  theme(axis.text.y = element_blank()) +
  labs(x="Mean difference") +
  ylab(NULL) +
  guides(alpha = "none")

p_estimates_secondary_cont <- ggplot(aes(y = relevel(outcome, "ICU stay", after=Inf)), 
                   data = tabdat_cont) +
  geom_text(aes(x = 0, label = effect), hjust = 0,
            fontface = ifelse(grepl("Mean difference|\\[95%CrI\\]", tabdat_cont$effect), "bold", "plain")) +
  geom_text(aes(x = 1, label = tau), hjust = 0, 
            fontface = ifelse(grepl("τ|\\[95%CrI\\]", tabdat_cont$tau), "bold", "plain")) +
  scale_color_identity() +
  theme_void() +
  coord_cartesian(xlim = c(0, 2))

# Map the fill and color aesthetics to the new column in the ggplot call
p_studies_secondary_cont <- ggplot(aes(y = relevel(outcome, "ICU stay", after=Inf)), 
                          data = tabdat_cont) +
  geom_text(aes(x = 0, label = outcome), hjust = 0, 
            fontface = ifelse(tabdat_cont$outcome == "Outcome", "bold","plain")) +
  geom_text(aes(x = 2, label = study_number), hjust = 0, 
            fontface = ifelse(tabdat_cont$study_number == "No. Studies", "bold", "plain")) +
  geom_text(aes(x = 4, label = dex_number), hjust = 0, 
            fontface = ifelse(tabdat_cont$dex_number == "Mean (SD)" | tabdat_cont$dex_number == "DEX", "bold", "plain")) +
  geom_text(aes(x = 6, label = control_number), hjust = 0, 
            fontface = ifelse(tabdat_cont$control_number == "Mean (SD)" | tabdat_cont$control_number == "Control", "bold", "plain")) +
  scale_color_identity() + # Use the specified colors directly for text color
  theme_void() +
  coord_cartesian(xlim = c(0, 8))

library(patchwork)

layout <- c(
  patchwork::area(t = 0, l = 0, b = 12, r = 36),
  patchwork::area(t = 0, l = 35, b = 12, r = 55), 
  patchwork::area(t = 0, l = 56, b = 12, r = 76),
  patchwork::area(t = 13, l = 0, b = 25, r = 36),
  patchwork::area(t = 13, l = 35, b = 25, r = 55), 
  patchwork::area(t = 13, l = 56, b = 25, r = 76))

p_studies_secondary_dichot + p_forest_secondary_dichot + p_estimates_secondary_dichot + 
  p_studies_secondary_cont + p_forest_secondary_cont + p_estimates_secondary_cont + plot_layout(design = layout)
```

## Probability of harm calculations

Let's also look at the probability of dexmedetomidine causing various levels of harm, in the form of bradycardia and hypotension. This is equal and opposite to @tbl-benefit-probs-all. @tbl-harm-probs-secondary below shows the relevant figures.

```{r}
#| label: tbl-harm-probs-secondary
#| tbl-cap: Probability of harm of dexmedetomidine in causing bradycardia and hypotension, across various subgroups.
#| #| results: 'hide'
#| message: FALSE
#| warning: FALSE
#| errors: FALSE

# First - bradycardia
 # Begin with overall
# First, calculate the median delirium rate in control group
Rc_overall_bradycardia <- median(IVdat_bradycardia$control_bradycardia_rate) 

rt_mcid_bradycardia <- (median(IVdat_bradycardia$control_bradycardia_rate)*exp(0.18))/(median(IVdat_bradycardia$control_bradycardia_rate)*(exp(0.18)-1) + 1)
rd_mcid_bradycardia <- rt_mcid_bradycardia - Rc_overall_bradycardia

arr_mcid_or_overall_bradycardia <- (rt_mcid_bradycardia*(Rc_overall_bradycardia - 1))/(Rc_overall_bradycardia*(rt_mcid_bradycardia - 1))

probs_overall_bradycardia = 
  m.brm_bradycardia |> 
  tidy_draws() |> 
  summarise(any_harm_overall_bradycardia = 100*mean(b_Intercept > log(1)),
            rrr_mcid_overall_bradycardia = 100*mean(b_Intercept > log(arr_mcid_or_overall_bradycardia)))


prob_tbl1 <- as.data.frame(rbind("Overall" = c("Overall",  Rc_overall_bradycardia, probs_overall_bradycardia))) %>%
  mutate_at(vars(2:4), as.numeric) %>%
  rename(`Subgroup` = V1,
          `median_rate` = V2) %>%
  mutate(`median_rate` = `median_rate` * 100) %>%
  mutate_at(vars(2:4), ~sprintf("%.1f", .))

colnames(prob_tbl1) <- c("Subgroup", "Median control group rate (%)", "Probability of any harm (%)", "Probability of harm >MCID")

# First - hypotension
 # Begin with overall
# First, calculate the median delirium rate in control group
Rc_overall_hypotension <- median(IVdat_hypotension$control_hypotension_rate) 

rt_mcid_hypotension <- (median(IVdat_hypotension$control_hypotension_rate)*exp(0.18))/(median(IVdat_hypotension$control_hypotension_rate)*(exp(0.18)-1) + 1)
rd_mcid_hypotension <- rt_mcid_hypotension - Rc_overall_hypotension

arr_mcid_or_overall_hypotension <- (rt_mcid_hypotension*(Rc_overall_hypotension - 1))/(Rc_overall_hypotension*(rt_mcid_hypotension - 1))

probs_overall_hypotension = 
  m.brm_hypotension |> 
  tidy_draws() |> 
  summarise(any_harm_overall_hypotension = 100*mean(b_Intercept > log(1)),
            rrr_mcid_overall_hypotension = 100*mean(b_Intercept > log(arr_mcid_or_overall_hypotension)))

prob_tbl2 <- as.data.frame(rbind("Overall" = c("Overall",  Rc_overall_hypotension, probs_overall_hypotension))) %>%
  mutate_at(vars(2:4), as.numeric) %>%
  rename(`Subgroup` = V1,
          `median_rate` = V2) %>%
  mutate(`median_rate` = `median_rate` * 100) %>%
  mutate_at(vars(2:4), ~sprintf("%.1f", .))

colnames(prob_tbl2) <- c("Subgroup", "Median control group rate (%)", "Probability of any harm (%)", "Probability of harm >MCID")

# combine the two data frames using rbind()
prob_tbl <- rbind(prob_tbl1, prob_tbl2)

# Add a row at the top with "Bradycardia"
prob_tbl$outcome <- rep(c("Bradycardia", "Hypotension"), each = 1)

tab <- prob_tbl %>%
  gt(rowname_col = "Subgroup", groupname_col = "outcome") %>%
  tab_style(
    style = list(
      cell_fill(color = "grey"),
      cell_text(weight = "bold")
      ),
    locations = cells_row_groups()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels())

 tab %>% 
  gt::gtsave(., "probs_harm.rtf")

tab

```

# Small study effects

We will use two Bayesian methods of sample study effects assessment: Bayesian regression testing and Bayesian model averaging.

## Bayesian regression test

Arguably the most popular method of sample study effect assessment is through analysis of funnel plot asymmetry, in the form of Egger's regression test (and variants therein). This test involves regressing the effect sizes of studies according to their precision; slopes that are significantly different from 0 suggest sample sample effects. This can also be applied in a Bayesian framework, and was described recently by [Shi et al.](https://pubmed.ncbi.nlm.nih.gov/32424987/) The interpretation regarding the slope is similar to the frequentist Egger's test. Shi et al. use the latent "true" SEs in the Egger-type regression under the Bayesian framework.

Like many sample bias tests, **this actually assesses funnel plot asymmetry (of which publication bias is only 1 cause).**

For a list of alternative causes of funnel plot asymmetry, see [Harrer et al.](https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/pub-bias.html)

Briefly, they are:

- Between-study effect heterogeneity
- Heterogeneity in types of feasible methods of small vs. large studies
- Small studies being more poorly run than large studies
- Random change

There are various options for inputs. We will use multiplicative heterogeneity rather than additive heterogeneity. We will use a half-normal prior with 0.5 scale parameter (Cauchy distributions are not available but the difference is likely trivial). The default vague priors for the regression intercept and slope are used: $N(0, 10^4)$, as this is the approach use for the model's validation in [Shi et al.](https://pubmed.ncbi.nlm.nih.gov/32424987/)

As you can see in @tbl-bayesian-regression, the 95%CrI for the slope excludes 0, whether looking at all studies or excluding studies at high risk of bias. This suggests the presence of publication bias.

## All studies

```{r}
#| label: tbl-bayesian-regression
#| tbl-cap: Bayesian regression testing to assess for small study effects.
#| message: FALSE
#| warning: FALSE
#| errors: FALSE

library(altmeta)
df_all <- pb.bayesian.binary(n00 = dex_no_del, n01 = dex_del, 
                   n10 = control_no_del, n11 = control_del, data = IVdat_del,
  sig.level = 0.05, method = "bay", het = "mul",
  sd.prior = "hn", n.adapt = 1000, n.chains = 3,
  n.burnin = 5000, n.iter = 100000, thin = 10,
  phi = 0.5, coda = FALSE,
  traceplot = FALSE)

df_low_rob <- pb.bayesian.binary(n00 = dex_no_del, n01 = dex_del, 
                   n10 = control_no_del, n11 = control_del, data = IVdat_del_low_rob,
  sig.level = 0.05, method = "bay", het = "mul",
  sd.prior = "hn", n.adapt = 1000, n.chains = 3,
  n.burnin = 5000, n.iter = 100000, thin = 10,
  phi = 0.5, coda = FALSE,
  traceplot = FALSE)

dat1 <- data.frame(estimate = sprintf('%.2f', df_all[[1]]),
                  confint = paste0(sprintf('%.2f', df_all$ci.bay[[1]]), ", ", sprintf('%.2f', df_all$ci.bay[[2]])),
                  Group = "All studies")

dat2 <- data.frame(estimate = sprintf('%.2f', df_low_rob[[1]]),
                  confint = paste0(sprintf('%.2f', df_low_rob$ci.bay[[1]]), ", ", sprintf('%.2f', df_low_rob$ci.bay[[2]])),
                  Group = "Excluding studies at high risk of bias")
dat_pub <- rbind(dat1, dat2)

colnames(dat_pub) <- c("Estimate", "95% credible interval", "Group")

dat_pub %>%
  gt(groupname_col = "Group") %>%
    tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels()) %>%
  tab_style(
    style = list(
      cell_fill(color = "grey"),
      cell_text(weight = "bold")
      ),
    locations = cells_row_groups())

```

## Bayesian model averaging

Bayesian model averaging is well described by [Bartos et al.](https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1594):

> "In practice, researchers seldom have knowledge about the data-generating process nor do they have sufficient information to choose with confidence among the wide variety of proposed methods that aim to adjust for publication bias. Furthermore, this wide range of proposed methods often leads to contradictory conclusions. The combination of uncertainty about the data-generating process and the presence of conflicting conclusions can create a "breeding ground" for confirmation bias: researchers may unintentionally select those methods that support the desired outcome. This freedom to choose can greatly inflate the rate of false positives, which can be a serious problem for conventional meta-analysis methods."

The RoBMA packages generates three families of models across 12 models (interfacing with `JAGS` through `rjags`), and averages their performance. A total of 32 of these models include publication bias and 4 do not. For a description see [this link](https://psyarxiv.com/u4cns?ref=hormones-brain-and-behavior). The output includes an **inclusion Bayes factor**. The Bayes factor is the ratio of two marginal likelihoods (i.e., two probabilities of data given certain models). We will produce Bayes factors for the mean effect, heterogeneity, and publication bias.

The "inclusion" part of "inclusion Bayes factor" refers to the fact we are comparing the alternative hypothesis *relative* to the null hypothesis. Hence our notation for the bayes factor is $BF_{10}$ rather than $BF_{01}$, which is another kind of Bayes factor that compares the null hypothesis *relative* to the alternative hypothesis. So, for the mean effect, our null model is $H_0: {\mu} = 0$ and alterative model is $H_1: {\mu} ≠ 0$. Then, the inclusion Bayes factor is:

$$
BF_{10} = \frac{p(data | H_1)}{p(data | H_0)}
$$ Bayes factors answers the question: Are the observed data more probable under models with a particular effect, than they are under models without that particular effect? Inclusion Bayes factors \>3 indicate 'substantial' evidence against the null, while inclusion Bayes factors \<1/3 indicate 'substantial' evidence for the null.

The benefit provided by the model averaging approach is that we are provided with an inclusion Bayes factor for publication bias. A high inclusion BF for publication bias would suggest that models accounting for publication bias are more consistent with the observed data. We are also provided with an estimate that accounts for publication bias.

Publication bias models include selection models and PET-PEESE models as methods of publication bias assessment. The publication bias adjustment prior is described in [Bartoš (2021).](https://onlinelibrary.wiley.com/doi/full/10.1002/jrsm.1594)

@tbl-robma shows the results.

### Summary

```{r}
#| label: tbl-robma
#| tbl-cap: |
#|    Results of the model-averaging approach to meta-analysis, 
#|    with results for models including publication bias and excluding publication bias.

library(RoBMA)
library(rjags)

## Model with pub bias models included
robma <- RoBMA(logOR = IVdat_del$yi, v = IVdat_del$vi,
               priors_effect = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.82)),
               priors_heterogeneity = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.5),
                                            truncation = list(lower = 0, upper = Inf)), 
               prior_scale = "logOR",
               effect_direction = "negative")

## Model without pub bias included
robma_no_bias <- RoBMA(logOR = IVdat_del$yi, v = IVdat_del$vi,
               priors_effect = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.82)),
               priors_heterogeneity = prior(distribution = "normal", parameters = list(mean = 0, sd = 0.5),
                                            truncation = list(lower = 0, upper = Inf)),
               prior_scale = "logOR",
               effect_direction = "negative", priors_bias = NULL)

df_all <- summary(robma)$components %>%
  data.frame() %>%
  mutate(parameter = c("Effect", "Heterogeneity", "Publication bias"),
         Group = "Models accounting for publication bias")

df_low_rob <- summary(robma_no_bias)$components %>%
  data.frame() %>%
  mutate(parameter = c("Effect", "Heterogeneity", "Publication bias"),
         Group = "Models not accounting for publication bias")

tab <- rbind(df_all, df_low_rob) %>%
  mutate(across(prior_prob:inclusion_BF, ~sprintf("%.2f", .))) %>%
  rename("Number of models" = models,
         "Prior probability" = prior_prob,
         "Posterior probability" = post_prob,
         "Inclusion Bayes factor" = inclusion_BF) %>%
  gt(rowname_col = "parameter", groupname_col = "Group") %>%
  tab_style(
    style = list(
      cell_fill(color = "grey"),
      cell_text(weight = "bold")
      ),
    locations = cells_row_groups()) %>%
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(weight = "bold")
      ),
    locations = cells_column_labels())

tab %>% 
  gt::gtsave(., "robma_tab.rtf")

tab

```

### Estimates

Below we present the model-averaged estimates from the robust Bayesian meta-analysis. We present model-averaged estimates (averaged across models assuming the null is true, and models assuming the alternative hypothesis is true) as well as conditional estimates (averaged over only models that assume the alternative hypothesis is true). 

```{r}
#| label: tbl-robma_estimates

tabdat_all <- summary(robma, conditional = TRUE)$estimates
tabdat_all$subgroup <- "Averaged across all models"
tabdat_conditional <- summary(robma, conditional = TRUE)$estimates_conditional
tabdat_conditional$subgroup <- "Averaged across models assuming the alternative hypothesis is true"

data.frame(rbind(tabdat_all, tabdat_conditional)) %>%
  slice(1:2, 11:12) %>%
  mutate(est = c("μ", "τ", "μ", "τ")) %>%
  mutate(across(where(is.numeric), ~ if_else(est == "μ", exp(.), .))) %>%
  mutate(across(.cols = -c(est, subgroup), ~ sprintf("%.2f", as.numeric(.))))  %>%
  gt(rowname_col = "est", groupname_col = "subgroup") %>%
  gt::cols_label("X0.025" = "2.5th percentile",
                 "X0.975" = "97.5th percentile") %>%
  tab_footnote(footnote = "Estimates are odds ratios",
                locations = cells_stub(rows = "μ")) %>%
  tab_footnote(footnote = "Estimates are log odds ratios",
                locations = cells_stub(rows = "τ"))
```


### Plots

Now let's plot the posterior distributions for the mean effect to visualise the effect of publication bias. In @fig-robma-plots below, (A) shows the distribution of the model-averaged estimate with models including publication bias, and (B) is the average distribution of models that do not include publication bias.

Our model-averaged estimates in these plots use models that assume the absence of an effect (other options includes models that assume the presence of an effect).

The arrows demonstrate the probability of a spike at $log(OR) = 0$ (no effect).

Evidently, including publication bias models significantly changes the results.

```{r}
#| label: fig-robma-plots
#| fig-cap: |
#|    Plots of the model-averaged mean effect when considering (A) all models including those accounting for publication bias, and (B) models excluding those accounting for publication bias.
#| fig.height: 4
#| fig.width: 10

# Set up the plots with a 1x2 grid
par(mfrow = c(1, 2))

# Plot the first graph with title "A" on the left side
plot1 <- plot(robma, parameter = "mu", prior = TRUE, xlim = c(-1, 1.5), plot_type = "ggplot")

plot1 <- plot1 +
  annotate("text", x = 1.1, y = 0.7, label = "Model-averaged \nmean effect including \nmodels accounting \nfor publication bias") +
  labs(x="Log odds ratio", title = "A") +  
  annotate("text", x = -0.5, y = 0.45, label = "Mean effect\nprior (N(0,0.82))", fontface = "bold") +
  geom_segment(aes(x = -0.5, y = 0.35, xend = -0.5, yend = 0.2),
             color = "black",
             size = 0.7,
             arrow = arrow(length = unit(0.04, "npc"), type = "closed")) +
  theme_light()

# Plot the second graph with title "B" on the left side
plot2 <- plot(robma_no_bias, parameter = "mu", prior = TRUE, xlim = c(-1, 1.5), plot_type = "ggplot")

plot2 <- plot2 +
  annotate("text", x = 0.55, y = 2, label = "Model-averaged \nmean effect excluding \nmodels accounting \nfor publication bias") +
  labs(x="Log odds ratio", title = "B") +  
  annotate("text", x = 1, y = 1, label = "Mean effect\nprior (N(0,0.82))", fontface = "bold") +
  geom_segment(aes(x = 1, y = 0.65, xend = 1, yend = 0.2),
             color = "black",
             size = 0.7,
             arrow = arrow(length = unit(0.04, "npc"), type = "closed")) +
  theme_light()

# Reset to the default 1x1 grid
grid.arrange(plot1, plot2, ncol = 2)

```

